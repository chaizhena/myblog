/*
 Navicat Premium Data Transfer

 Source Server         : 阿里云MySQL
 Source Server Type    : MySQL
 Source Server Version : 50727
 Source Host           : 123.57.36.1:3306
 Source Schema         : vueblog

 Target Server Type    : MySQL
 Target Server Version : 50727
 File Encoding         : 65001

 Date: 08/02/2022 18:01:24
*/

SET NAMES utf8mb4;
SET FOREIGN_KEY_CHECKS = 0;

-- ----------------------------
-- Table structure for book
-- ----------------------------
DROP TABLE IF EXISTS `book`;
CREATE TABLE `book`  (
  `id` int(11) NOT NULL AUTO_INCREMENT,
  `cover` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT '',
  `title` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL DEFAULT '',
  `author` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT '',
  `date` varchar(20) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT '',
  `press` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT '',
  `abs` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `cid` int(11) NULL DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `fk_book_category_on_cid`(`cid`) USING BTREE,
  CONSTRAINT `fk_book_category_on_cid` FOREIGN KEY (`cid`) REFERENCES `category` (`id`) ON DELETE SET NULL ON UPDATE CASCADE
) ENGINE = InnoDB AUTO_INCREMENT = 76 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of book
-- ----------------------------
INSERT INTO `book` VALUES (2, 'https://i.loli.net/2019/04/10/5cada7e73d601.jpg', '三体', '刘慈欣', ' 2008-1', '重庆出版社', '文化大革命如火如荼进行的同时。军方探寻外星文明的绝秘计划“红岸工程”取得了突破性进展。但在按下发射键的那一刻，历经劫难的叶文洁没有意识到，她彻底改变了人类的命运。地球文明向宇宙发出的第一声啼鸣，以太阳为中心，以光速向宇宙深处飞驰……\r\n\r\n四光年外，“三体文明”正苦苦挣扎——三颗无规则运行的太阳主导下的百余次毁灭与重生逼迫他们逃离母星。而恰在此时。他们接收到了地球发来的信息。在运用超技术锁死地球人的基础科学之后。三体人庞大的宇宙舰队开始向地球进发……\r\n\r\n人类的末日悄然来临。', 2);
INSERT INTO `book` VALUES (32, 'https://i.loli.net/2019/04/10/5cada99bd8ca5.jpg', '叙事的虚构性', '[美] 海登·怀特 ', '2019-3', '南京大学出版社', '海登•怀特被誉为人类伟大的思想家之一。从1973年出版具有里程碑意义的专著《元史学》以来，怀特的作品对于历史学、文学研究、人类学、哲学、艺术史、电影传媒研究等将叙事学作为关注焦点的学科而言意义非凡。\n\n本书由罗伯特•多兰作序，他巧妙地将怀特重要但难得一见的文章汇集成册，研究探讨他关于历史书写和叙事的革命性理论。怀特的这些文章大多采用论文体，内容涉及多位思想家，探讨诸多主题，文笔犀利，语言优美。\n\n《叙事的虚构性》追溯怀特重要思想的演变轨迹，是历史编纂学者和学习者、历史理论和文学研究学者们的重要读物。', 3);
INSERT INTO `book` VALUES (35, 'https://i.loli.net/2019/04/10/5cada940e206a.jpg', '圣母', '[日]秋吉理香子 ', '2019-3', '新星出版社', '一起男童被害案搅得蓝出市人心惶惶。\n\n好不容易怀孕生产的保奈美抱紧年幼的孩子，立誓要不惜任何代价保护她。\n\n男人是在孩子出生后才成为父亲的，但女人，是从小生命来到体内的那一瞬间起，就是母亲了。患有不孕症的保奈美是经历过艰辛的治疗过程才终于有了孩子的，她不允许这起命案威胁到宝贵的孩子！\n\n母亲，就是要消除所有对子女的威胁，每一位母亲都应肩负这样的使命，这是神圣的天职！', 1);
INSERT INTO `book` VALUES (37, 'https://i.loli.net/2019/04/10/5cada8986e13a.jpg', '奢侈与逸乐', '[英]马克辛·伯格', '2019-3', '中国工人出版社', '本书探讨了十八世纪英国新式、时尚的消费品的发明、制造和购买。', 3);
INSERT INTO `book` VALUES (38, 'https://i.loli.net/2019/04/10/5cada8b8a3a17.jpg', '忧伤动物', '[德]莫妮卡·马龙 ', '2019-4', '漓江出版社', '“忧伤动物”(animal triste)这个词组取自一句最早可以追溯到亚里士多德时代的拉丁语名言，即“欢爱后，每个动物都忧伤不已”（Post coitum omne animal triste est）。无疑，这部冠以如此标题的小说让人有不祥的预感并暗示着宿命的思想。小说的女主人公是位近乎百岁的老人。在多年前有意斩断了与外界的一切联系之后，在她的后半生里，她唯一能做的就是或躺或坐在“印着鲜红、艳绿和深紫色的大花”、让人想起“食肉植物的花朵”的床单上，追忆几十年前她和自己...', 1);
INSERT INTO `book` VALUES (54, 'https://i.loli.net/2019/04/10/5cada9d9d23a6.jpg', '爱界', '[英] 费伊·韦尔登 ', '2019-3-1', '人民文学出版社', '去不去爱，爱的界限何在，一直是普拉克西丝的人生课题。\n\n年迈的她独自待在肮脏而昏暗的地下室里，想写回忆录，可她该写些什么呢？是写父母未婚同居生下了她，她还年幼天真无邪时，母女就遭父亲抛弃？还是写她曾经或是主动或是被动地成了未婚同居者、妻子、情人、母亲、后母？还是写她两年的牢狱生活？她想描绘二十世纪女性的众生相，想记录女性群体在情感、灵魂和思想方面所处的三重困境，想道出女性之间的大爱如何铸成姐妹之谊。', 3);
INSERT INTO `book` VALUES (55, 'https://i.loli.net/2019/04/10/5cada824c7119.jpg', '密室中的旅行', '[美] 保罗·奥斯特 ', '2019-3', '九州出版社', '一旦被抛进这个世界，我们就永远不会消失，即使造物者已经死去。\n\n.\n\n布兰克先生发现自己被囚禁在一个陌生的房间里，对过去的身份和经历一无所知。桌上有四叠六英寸厚的文稿，其中有一份未完待续的囚犯自述；还有一叠似曾相识的照片，照片中的人物将逐一登场。他续写了那个囚犯的故事，却发现自己正在经历的一切也早已被记录在文稿中……', 1);
INSERT INTO `book` VALUES (59, 'https://i.loli.net/2019/04/10/5cada87fd5c72.jpg', '基本穿搭', '[日]大山旬 ', '2019-3', '四川人民出版社', '对穿衣搭配感到不耐烦，认为时尚很麻烦，穿什么都可以或者对衣服有着自己的想法但不够自信，本书就是为这样的人而准备的穿衣指南。不需要追随瞬息万变的时尚潮流，也不需要烦恼色彩搭配，只要掌握最低限度的知识和备齐常规单品，谁都能完成清爽得体的 80分搭配。', 4);
INSERT INTO `book` VALUES (60, 'https://i.loli.net/2019/04/10/5cada976927da.jpg', '冒牌人生', '陈思安', '2019-4', '四川文艺出版社', '《冒牌人生》收录了十篇短篇小说。十个故事分别以城市中的怪人为主角，他们默默无闻地生存在城市主流生活的边缘地带：或是等待手术的性别认同障碍者，或是武艺高强而深藏不露的夜市摊主，或是卧底追凶的底层保安，或是甘于...', 1);
INSERT INTO `book` VALUES (61, 'https://i.loli.net/2019/04/10/5cada9202d970.jpg', '战争哀歌', '[越]保宁 ', '2019-4', '湖南文艺出版社', '《战争哀歌》超越了战争，战争是它的背景，它的内核是关于逝去的青春，关于美和伤痛！\n\n一场突如其来的战争打碎了阿坚和阿芳这对年轻情侣的生活，在血肉横飞的战争中，主人公阿坚成了幸存者，但战争带来的伤痛还远远没有平息。那些经历仍旧萦绕在阿坚的生活之中，被战争毁灭的不仅 仅是阿坚， 阿芳也遭遇了难以想象的梦魇。时间越长，阿坚越觉得自己不是活着，而是被困在这人世间。', 1);
INSERT INTO `book` VALUES (62, 'https://i.loli.net/2019/04/10/5cada9c852298.jpg', '胡椒的全球史', '[美] 玛乔丽·谢弗 ', '2019-3', '上海三联出版社', '看似不起眼的胡椒，却是家家餐桌必备。在中世纪时，更是欧洲达官显贵们的最爱、财富与地位的象征。黑胡椒原产于印度，距离欧洲各港口有十万八千里之远，取之向来不易。商人们对其供应来源不遗余力的追寻，成为世界史上一股重要的推动力量，促成全球贸易的兴起，重新划定了世界经济版图。', 2);
INSERT INTO `book` VALUES (63, 'https://i.loli.net/2019/04/10/5cada962c287c.jpg', '与病对话', '胡冰霜', '2019-3-31', '北京联合出版公司', '一部融合科普性与趣味性、兼具心理学与哲学意味的医学散文。\n\n一位满怀仁心的资深医者对几十年行医生涯的回望与省思。\n\n全书以真实的病例和鲜活的故事贯穿始终，作者从一位全科医生、心理学者的视角观察、解读疾病与患者身心之关系，厘清大众对诸多常见疾病的误解...', 1);
INSERT INTO `book` VALUES (64, 'https://i.loli.net/2019/04/10/5cada858e6019.jpg', '上帝笑了99次', '[英]彼得·凯弗', '2019-2', '北京联合出版公司', '一只美洲羊驼会坠入爱河吗？机器人能变成人吗？怎样才能不赢得公主青睐？人类一思考，上帝就发笑。在99个奇妙、怪诞、滑稽的问题背后，其实是99个烧脑的哲学、道德、法律领域的经典悖论，也是99道极富挑战性的大思考测试。本书内容覆盖了大多数常见哲学话题，包括形而上学、逻辑学、伦理学、语言哲学、政治哲学、自我认知、人际关系、美学、存在主义等，还配有20多幅漫画插图。在锻炼思维之外，本书也能帮我们建立个性化的哲学知识体系。', 3);
INSERT INTO `book` VALUES (65, 'https://i.loli.net/2019/04/10/5cada8e1aa892.jpg', '互联网算法', '[美] 菲斯曼等 ', '2019-4', '江西人民出版社', '只要你租过房子、上网买过东西、自己经营过企业，那么你就处在商业变革的前线。在这场变革中，亚马逊、谷歌、优步等不同以往的企业取得了史无前例的成功，而促成这场变革的不只是科技进步，还有经济学思想。\n\n在这本趣味横生的书中，我们会看到，经济思想的革命远比科技革命更宏大。从谷歌广告的算法，到网上购物规避欺诈，都要依靠经济学家建立的经济模型，甚至连互联网公司...', 6);
INSERT INTO `book` VALUES (66, 'https://i.loli.net/2019/04/10/5cada9ec514c9.jpg', '七侯笔录', '马伯庸', '2019-4-15', '湖南文艺出版社', '一个关于文化的离奇故事，一段关于文人的壮丽传说。\n\n几千年来，每一位风华绝代的文人墨客辞世之时，都会让自己的灵魂寄寓在一管毛笔之中。他们身躯虽去，才华永存，这些伟大的精神凝为性情不一的笔灵，深藏于世间，只为一句“不教天下才情付诸东流”的誓言。其中最伟大的七位古人，他们所凝聚的七管笔灵，被称为“管城七侯”。\n\n一位不学无术的现代少年，无意中邂逅了李白的青莲笔，命运就此与千年之前的诗仙交织一处，并为他开启了一个叫作笔冢的神秘世界。', 3);
INSERT INTO `book` VALUES (67, 'https://i.loli.net/2019/04/10/5cada9870c2ab.jpg', '中心与边缘', '[美] 希尔斯', '2019-3', '译林出版社', '美国著名社会学家爱德华·希尔斯的主要研究成果包括他对“克里斯玛”、“中心”和“边缘”等概念的解释，以及他对“大众社会”一词的修正，这些研究对分析政治和文化领导力以及社会凝聚力具有重要价值。本书对希尔斯数十载社会理论研究进行了全面而详细的总结，为解释与探究当代社会的结构与变化提供了极具科学性的参考依据。', 3);
INSERT INTO `book` VALUES (68, 'https://i.loli.net/2019/04/10/5cad643643d4c.jpg', '水浒群星闪耀时', '李黎', '2019-4', '上海文艺出版社', '本书以众所周知的梁山英雄为写作对象，重点书写其上山后、招安前的日常生活，涉及他们的喜怒哀乐、同类中人、乡愁怀旧、未来憧憬、命运追问等。书中涉及宋江、武松、鲁智深、李俊、燕青等等耳熟能详的人物而显得有些“改编”与水浒研究的意味，但鉴于所有人物皆为虚构，本书稿的内容是虚构之上的虚构，旨在宏大叙事的语境下突出个人的细微之处和命运感。', 1);
INSERT INTO `book` VALUES (69, 'https://i.loli.net/2019/04/10/5cad63931ce27.jpg', '谋杀狄更斯', '[美] 丹·西蒙斯 ', '2019-4', '上海文艺出版社', '“狄更斯的那场意外灾难发生在1865年6月9日，那列搭载他的成功、平静、理智、手稿与情妇的火车一路飞驰，迎向铁道上的裂隙，突然触目惊心地坠落了。”', 1);
INSERT INTO `book` VALUES (74, 'https://i.loli.net/2019/04/10/5cad63931ce27.jpg', 'hhhh', 'sdaf', 'asdf', 'asdf', 'asf', 5);

-- ----------------------------
-- Table structure for category
-- ----------------------------
DROP TABLE IF EXISTS `category`;
CREATE TABLE `category`  (
  `id` int(11) NOT NULL,
  `name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL,
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of category
-- ----------------------------
INSERT INTO `category` VALUES (1, '文学');
INSERT INTO `category` VALUES (2, '流行');
INSERT INTO `category` VALUES (3, '文化');
INSERT INTO `category` VALUES (4, '生活');
INSERT INTO `category` VALUES (5, '经管');
INSERT INTO `category` VALUES (6, '科技');

-- ----------------------------
-- Table structure for commit
-- ----------------------------
DROP TABLE IF EXISTS `commit`;
CREATE TABLE `commit`  (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `user_id` bigint(20) NULL DEFAULT NULL,
  `commit` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `create_time` datetime(0) NULL DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 1490944221815771139 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of commit
-- ----------------------------
INSERT INTO `commit` VALUES (1485558039284125698, NULL, '果然很沙雕啊', '2022-01-24 18:20:12');
INSERT INTO `commit` VALUES (1485794334669361154, NULL, '这是什么啊', '2022-01-25 09:59:09');
INSERT INTO `commit` VALUES (1485798250261774337, NULL, '我看见一个男人，前几年无忧无虑，逍遥自在，现在他一身烟味，两眼无光，满脸憔悴。我有点心疼他，想伸手摸摸他，却摸到冰冷的镜子。', '2022-01-25 10:14:42');
INSERT INTO `commit` VALUES (1485803006841585666, NULL, '我们只在黄昏时分相爱，你从未与我一起遮挡白日刺眼的阳光，你从未与我一起躲避黑暗刺骨的寒风。你为何只愿与我共享这与世隔绝的夕阳，为何啊？你看我又找不到你了，因为你只存在黄昏里。', '2022-01-25 10:33:36');
INSERT INTO `commit` VALUES (1490944221815771138, NULL, 'sdfgsdfgsfdgfdv', '2022-02-08 15:02:58');

-- ----------------------------
-- Table structure for m_blog
-- ----------------------------
DROP TABLE IF EXISTS `m_blog`;
CREATE TABLE `m_blog`  (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `user_id` bigint(20) NOT NULL,
  `title` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `description` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL,
  `content` longtext CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL,
  `created` datetime(0) NOT NULL,
  `status` tinyint(4) NULL DEFAULT NULL,
  `update_time` datetime(0) NULL DEFAULT NULL,
  `is_delete` tinyint(1) NULL DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 18 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of m_blog
-- ----------------------------
INSERT INTO `m_blog` VALUES (1, 1, '博客', '第三篇博客', 'String str = \"hello\";\r\n        //编码加密\r\n        String encodeStr = Base64.getEncoder().encodeToString(str.getBytes(\"UTF-8\"));\r\n        System.out.println(\"加密后的字符串为:\" + encodeStr);\r\n\r\n        //解码解密\r\n        String decoderStr = new String(Base64.getDecoder().decode(encodeStr), StandardCharsets.UTF_8); //\r\n        // 推荐使用StandardCharsets类指定\r\n        System.out.println(\"解密后的字符串为  \" + decoderStr);', '2022-01-25 18:49:45', 0, '2021-12-02 18:19:16', 1);
INSERT INTO `m_blog` VALUES (3, 1, '人生百态', '时间是一把杀猪刀，刀刀催人老。', '\n## 错把陈醋当成墨，写进半生纸上酸\n#### 人生如棋，落子无悔。\n&emsp;&emsp;&emsp;2017年当我背着书包，拉着行李箱，在姐姐的陪同下前往了北京旁边的燕郊小镇，一个让我欢喜让我优的地方，一个快乐与遗憾并存的地方，也是一个少年开始挥洒青春与热血的地方。在背靠北京这片肥沃的土地上，燕郊一个低调又繁华的小镇，却孕育出了很多所大学，而我即将前往的地点就是其中的一所高校，华北科技学院，一个普通的二本学校，至于我为什么只考上一所普通的二本学校，这还要从高三的那年说起，那一年，也是山东高考制度改革的第一年，将本科合并，从此没有一本和二本之分，正是这个政策的出现让我放掉了自己的戒备，开始了松懈，因为那时我觉得只有本科线了，别人根本就不会知道我有没有考上一本。\n\n&emsp;&emsp;&emsp;还有一点就是当时整个高中都在宣扬高考是改变人生命运的唯一机会，考不上好学校就不能有美好的未来，这让那时叛逆的我觉得难道二本的学生就没有出路吗，我偏不信，于是三年努力的最后一战--高考，考出了我上高中以来最好的成绩（当然是倒数），还记得我们高中班主任跟我说，她第一个查的就是我的成绩，可能令她失望了吧，不过，成绩没考好，还好我心态好。\n\n&emsp;&emsp;&emsp;我用四年的青春加上毕业半年后的求职经历告诉你，好的大学确实有用，如果你考上了一个好的大学，在同学的聚会的时候你可以骄傲的说我是哪个哪个大学 而不会感到自卑，在找工作的时候你确实会受到别样的对待可以得到更好的机会，你的平台你的起点确实要比别人高很多，你如果问我有没有后悔过，我确实后悔过，我曾经很多次梦到我去复读的教室里重新来过。可是人生如棋，落子无悔啊，我能做的只有慢慢的努力去填补当年的叛逆。\n\n#### 大学生活，多姿多彩。\n&emsp;&emsp;&emsp;怀着无比憧憬，无比向往的心情来到了大学。大学的学习氛围相对轻松，浪漫色彩较为浓重是大学里的基调。爱情更是依赖这块沃土肆意滋长，形成一道道绚丽的风景。刚上大一，我加入了很多社团组织，其中有街舞社，国旗护卫队，志愿者，社联，在这些社团、组织里，我认识了很多朋友，也让自己的大学生活变得充实起来，有在国旗护卫队挥洒汗水的热血，也有在街舞社嬉闹的欢乐，也记得当志愿者收垃圾瓶子，看望老人的这样比较有意义的事情。当然还记得在大一的时候也曾喜欢过一个女孩，当时不够勇敢没有去追，后面也没有太多的交集，再后来在2022年1月1日把我qq删了，有些人一旦错过就是永远可人生总是会有遗憾的，你说对吗。\n\n&emsp;&emsp;&emsp;有快乐肯定就有烦恼，在大学里我做过很多的兼职，比如保安，服务员，发传单，后来给别人招人，做家教，这些生活我都体验过，也懂得其中的辛酸苦辣，还记得大一国庆的时候和我朋友一块去做保安的日子，那时候虽然日子过的很苦，但真的很快乐。后来再大二的时候我攒了一些钱，被一个朋友拉去投资某个奶茶店，有些人可能只知道我是随便投点，只有我知道那是我攒下的全部本金，近两万块。只是觉得当时很懦弱，为什么不拿起法律的武器跟他拼命呢。这件事情让我成熟了很多，也明白了很多，下面这句话我觉得很好。\n\n&emsp;&emsp;&emsp;本性善良的人都晚熟，并且他们是被他们是被劣人所催熟的，当别人聪明伶俐时，他们又傻又呆，当别人权衡利弊时，他们一片赤诚，当别人心机用尽时，他们灵魂开窍，后来虽然开窍了，但内心还会保持善良与赤诚，他们不断的寻找同类，但最后变成了孤独的那一个。--莫言《晚熟的人》\n\n## 错把陈墨当成醋，喝尽半生心里苦\n#### 不断尝试，不怕失败。\n&emsp;&emsp;&emsp;emmm,在大学里面我也在一直的尝试一直的选择，在大学四年里一共换了三个专业，在大一的时候我被调剂测绘专业，那是一个我不太喜欢的工科专业，但可笑的是在那一年我还拿了国家奖学金，也有可能是没有涉及到很多专业课的缘由。在大二的时候我如愿的转到了经管学院学国际经济与贸易专业，后来发现这个专业对我来说谈不上多喜欢，但是听起来课，也不觉得讨厌（也有可能是女生比较多一些）。再后来在大三的时候疫情被困在家里，于是开始自学计算机，组装了我了第一台台式机，后来《被》我姐以高价回收，在疫情在家的时间里，我开始自学Java，python，后来自己用python做了一个表白的小工具，视频在b站上，可笑的是，竟找不到人发，再后来就花了很大的精力，金钱去北京培训Java，我仍然记得某一天在去北京培训的路上做错了车，迷了路，当时是零下十几度，是那年北京最冷的一天。有人问你会后悔吗，你当时的努力现在看来并没有很大的回报，甚至是仅仅解决温饱，但我不后悔，我一直觉得大学里面是试错成本最低的，最起码我现在的工作并不会让我觉得讨厌，相反我觉得我能做自己喜欢的事情就够了。\n\n#### 尽人事，听天命\n&emsp;&emsp;&emsp;楚王虽雄难免乌江自刎，汉王虽弱却有万里江山。满腹经纶白发不第，才疏学浅少年登科。有先贫而后富，有先富而后贫，蛟龙未遇潜身于鱼虾之间，君子失时拱手于小人之下，天不得时日月无光，地不得时草木不长，水不得时风浪不止，人不得时利运不通。概人生在世，富贵不能淫，贫贱不能移，威武不能屈，此乃天理循环，终而复始也。\n\n\n\n\n\n\n\n ', '2021-10-01 09:49:11', 0, '2022-01-26 17:21:56', 0);
INSERT INTO `m_blog` VALUES (5, 1, '这是一个测试markdown的文章', '。。。', '**1.草泥马，再不行，老子砸了你.**\n```language\nsout(\"helloworld\")\n```\n\n# 这是一个标题\n\n\n##### 撒旦发射点发生\n[sdfsd](www.chai666.com)\n\n', '2021-12-09 10:02:31', 0, '2021-12-09 10:07:02', 1);
INSERT INTO `m_blog` VALUES (7, 1, '非关系型数据库--redis  01', 'redis-01', '# Redis-01\n\n# 1 淘宝秒杀门\n\n## 1.1 事件回顾\n\n​	2009年9月25日20点整“淘宝网”为庆祝成立6周年发起“一元秒杀”活动，活动商品都是价值数千元的数码类产品，但是20点活动开始之前，有网民发现开拍前这些“一元秒杀”商品被转移，一直持续到20点之后页面才恢复正常，更奇怪的是一些网民竟然能在同时同分同秒同时拍下所有的“一元秒杀”商品，这种行为被网民视为欺诈，网民门到处发帖声讨“淘宝网”，某些网民甚至到315投诉网去投诉，如调查属实，那么此次活动很可能会成为本世纪“受骗”人数最多的“骗局”。\n\n​	晚10点左右淘宝官网给出公告：\n\n```\n	万众瞩目的淘宝商城1元秒杀活动于今晚8：00准时开始后，由于参与淘友过于踊跃，瞬间流量超过了我们的预估值，导致部分网络较拥堵地区的会员不能正常浏览页面，且数据不能及时同步，，令最终秒杀商品数量异常增加。\n	淘宝网决定：对于超出原定数量的成功秒杀会员，只要遵守活动规则、没有作弊行为，淘宝网将承担费用，提供会员秒到商品，以示诚信！\n```\n\n## 1.2 从技术的角度思考\n\n​	这个问题的出现其实主要是因为早期淘宝的技术架构，无法承载过多的流量访问造成的问题，在当时的年代，经常会出现这种问题，比方说2008年中国奥运会的票务平台、12306、京东、聚美优品等等。\n\n客户端-->服务器-->mysql\n\n​	在这种架构下，随着用户访问量的不断增长，**并发读写数据库会成为整个系统性能的瓶颈**。因为数据库是基于磁盘进行数据操作的，因此效率并不能达到非常高。\n\n​	那现在想要提升数据并发读写性能的话，该怎么办呢？ 大家应该知道对于一台计算机来说，从运行速度的角度来说：**CPU>内存>硬盘**。内存的操作效率是非常高的，那我们就想了，能不能在内存中直接完成数据操作呢？ 这里告诉大家是可以的， 要想在内存中直接完成数据操作的话，我们就可以通过Redis来实现。Redis现在在微服务开发中的分量非常重，可以说，它现在已经是一个开发人员的必备技术了。\n\n# 2 Redis概述\n\n## 2.1 Redis介绍\n\nRedis是一款通过C语言实现、基于内存、通过键值对完成数据操作的一款**NoSQL**数据库，也可以称为**非关系型数据库**。\n\n其具备如下几个特点：\n\n**性能极高**：读的速度可达到11W次/s，写的速度可达到8W次/s。\n\n**丰富的数据类型**：String、Hash、List、Set、SortedSet等。\n\n**原子性**：Redis内部使用单线程，可以让所有操作都是原子性的，同时还支持对几个操作全并后的原子性执行。\n\n**持久化**：Redis提供数据持久化机制，尽可能保证数据不丢失。\n\n\n## 2.2 NoSQL介绍\n\n​	NoSQL指的就是**非关系型数据库**。那什么又叫非关系型数据库呢？  大家都知道我们熟悉的MySQL属于关系型数据库。 对于关系型数据库它存在如下的一些问题：\n\n- **并发量巨大时，硬盘IO会成为性能瓶颈。**\n- **表中存在海量数据时，查询效率低下。**\n- **数据模型固定，当要对表结构修改时，成本往往是很巨大的。**\n- **表结构关系复杂，随着数据量的增加，很难通过添加服务器的方式进行横向扩展，往往需要停机维护和数据迁移。**\n- **经常需要进行多表关系查询以及复杂SQL执行，性能较差。**\n\n对于关系型数据库存在的问题，现在则可以通过NoSQL进行解决，其具有如下特点：\n\n- **高并发读写。**\n- **海量数据的高效率存储和访问。**\n- **高扩展性和高可用性。**\n- **灵活的数据模型**\n\nNoSQL数据库一般可以划分为四大类：\n\n- **键值存储**\n- **列存储**\n- **文档数据库**\n- **图形数据库**\n\n| 分类       | 相关产品         | 典型应用                                                     |\n| ---------- | ---------------- | ------------------------------------------------------------ |\n| 键值存储   | Redis、Memcached | 主要用于处理数据的高效访问以及热点数据存储。                 |\n| 列存储     | HBase、Cassandra | 适用于数据量较大且不需要复杂查询条件的应用。如社交消息、游戏日志等。 |\n| 文档数据库 | MongoDB、CouchDB | 适用于存储与查询存在复杂关系的数据，如评论、用户信息等。     |\n| 图形数据库 | Neo4J、InfoGrid  | 社交系统、推荐系统等，主要用于构建关系图谱。                 |\n\n\n\n## 2.3 安装\n\n**1）下载redis镜像**\n\n```yacas\ndocker pull redis:latest\n```\n\n\n\n\n**2）创建目录**\n\n```yacas\nmkdir -p /mydata/redis/data\n```\n\n**3）上传redis.conf到/mydata/redis下**\n 如果需要资料可以加我qq发你\n\n**4）修改redis.conf文件权限**\n\n```yacas\nchmod 777 /mydata/redis/redis.conf\n```\n\n**4）创建Redis容器**\n\n```yacas\ndocker run \\\n--name redis-master \\\n-p 6379:6379 \\\n-v /mydata/redis/data:/data \\\n-v /mydata/redis/redis.conf:/etc/redis/redis.conf \\\n--privileged=true \\\n-d redis:6.0.11 redis-server /etc/redis/redis.conf\n```\n\n**5）查看redis日志**\n\n```yacas\ndocker logs -f myredis\n```\n\n**6）通过redis客户端工具连接测试**\n\n\n# 3 Redis性能测试\n\n## 3.1 压测工具使用\n\n​	之前一直都在说Redis性能有多么多么的优秀，但是口说无凭，现在我们就来对redis进行一下性能测试。\n\n​	Redis官方提供了一个压测工具redis-benchmark。\n\n基本命令如下:\n\n```yacas\nredis-benchmark [option] [option value]\n```\n\n| 选项 | 描述           | 默认值    |\n| ---- | -------------- | --------- |\n| -h   | 指定服务IP     | 127.0.0.1 |\n| -p   | 指定服务端口   | 6379      |\n| -c   | 指定并发连接数 | 50        |\n| -n   | 指定请求数     | 10000     |\n\n操作使用：\n\n```yacas\n#测试1000个客户端发送10W个请求\ndocker exec -it myredis redis-benchmark -c 1000 -n 100000\n```\n\n\n## 3.2 Redis使用单线程为什么这么快\n\n​	redis在通过指令操作数据时使用的是单线程，虽然说最新版redis已经支持了多线程，但是其只是通过多线程优化了网络IO操作，执行命令仍然是单线程的，通过指令的单线程操作从而避免了冲突问题的出现。\n\n​	之前大家对于线程这里可能会存在一个很严重的误区：**系统中开启越多的线程，系统效率就会越高。**\n\n​	这个想法准确来说是错误的。多线程在操作时，会产生线程的上下文切换，这是一个非常耗时的操作。而redis采用单线程对内存进行直接操作，避免出现上下文切换，这种操作的效率是非常高的。\n\n# 4 Redis基本使用\n\n## 4.1 Redis数据库\n\n### 4.1.1 介绍\n\nredis默认存在16个数据库，默认使用0号数据库。每个数据库中不会存在相同的key，但是不同的数据库中可以存在相同的key。\n\n\n\n如果想要配置数据库数量，则可以通过**修改redis.conf中的databases属性**\n\n\n### 4.1.2 指令\n\n#### 4.1.2.1 连接redis客户端\n\n对于Redis客户端的连接可以通过两种方式：Docker、图形化工具\n\n```yacas\n#docker连接redis-cli\ndocker exec -it myredis redis-cli\n```\n\n\n#### 4.1.2.1 切换数据库\n\n语法格式：\n\n```yacas\nselect 数据库索引\n```\n\n使用\n\n```yacas\n#切换到3号数据库\nselect 3\n\n#存储数据\nset name zhangsan\n\n#获取数据\nget name\n\n#切换到5号数据库\nselect 5\n\n#存储数据\nset name zhangsan\n\n#获取数据\nget name\n```\n\n\n**当存储中文时，会出现乱码问题**\n\n\n\n对于该问题的解决，可以通过连接客户端时添加参数`--raw`解决\n\n```yacas\ndocker exec -it myredis redis-cli --raw\n```\n\n\n#### 4.1.2.2 清空数据库\n\n语法格式：\n\n```yacas\nflushdb\n```\n\n## 4.2 常见指令\n\n### 4.2.1 查看当前数据库下所有的key\n\n```yacas\n#语法：keys *\n#介绍：获取所有的key\n```\n\n### 4.2.2 删除指定key\n\n```yacas\n#语法：del key\n#介绍：删除指定key\n```\n\n\n\n### 4.2.3 判断key是否存在\n\n```yacas\n#语法：exists key\n#介绍：1代表存在，0代表不存在\n```\n\n\n\n### 4.2.4 设置数据有效期\n\n```yacas\n#语法：expire key\n#介绍：设置key的有效期，以秒为单位\n```\n\n```yacas\n#数据准备\nset name zhangsan\n\n#对name设置过期时间为5秒\nexpire name 5\n```\n \n\n### 4.2.5 查看数据有效期\n\n```yacas\n#语法：ttl key\n#介绍：查看key的有效期\n```\n\n```yacas\n#数据准备\nset name zhangsan\n\n#对name设置过期时间为10秒\nexpire name 10\n\n#查看有效期\nttl name\n```\n\n\n\n### 4.2.6 取消有效期设置\n\n```yacas\n#语法：persist key\n#介绍：取消key的过期时间，转为永久存在\n```\n\n```yacas\n#数据准备\nset name zhangsan\n\n#设置过期时间10秒\nexpire name 10\n\n#查看过期时间\nttl name\n\n#转为永久存在\npersist name\n```\n\n\n\n# 5 Redis数据类型\n\n## 5.1 五种基本数据类型\n\n### 5.1.1 String\n\n​	String是一种使用非常广泛的数据类型，它能够表达3种值的类型：**字符串**、**整数**、**浮点数**。很多程序员对于redis的使用只是会用String进行数据保存和获取。\n\n#### 5.1.1.1 数据保存\n\n```yacas\n#语法：set key value\n#介绍：保存键值对\n```\n\n使用：**根据id保存商品名称**\n\n```yacas\n#set 商品id 商品名称\nset 128 平板电脑\n```\n\n\n使用：**根据id保存商品对象**\n\n```yacas\n#set 商品id 商品对象（包含商品名称、商品价格）\nset 256 \"{\'name\':\'鼠标\',\'price\':99}\"\n```\n\n\n#### 5.1.1.2 数据获取\n\n命令格式：\n\n```yacas\nget key\n```\n\n使用：**获取商品id获取商品名称**\n\n```yacas\nget 128\n```\n\n\n使用：**根据商品id获取商品对象**\n\n```yacas\nget 256\n```\n\n\n#### 5.1.1.3 数据删除\n\n命令格式：\n\n```yacas\ndel key\n```\n\n使用\n\n```yacas\n#根据key删除数据\ndel 128\n```\n#### 5.1.1.4 值自增与自减\n\n场景分析：\n\n​	以电商为例，每个商品都会存在销量、购买人数等信息。 对于这些信息如果直接基于Mysql来存储的话，在并发读写效率上较差，现在则可以将这部分数据在redis中进行操作。\n\n**1）自增**\n\n```yacas\n#设置初始销量\nset iphone 0\n\n#根据商品名称对销量自增+1\n#语法：incr key\nincr iphone\n\n#确定自增成功\nget iphone\n```\n\n这种场景只会自增一个，但是有时可能一次自增多个，应该怎么办呢？\n\n```yacas\n#设置一次自增10个\n#语法：incrby key 步长值（数量）\nincrby iphone 10\n```\n\n**2）自减**\n\n那现在有增加就会有减少，比方说用户退货了，那这销量是不是就要减少呀\n\n```yacas\n#对iphone的销量扣减\n#语法：decr key\ndecr iphone\n```\n\n根据刚才的演示可以看到，其只会扣减一个，但是如果用户退了多个呢？该怎么办呢？\n\n```yacas\n#对iphone的销量扣减6个\n#语法：decrby key 步长值（数量）\ndecrby iphone 6\n```\n#### 5.1.1.5 设置有效期\n场景分析：\n​	在一些活动场景下，如秒杀、促销、店庆等等。商品都只是在一段时间内有效，那么这个功能应该如何实现呢？\n\n```yacas\n#新增商品并设置有效期\n#语法：setex key seconds(有效期) value\nsetex 666 5 鼠标\n```\n#### 5.1.1.7 保证唯一性\n\n场景分析：\n\n​	以秒杀为例，每个商品肯定只能存在一个呀，那现在有的朋友可能就说了，那这还不容易吗？ 让这些数据都存在于一个redis的数据库中不就可以了。 OK，那我们注意， 如果在同一个数据库中的话，你用key为666存了一条数据，我接着也用key为666存一条数据，数据虽然还是一条，但是我这条数据是不是就把你之前的覆盖了。  \n\n​	而我们现在要保证的是，如果某个key不存在，则正常保存。如果某个key存在，则不执行任何操作。\n\n```yacas\n#保证id为123的数据，多次set只有一次成功\n#语法：setnx key value\nsetnx 123 watch\n\n#多次执行setnx，操作相同的key \nsetnx 123 phone\nsetnx 123 tv\nsetnx 123 computer\n\n#获取值\nget 123\nwatch\n```\n\n#### 5.1.1.8 特殊使用\n\n场景分析：\n\n​	以活动场景，不同的活动下，会存在不同的商品。 根据我们之前的学习，现在可以达到这个需求么？ 明显达不到，截止到现在，都是一个key对应一个value，那这时该怎么办呢？ 我们这时就可以对key使用一种特殊的写法。\n\n​	对于key的编写可以通过`:`冒号进行分层， 什么意思呢？ 我们一起来看下效果\n\n```yacas\n#设置不同活动下的不同商品\nset hd:1:11 tv1\nset hd:1:12 tv2\nset hd:1:13 tv3\n\nset hd:2:21 watch1\nset hd:2:22 watch2\nset hd:2:23 watch3\n```\n在key中通过对冒号的使用，可以进行结构分层， 从而更加利于数据归类。\n\n### 5.1.2 Hash\n\n​	该类型也是一种经常会使用的类型，主要用于数据需要归类的场景下。 基本数据格式： **key field value**。大家可以将其理解为：**key map**结构， 这样的话，相信大家更容易理解。 但是大家要注意，现在想要获取到value值该怎么办？  通过key能直接获取到么？ 不能，我们需要key和field才能最终获取到value。\n\n| 键 | 字段           | 字段的值    |\n| ---- | -------------- | --------- |\n| user  | username     | zhangfei |\n|  user   | password   | 123456     |\n|  user  | age | 23        |\n| user    | sex     | 男     |\n\n\n​	我们以购物车场景为例，完成对Hash类型常用命令的学习。\n\n\n#### 5.1.2.1 添加数据\n\n场景分析：\n\n​	向购物车添加商品\n\n\n```yacas\n#语法：hset key field value\n#考虑每个用户会有自己的购物车，所以key使用冒号形式，拼接userid\n#hset cart:userid（key） 商品id（field） 商品名称（value）\nhset cart:userid:1 1 phone\nhset cart:userid:1 2 watch\nhset cart:userid:1 3 computer\n```\n\n#### 5.1.2.2 获取数据\n\n场景分析：\n\n​	购物车中有了数据后，从购物车中根据商品id获取商品名称\n\n```yacas\n#语法：hget key field\nhget cart:userid:1 3\n```\n\n\n#### 5.1.2.3 获取所有数据\n\n场景分析：\n\n​	刚才只是获取某一个商品，但是正常情况下，当用户点开购物车后，应该获取到其购物车下的所有商品，这又该如何实现呢？\n\n\n```yacas\n#语法：hgetall key\nhgetall cart:userid:1\n```\n\n#### 5.1.2.4 获取数据数量\n\n场景分析：\n\n​	结合淘宝购物车页面来说，需要展示购物车中的商品数量，那么这个数据我们又该如何获取呢？\n\n```yacas\n#语法：hlen key\nhlen cart:userid:1\n```\n\n\n#### 5.1.2.5 删除数据\n\n场景分析：\n\n​	用户可能会将自己购物车中的某个商品删除掉，那这个功能该如何实现呢？\n\n\n```yacas\n#语法：hdel key field\nhdel cart:userid:1 1\n\n#查询数据量\nhlen cart:userid:1\n```\n\n#### 5.1.2.6 判断数据是否存在\n\n场景分析：\n\n​	当用户向购物车中添加商品时，需要判断这个商品在购物车是否存在，如果存在则更新数量，不存在则添加\n\n```yacas\n#语法： hexists key field   1存在 0不存在\nhexists cart:userid:1 3\n```\n\n\n#### 5.1.2.7 获取所有的field\n\n场景分析：\n\n​	用户在对购物车中商品进行结算时，可以会选择全部进行结算。从开发角度来说，我们就只需要获取到所有商品id发送到后台就可以了， 那么这个功能又该如何实现呢？\n\n\n```yacas\n#语法：hkeys key\nhkeys cart:userid:1\n```\n\n\n​	既然能够获取到所有的field，那么能不能获取到所有的value呢？ 当然也是可以的。\n\n```yacas\n#语法：hvals key\nhvals cart:userid:1\n```\n\n\n#### 5.1.2.8 保证数据唯一性\n\n场景分析：\n\n​	在购物车中，会存在店铺信息，如果店铺不存在则添加，如果店铺存在则不添加。保证店铺在购物车中的唯一性。\n\n\n\n```yacas\n#语法：hsetnx key field value  返回1成功0失败\nhsetnx cart:userid:1 shop itheima\n1\nhsetnx cart:userid:1 shop itheima\n0\n```\n\n\n#### 5.1.2.9 应用场景\n\n​	hash结构可以存储 2^32 - 1 键值对（约40多亿）。主要适应于进行对象存储，而且通过它可以很容易的把关系型数据库的表结构存入到redis中。\n\n​	现在有的通过可能会想了，通过String的json也可以存储对象，hash也可以存储对象，那么该选择哪种呢？ 根据开发经验来说，当对象的某个属性需要频繁修改时，如商品的价格、销量、关注数、评价数等，建议通过hash进行存储，它可以针对某个属性单独修改。而如果这些数据通过String的json存储的话，修改起来则很麻烦。 \n\n### 5.1.3 List\n\n​	List是一种基于链表实现的字符串列表，按照插入顺序排序，并且允许存在重复元素。每个列表最多可以存在2^32-1（40多亿）个元素。 其经常用于存储列表输入、或作为队列使用。如秒杀场景下，服务端可能无法同时处理过多请求，则可以通过redis将客户端请求暂存在redis队列中。\n\n\n\n#### 5.1.3.1 插入数据\n\n**1）左侧插入**\n\n\n\n```yacas\n#语法 lpush key value1 [value2]\nlpush lreqlist 192.168.200.151\nlpush lreqlist 192.168.200.152 192.168.200.153 192.168.200.154\n```\n\n\n```yacas\n#获取队列全部数据\n#语法：lrange key start end\nlrange lreqlist 0 -1\n```\n\n\n大家从此处可以看到，遍历时是从头部向尾部遍历，所以先进去后出来，达到栈的效果。\n\n**2）右侧插入**\n\n\n```yacas\n#语法 rpush key value1 [value2]\nrpush rreqlist 192.168.10.11\nrpush rreqlist 192.168.10.12 192.168.10.13 192.168.10.14\n```\n\n\n```yacas\n#获取队列全部数据\nlrange rreqlist 0 -1\n```\n\n\n大家从此处可以看到，因为是从右侧向队列插入，同时从头部遍历，所以先进入的先出来，达到队列的效果。\n\n#### 5.1.3.2 获取列表长度\n\n场景分析：\n\n​	假定当队列中存在超过100个元素，则不再向队列中插入数据。因此在向队列插入请求时，需要获取整个队列长度，并判断是否超过100，没有超过则添加请求。\n\n```yacas\n#语法：llen key\nllen lreqlist\n```\n\n\n#### 5.1.3.3 获取并移除第一个元素\n\n场景分析：\n\n​	现在队列中已经存在了若干的请求，需要将其按顺序从队列中获取出来。\n\n```yacas\n#语法\nlpop key 获取并移出第一个元素\nrpop key 获取并移出最后一个元素\n```\n\n**1）左进左出（栈）先进后出**\n\n\n```yacas\nlpop lreqlist\n```\n\n\n**2）右进右出（栈）先进后出**\n\n\n```yacas\nrpop rreqlist\n```\n\n\n**3）左进右出（队列） 先进先出**\n\n\n```yacas\nrpop lreqlist\n```\n\n\n**4）右进左出（队列） 先进先出**\n\n\n```yacas\nlpop rreqlist\n```\n\n\n#### 5.1.3.4 根据索引获取元素\n\n场景分析：\n\n​	正常排队处理属于公平方式，但是基于非公平的思想，可以提前获取列表中某个请求进行处理。假设现在后端就要指定获取请求2优先处理，这时应该怎么办呢？ list本身是一个链表，那么元素势必会存在索引，因此可以通过索引获取特定元素。从0开始计算\n\n```yacas\n#语法：lindex key index\nlindex lreqlist 2\n```\n#### 5.1.3.5 移除列表元素\n\n场景分析：\n\n​	按照上述需求， 当后端获取到了该请求后，则应该将该请求从队列中删除。现在该怎么做呢。\n\n```yacas\n#语法：lrem key count value\n#当count为正数，是从前往后删。 当count为负数，是从后往前删\n#当count为0，则删除所有指定元素\n#测试数据\nlpush lreqlist 192.168.200.151 192.168.200.151 192.168.200.151 192.168.200.152 192.168.200.153 192.168.200.154 \n\nlrem lreqlist 0 192.168.200.151\n```\n\n\n#### 5.1.3.6 阻塞获取\n\n场景分析：\n\n​	假设redis列表中现在没有元素，但是后端服务要来获取请求，发现没有就过一会再来看有没有，然后继续没有。 大家现在想一下，这样是不是会造成服务端需要经常与redis建立连接通信，比较耗费资源。 而且实时性也不高。 那现在对于这个问题如何解决呢？ \n\n​	我们可以通过列表中提供的**阻塞获取**的方式来进行解决。那什么叫阻塞获取呢？ 当从列表中获取元素时，如果没有则等待，直到有了为止。\n\n**1）从列表中获取第一个请求，如果没有则阻塞等待**\n\n```yacas\n#语法：blpop key1 [key2...] timeout\n```\n\n使用：\n\n```yacas\n#客户端1\nrpush rreqlist 192.168.200.151\n```\n\n```yacas\n#客户端2\nblpop rreqlist 0\n```\n\n```yacas\n#客户端2\nblpop rreqlist 0\n```\n\n```yacas\n#客户端1\nrpush rreqlist 192.168.200.152\n```\n\n当客户端1又插入一条数据后，可以发现客户端2的阻塞消失，并获取到相关数据\n\n**2）从列表中获取最后一个请求，如果没有则阻塞等待**\n\n```yacas\n#语法： brpop key1 [key2...] timeout\n```\n\n这里又大家自行练习，只是获取方向不同而已。\n\n#### 5.1.3.7 向指定位置插入元素\n\n场景分析：\n\n​	大家也都知道，像淘宝，天猫，京东来说，会员都有等级。 那么假设他们在发起一场活动时，比方说：会员节。 后台可能设置会员等级越高的人，秒杀成功几率就越高。 那么我们就可以让会员等级高的人发出的请求，可以插队到会员等级低的人前面。 那么这又该如何实现呢？\n\n\n```yacas\n语法：LINSERT key BEFORE|AFTER pivot（插入点） value（插入值）  在列表的元素前或者后插入元素\n```\n\n使用\n\n```yacas\nrpush rreqlist 192.168.200.151 192.168.200.152 192.168.200.153\nlrange rreqlist 0 -1\n```\n\n现在要把154的请求插入到151前面。\n\n```yacas\nlinsert rreqlist before 192.168.200.151 192.168.200.154\n```\n\n\n#### 5.1.3.8 列表元素转移\n\n场景分析：\n\n​	按照现在的实现方式来说，如果服务端从列表中获取到了这个请求，但是处理的过程中崩溃了，那么这个请求就彻底丢失了，会出现数据处理的混乱，严重降低用户体验度。 \n\n​	现在如果想避免这个问题，应该使用一种更加安全的方式，那怎么来实现一个更安全的队列呢？我们想一想，现在一个队列不安全，我们搞两个行不行。 思路：\n\n- 服务端先从A队列中获取元素，当A队列移出元素时，同时将该元素保存到B队列。\n- 如果服务端处理该请求失败了，它还可以到B队列中获取到这个请求。\n\n其实总的思路很简单，无非就是一个数据备份的思想。\n\n```yacas\n#语法：RPOPLPUSH source destination  \n#介绍：移除列表的最后一个元素，并将该元素添加到另一个列表并返回\n```\n\n```yacas\nRPUSH reqlist 192.168.200.151\nRPUSH reqlist 192.168.200.152\nRPUSH reqlist 192.168.200.153\n\nRPOPLPUSH reqlist reqotherlist\n\nLRANGE reqlist 0 -1\n\nLRANGE reqotherlist 0 -1\n```\n\n### 5.1.4 Set\n\n​	特点：**元素无序、元素唯一**。适用于存储不能重复且不需要顺序的数据。如**关注、粉丝、抽奖等场景**。\n\n\n现在以关注场景为例，完成对Set类型常用命令的学习。\n\n#### 5.1.4.1 添加数据\n\n场景介绍：\n\n​	用户登录后，可以添加自己关注的UP主。\n\n\n```yacas\n#语法：SADD key member [members...]\n#介绍：添加元素 一个或多个\n```\n\n使用\n\n```yacas\nSADD concern:1 java\nSADD concern:1 go python redis rocketmq\n\nsadd concern:2 java redis hive hbase spark\n```\n\n#### 5.1.4.2 获取集合中元素数量\n\n场景分析：\n\n​	在页面上，我们可以看到每个人的关注数量有多少，那么这个数据应该如何获取呢？\n\n```yacas\n#语法：scard key\n#介绍：根据key获取集合中元素数量\n```\n\n```yacas\nscard concern:1\n```\n\n#### 5.1.4.3 获取集合中所有元素\n\n场景分析：\n\n​	知道了查看数量后，有时我们就会很好奇，他都关注了哪些其他人呢？   其实对于这个功能来说，无非就是获取集合中的所有元素。\n\n```yacas\n#语法：smembers key\n#介绍：根据key获取某个集合下的元素列表\n```\n\n```yacas\nsmembers concern:1\n```\n\n#### 5.1.4.4 删除数据\n\n场景分析：\n\n​	对于用户的一些关注， 用户现在可能不想看他了，就会取消对它的关注。\n\n\n```yacas\n#语法：srem key member1 [member2...]\n#介绍：根据key删除一个或多个元素\n```\n\n```yacas\nsrem concern:1 go\n```\n\n\n#### 5.1.4.5 求多集合交集\n\n场景分析：\n\n​	后台需要对用户的关注进行统计分析， 需要获取到多个用户相同的关注。\n\n\n```yacas\nsmembers concern:1\nsmembers concern:2\n```\n\n\n```yacas\n#语法：sinter key1 key2 key3...\n#介绍：求多集合的交集\n```\n\n```yacas\nsinter concern:1 concern:2\n```\n\n\n#### 5.1.4.6 求多集合差集\n\n场景分析：\n\n​	后台需要对用户的关注进行统计分析， 需要获取到多个用户不同的关注。\n\n\n```yacas\nsmembers concern:1\nsmembers concern:2\n```\n\n\n```yacas\n#语法：sdiff key1 key2 key3...\n#介绍：获取第一个集合与其他集合之间的差异\n```\n\n```yacas\nsdiff concern:1 concern:2  #获取concern:1中与concern:2差异化的数据\n```\n\n\n```yacas\nsdiff concern:2 concern:1 #获取concern:2中与concern:1差异化的数据\n```\n\n\n#### 5.1.4.7 求多集合并集\n\n场景分析：\n\n​	后台需要对用户的关注进行统计分析， 需要获取到多个用户所有的关注。\n\n\n```yacas\n#语法：sunion key1 key2 key3...\n#介绍：求多个集合的并集\n```\n\n```yacas\nsunion concern:1 concern:2\n```\n\n\n### 5.1.5 Sortedset\n\n​	Sortedset也被称为Zset。其不同于Set，它是一个有序集合，同时集合中元素是不重复的。它最经典的应用场景就是排行榜。\n\n\n#### 5.1.5.1 添加数据\n\n场景分析：\n\n​	要做排行的话，一定需要先向集合中保存数据。\n\n```yacas\n#语法：ZADD key score1 member1 [score2 member2...]\n#介绍：向集合添加一个或多个成员\n```\n\n```yacas\nzadd ranklist 100 java\nzadd ranklist 99 redis 98 rocketmq 97 rabbitmq 96 sentinel 95 eureka 94 zookeeper\n```\n\n\n#### 5.1.5.2 获取集合元素数量\n\n场景分析：\n\n​	对于排行榜来说，数据数量一般都是有限制的。因此，我们在添加元素时，需要先确定下当前集合中的元素数量。\n\n```yacas\n#语法：zcard key\n#介绍：根据key获取集合中元素数量\n```\n\n```yacas\nzcard ranklist\n```\n\n\n#### 5.1.5.3 按分数排序\n\n场景分析：\n\n​	排行榜的核心功能就是数据排序。在向sortedSet添加数据时，我们设置了score分数， 现在就该发挥它的作用了。\n\n##### 5.1.5.3.1 升序排序\n\n```yacas\n#语法：ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT]\n#介绍：获得集合中指定区间成员，按分数升序排序\n```\n\n```yacas\n#对所有元素按升序排序\nzrangebyscore ranklist -inf +inf WITHSCORES\n```\n\n```yacas\n#显示分数大于等于95的数据\nzrangebyscores ranklist 95 +inf withscores\n```\n\n```yacas\n显示分数大于95,小于等于98的数据\n#如携带小括号则不包括等于，不携带则包括等号\nzrangebyscore ranklist (95 98 withscores\n```\n\n##### 5.1.5.3.2 降序排序\n\n​	有升序的则势必存在降序，那么降序又该如何实现呢？\n\n```yacas\n#语法：zrevrangebyscore key max min [WITHSCORES] [LIMIT]\n#介绍：获得集合中指定区间成员，按分数递减排序\n```\n\n```yacas\nzrevrangebyscore ranklist +inf -inf withscores\n```\n\n#### 5.1.5.4 为元素加分\n\n场景分析：\n\n​	排行榜是根据一些属性实时动态变化的，如点击量、播放量、收藏量等等。所以对于元素的分数也应该动态的进行增加。\n\n```yacas\n#语法：zincrby key increment member \n#介绍：为某个key中的某个元素加分（increment）\n```\n\n```yacas\nzincrby ranklist 10 zookeeper\n```\n\n```yacas\nzrevrangebyscore ranklist +inf -inf withscores\n```\n\n\n#### 5.1.5.5 删除元素\n\n场景分析：\n\n​	排行榜一般都是有长度限制的， 如果末位的元素被超越，则应该将其删除掉。\n\n\n```yacas\n#语法：zrem key mem1 mem2.... \n#介绍：删除集合中指定元素\n```\n\n```yacas\nzrem ranklist eureka\n```\n\n\n## 5.2 三种高级数据类型\n\n### 5.2.1 Geospatial\n\n​	geo是Redis用来处理位置信息的。在Redis3.2中正式使用。主要用于计算距离、地理位置、 **搜索附近人**。\n\n\n\n#### 6.2.2.1 添加地理坐标\n\n场景分析：\n\n​	要获取附近人的话，首先需要先对地理位置进行录入。\n\n```yacas\n#语法：geoadd key longitude(经度) latitude(纬度) member [longitude latitude member ...]\n#介绍：添加地理坐标\n```\n\n访问：http://www.daquan.la/jingwei/   获取地点的经纬度\n\n```yacas\ngeoadd nearinfo 116.401481 40.003264 张三 116.342264 39.951955 李四 116.404355 39.920089 王五\n```\n\n\n\n#### 6.2.2.2 获取成员经纬度\n\n场景分析：\n\n​	我们要进行附近人匹配的话，可以通过获取到各个成员的经纬度进行计算\n\n```yacas\n#语法：geopos key member1 member2... \n#介绍：获取指定成员经纬度\n```\n\n```yacas\ngeopos nearinfo 张三 李四\n```\n\n\n\n#### 6.2.2.3 计算成员间距离\n\n场景分析：\n\n​	一般在搜索附近人的时候，都会限制成员间的距离， 比方说只会显示三公里以内的附近人， 那么这个又该如何实现呢？\n\n```yacas\n#语法：geodist key member1 member2 [m|km|ft|mi]\n#介绍：计算成员间距离\n#m ：米，默认单位。\n#km ：千米。\n#mi ：英里。\n#ft ：英尺。\n```\n\n```yacas\ngeodist nearinfo 张三 李四 km\n```\n\n\n\n#### 6.2.2.4 根据成员查找附近成员\n\n场景分析：\n\n​	通过手动挨个计算距离太麻烦了， 正常来说， 搜索附近人的话， 应该按照我自己的当前位置来搜索附件的人， 那么这个又该如何实现呢？\n\n```yacas\n#语法：georadiusbymember key member 距离值 m|km|ft|mi [WITHCOORD] [WITHDIST] [WITHHASH] [COUNT 数量] [ASC|DESC]\n#介绍：根据成员查找附件的成员，查找某个人在一定距离内的附近人\n```\n\n```yacas\ngeoradiusbymember nearinfo 张三 8 km\n```\n\n\n\n```yacas\ngeoradiusbymember nearinfo 张三 10 km\n```\n\n\n\n在获取附近人的时候，有时可能会限制附近人的数量 以及 按距离进行排序\n\n```yacas\n#数据准备\ngeoadd nearinfo 116.496917 39.955495 狗蛋 116.460697 40.017412 铁蛋 116.326167 39.927172 丫蛋\n\ngeoradiusbymember nearinfo 张三 10 km\n```\n\n\n```yacas\n#需求：获取10公里内，距离张三最近的三个人,升序（从近到远）\ngeoradiusbymemeber nearinfo 张三 10 km withdist count 4 asc\n```\n\n\n### 5.2.2 HyperLogLog\n\nHyperLogLog是Redis 在 2.8.9 版本新增一种数据结构，主要用于做基数统计的算法。适用于统计网站访问量（PV）、UV（网站访客）相关数据。\n\n#### 5.2.2.1 什么是基数\n\n​	所谓的基数，即集合中不重复的元素个数。  假设现在存在一个集合：{1,2,3,4,5,5,4,3,2,1}。那么这个集合的基数就是：5。\n\n#### 5.2.2.2 场景与功能实现分析\n\n​	以UV（网站访客）为例，一个人可以访问某个网站多次，但是其根本上只能算作一个网站访客。 那么现在要来统计UV数量的话，我们想想应该如何实现呢？  给大家个提示： 去重。   那么其实这个功能可以通过set来实现。\n\n**1）通过set实现统计UV数量**\n\n​	当用户访问后，通过set集合保存用户id，然后对set中的元素进行数量统计，即可获取到网站访客数量。 功能实现上非常简单。 但是这并不是最优方案，因为通过set保存大量用户Id的话，会占用大量内存空间，而且集合中的userId本身也没有实际意义，只是用来统计而已。\n\n**2）通过HyperLogLog实现统计UV数量**\n\n​	在redis中，每个HyperLogLog只会占用 12 KB 内存并且空间是固定的，但是其能够存储计算接近 2^64 （18446744073709551616）个不同元素。 这就与set存储形成了鲜明的对比。  但是有得必有失，HyperLogLog在进行数据计算时，存在一定的误差率，官方说存在有0.81%的错误率。 但是对于这种统计PV、UV的场景来说， 这完全是可以接收的。\n\n#### 5.2.2.3 操作指令\n\n##### 5.2.2.3.1 添加数据\n\n```yacas\n#语法：pfadd key element [element ...]\n#介绍：添加指定元素到 HyperLogLog\n```\n\n```yacas\npfadd uvinfo 1 2 3 4 5 6 7 8 9 10 10 8 6 5 3\n```\n\n\n##### 5.2.2.3.2 统计计算\n\n```yacas\n#语法：pfcount key [key ...]\n#介绍：返回给定 HyperLogLog 的基数估算值\n```\n\n```yacas\npfcount uvinfo\n```\n\n### 5.2.3 BitMap\n\n#### 5.2.3.1 场景分析\n\n​	大家也都知道redis是基于内存来保存数据的，因此对于内存空间的使用率则是其非常关注的一点。 那么现在给大家一个需求，记录用户每日的签到信息。我们可以采用redis的哪种数据类型来存储呢？ 通过String、Hash、List、Set都是可以实现这个功能的。 比方说通过String可以这样设置`sign:1:20210225 1`代表签到。 \n\n\n​	但是此时需要注意，一个数字或者一个字母占用一个字节。 虽然一个字节并不大，但是现在如果现在要记录很多用户的签到信息呢？ 积少成多呀。而且这些数据是每天都会增加的。\n\n**计算：现在每天有一千万人签到， 每天就需要10000000个字节。 10000000/1024/1024=9.53mb。 一个月就需要285.9mb。一年就需要3478.45mb 约为3.4G。**\n\n#### 5.2.3.2 概述\n\n​	BitMap是基于位（bit）操作的，因此其只能存储0和1的数据，因此它可以极大的节省存储空间。但是其只适合存储简单结构数据，如状态性信息，比方用户是否签到、用户是否为活跃用户、用户是否在线等等。\n\n**计算：现在每天有一千万人签到 ，每天需要1000000bit。10000000/8=1250000byte/1024/1024=1.19mb。一个月需要35.76mb。一年需要434.35mb。**\n\n#### 5.2.3.2 操作指令\n\n##### 5.2.3.2.1 保存数据\n\n场景分析：\n\n​	当用户点击签到时，需要保存哪个用户在哪一天的签到信息。\n\n\n```yacas\n#语法：setbit key offset value\n#介绍：设置key在offset处的bit值(只能是0或1)\n```\n\n```yacas\n#sign:日期  用户id  是否签到\nsetbit sign:20210225 1 1\nsetbit sign:20210225 2 0\n```\n\n\n##### 5.2.3.2.2 获取数据\n\n场景分析：\n\n​	在签到页面，需要展示用户在某一天是否已经签到\n\n\n```yacas\n#语法：getbit key offset \n#介绍：获得key在offset处的bit值\n```\n\n```yacas\ngetbit sign:userid:1 20200225\n\ngetbit sign:userid:2 20210225\n```\n\n##### 5.2.3.2.3 获取key的bit位为1的个数\n\n场景分析：\n\n​	假设现在需要统计某天已签到的用户数量、或者在线的用户数量等等。 应该如何获取到呢？ \n\n```yacas\n#数据准备\nsetbit 20210225 1 1\nsetbit 20210225 2 1\nsetbit 20210225 3 1\nsetbit 20210225 4 1\nsetbit 20210225 5 1\nsetbit 20210225 6 0\nsetbit 20210225 7 0\n```\n\n```yacas\n#语法：bitcount key\n#介绍：获得key的bit位为1的个数\n```\n\n```yacas\nbitcount 20210225\n```\n\n##### 5.2.3.2.4 操作bitmap AND 、 OR 、 NOT 、 XOR\n\n\n\n# 6 消息通知\n\n## 6.1 概述\n\n​	消息队列大家并不陌生，之前我们也是刚刚学习完。其实Redis也是可以作为消息队列来使用的，它本身提供了发布订阅的功能， 但是使用的很少，因为redis本身的发布订阅有一个非常致命的问题，就是消息无法持久化，也就说如果网络中断、服务器宕机等情况，会造成消息丢失。\n\n​	为了解决这个问题，Redis在5.0版本新增了Stream数据结构。通过它可以来实现一个具备消息持久化特性的消息队列。\n\n## 6.2 操作指令\n\n​	下面我们就来使用Stream相关指令，完成消息的收发。\n\n### 6.2.1 发送消息\n\n```yacas\n#语法：XADD key ID field value [field value ...]\n#介绍：向队列添加消息，如果指定的队列不存在，则创建一个队列\n#key：队列名称\n#ID：消息id 当为*，该值由redis生成，也可以手动指定，但不允许出现重复\n#field value：数据，可以理解为是一个map。\n```\n\n```yacas\n#发送人员对象信息\nxadd queue:user * name lili age 18 sex female\nxadd queue:user * name honghong age 20 sex female\n```\n\n\n### 6.2.2 获取消息总量\n\n```yacas\n#语法：xrange key start end [COUNT]\n#介绍：读取队列中给定ID范围的消息    COUNT：返回消息条数\n```\n\n```yacas\n#获取队列中所有消息\nxrange queue:user - +\n```\n\n\n### 6.2.3 接收消息\n\n```yacas\n#语法：XREAD [COUNT count] [BLOCK milliseconds] STREAMS  [key ...] id [id ...]\n#介绍：从消息队列头部开始读取消息\n\n#key：队列名\n#COUNT：获取几条消息\n#BLOCK：设置接收消息是阻塞还是非阻塞。没有设置就是非阻塞模式  ，时间单位：毫秒\n#key：队列名\n#id：消息id\n```\n\n```yacas\nxread count 1 streams queue:user 0\n```\n\n\n### 6.2.4 删除消息\n\n```yacas\n#语法：xdel key id \n#介绍：根据key删除指定id的消息\n```\n\n```yacas\nxdel queue:user 1614300691164-0\n```\n\n\n\n\n# 7 SpringBoot整合Redis\n\n## 7.1 基础整合\n\n1）导入**/资料/基础工程**\n\n2）修改redis_lesson的pom文件，添加redis依赖\n\n```xml\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-data-redis</artifactId>\n</dependency>\n```\n\n3）修改application.yml，配置redis连接信息\n\n```yml\nspring:\n  redis:\n    host: 192.168.200.151\n    port: 6379\n```\n\n4）添加redis配置类\n\n```java\n@Configuration\npublic class RedisConfig {\n\n    @Bean\n    public RedisTemplate redisTemplate(RedisConnectionFactory redisConnectionFactory){\n        RedisTemplate redisTemplate = new RedisTemplate();\n        redisTemplate.setConnectionFactory(redisConnectionFactory);\n\n        //解决Redis  key的序列化方式\n        redisTemplate.setKeySerializer(new StringRedisSerializer());\n\n        //解决Redis value的序列化方式\n        Jackson2JsonRedisSerializer jackson2JsonRedisSerializer =new Jackson2JsonRedisSerializer(Object.class);\n        ObjectMapper objectMapper = new ObjectMapper();\n        objectMapper.activateDefaultTyping(LaissezFaireSubTypeValidator.instance,ObjectMapper.DefaultTyping.NON_FINAL, JsonTypeInfo.As.WRAPPER_ARRAY);\n        jackson2JsonRedisSerializer.setObjectMapper(objectMapper);\n        redisTemplate.setValueSerializer(jackson2JsonRedisSerializer);\n        redisTemplate.setHashValueSerializer(jackson2JsonRedisSerializer);\n        return redisTemplate;\n    }\n}\n```\n\n5）编写测试类\n\n```java\n@SpringBootTest\n@RunWith(SpringRunner.class)\npublic class RedisTest {\n\n    @Autowired\n    private RedisTemplate redisTemplate;\n\n    //String\n    //添加数据\n    @Test\n    public void addInfo(){\n        redisTemplate.opsForValue().set(\"name\",\"zhangsan\");\n        //设置过期时间\n        redisTemplate.opsForValue().set(\"age\",18,5, TimeUnit.SECONDS);\n    }\n\n    //获取数据\n    @Test\n    public void getInfo(){\n        redisTemplate.opsForValue().get(\"name\");\n    }\n\n    //删除数据\n    @Test\n    public void setExpire(){\n        redisTemplate.delete(\"name\");\n    }\n}\n```\n\n## 7.2 业务实现\n\n场景分析：\n\n​	以商品详情页为例，假设现在客户端有大量请求在查询商品详情信息， 如果直接基于数据库查询的话，则很有可能因为数据库性能问题，造成系统响应速度过慢，甚至宕机。那么此时则可以基于Redis进行改造。 \n\n改造思路如下图所示：\n\n\n```java\n@Service\npublic class GoodsServiceImpl implements GoodsService {\n\n    @Autowired\n    private GoodsMapper goodsMapper;\n\n    @Autowired\n    private RedisTemplate redisTemplate;\n\n    @Override\n    public GoodsEntity findGoodsInfoById(Long goodsId) {\n\n        //先查询缓存\n        GoodsEntity redisGoods = (GoodsEntity) redisTemplate.opsForValue().get(\"goods:\" + goodsId);\n        if (redisGoods!= null){\n            return redisGoods;\n        }\n\n        GoodsEntity goodsEntity = goodsMapper.selectById(goodsId);\n        //存入缓存\n        redisTemplate.opsForValue().set(\"goods:\"+goodsId,goodsEntity);\n\n        return goodsEntity;\n    }\n}\n```', '2021-11-01 11:51:34', 0, '2022-02-08 10:07:51', 0);
INSERT INTO `m_blog` VALUES (8, 1, 'Docker', 'Docker的使用', '# 	Docker\n\n# 1 Docker初体验\n\n​	想必大家之前在学习Linux时，应该装过各种的环境。 比方说Mysql。安装步骤非常繁琐，很痛苦。 \n\n```yacas\nrpm -qa | grep \"mysql\"\nrpm -qa | grep \"mariadb\"\nmkdir /usr/local/mysql\n\ncd /tmp\n\ntar -xvf mysql-5.7.25-1.el7.x86_64.rpm-bundle.tar.gz -C /usr/local/mysql\n\ncd /usr/local/mysql\n\n#执行安装指令， 逐一执行\nrpm -ivh mysql-community-common-5.7.25-1.el7.x86_64.rpm\n\nrpm -ivh mysql-community-libs-5.7.25-1.el7.x86_64.rpm\n\nrpm -ivh mysql-community-devel-5.7.25-1.el7.x86_64.rpm\n\nrpm -ivh mysql-community-libs-compat-5.7.25-1.el7.x86_64.rpm\n\nrpm -ivh mysql-community-client-5.7.25-1.el7.x86_64.rpm\n\nrpm -ivh mysql-community-server-5.7.25-1.el7.x86_64.rpm\n\n#查看初始密码\ncat /var/log/mysqld.log | grep \"temporary password\"\n\n#登录mysql\nmysql -uroot -p\n\n#修改密码\nset global validate_password_length=4;\nset global validate_password_policy=LOW;\nset password = password(\'root\');\n\n#开启访问权限\ngrant all on *.* to \'root\'@\'%\' identified by \'root\';\n\nflush privileges;\n```\n\n那现在能不能简化软件的安装呢，让我们不再那么痛苦呢？ Docker就可以帮助我们解决这方面的烦恼，只需要一个命令，就可以完成Mysql的安装\n\n```yacas\ndocker run --name mysql -p 3306:3306 --privileged=true -ti -e MYSQL_ROOT_PASSWORD=root -e MYSQL_USER=user -e MYSQL_PASSWORD=pass -v /mydata/mysql/3307/conf:/etc/mysql/conf.d -v /mydata/mysql/3307/data/:/var/lib/mysql -v /mydata/mysql/3307/logs/:/var/log/mysql -d mysql:5.7\n```\n\n- **项目环境切换麻烦**\n\n  对于一个系统来说，其从开发到生产，一般都会经历三个环境：开发、测试、生产。但是不同的环境下一定会存在差异，如技术版本。所以很容易出现当环境切换后，项目无法正常运行。\n\n- **服务过多，迁移和扩展太慢**\n\n   对于一个分布式系统来说，经常动不动就几十上百个服务。那么一旦要发布项目时，是一件极为耗时的操作。\n\n- **应用隔离**\n\n  在部署项目时，有时因为服务器数量的问题，很有可能将多个服务部署在同一台机器上。那么一旦某一个服务出现问题，导致CPU占用100%。则其他服务也会受到关联，一起出现问题无法使用。\n\n# 2 Docker概述\n\n\n\n​	Docker 是一个开源的、轻量级、可移植的**容器引擎**，主要运行于 Linux 和 Windows,性能很高。其会对Linux中的若干进程进行隔离，如：Mysql、Nginx、SpringBoot等，而被隔离的进程则被称为**容器**，完全独立于宿主机的进程。\n\n​	官网地址：https://index.docker.io/ \n\n**Docker常用场景：**\n\n- web应用的自动化打包和发布；\n- 自动化测试和持续集成、发布；\n- 在服务环境中部署和调整后台应用；\n- 项目环境统一；\n\n# 3 Docker安装与启动\n\n## 3.1 安装\n\n1）更新yum包\n\n```yacas\nyum update\n```\n\n2）安装需要的软件包\n\n```yacas\nyum install -y yum-utils device-mapper-persistent-data lvm2\n```\n\n3）设置yum源\n\n```yacas\nyum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo\n```\n\n4）查看远程仓库中所有docker版本\n\n```yacas\nyum list docker-ce --showduplicates | sort -r\n```\n\n5）安装docker\n\n```yacas\nyum install docker-ce  #安装最新版\n```\n\n` 如需指定版本，则使用如下命令 yum install <FQPN>  例如：sudo yum install docker-ce-17.12.0.ce `\n\n6）修改Docker远程仓库\n\n​	Docker的使用过程中，需要从远程仓库下载镜像，但是默认为国外网站，所以在下载时会出现下载连接超时导致下载失败，因此需要将远程仓库修改为国内镜像仓库\n\n国内常用的docker镜像仓库\n\n1. Docker官方中国区： https://registry.docker-cn.com\n\n 	2. 阿里云：https://www.aliyun.com/\n 	3. 网易：http://hub-mirror.c.163.com\n 	4. 中国科学技术大学：https://docker.mirrors.ustc.edu.cn\n\n本次使用阿里云镜像\n\n登录阿里云，进入容器镜像服务控制台，找到镜像加速器，操作文档选择CentOS,找到配置镜像加速器，复制运行下面的命令行。使用下面这个命令\n\n\n```yacas\ncat /etc/docker/daemon.json\n```\n出现这句话代表执行成功\n```language\n\"registry-mirrors\": [\"https://nbamvav1.mirror.aliyuncs.com\"]\n```\n\n\n7）启动并加入开机启动\n\n```yacas\nsystemctl start docker\nsystemctl enable docker\n```\n\n8）验证安装是否成功\n\n```yacas\ndocker version\n```\n\n## 3.2 系统指令\n\n### 3.2.1 启动docker服务\n\n```yacas\nsystemctl start docker\n```\n\n### 3.2.2 停止docker服务\n\n```yacas\nsystemctl stop docker\n```\n\n### 3.2.3 重启docker服务\n\n```yacas\nsystemctl restart docker\n```\n\n### 3.2.4 查看docker服务状态\n\n```yacas\nsystemctl status docker\n```\n\n\n\n# 4 Docker应用\n\n​	Docker中核心概念主要有两个，分别为：镜像（Image）、容器（Container）。对于这两个概念的理解，是学习与使用Docker的关键所在。\n\n## 4.1 镜像\n\n​	镜像是一种轻量级、可执行的独立软件包。用于封装应用项目和项目环境。其内部会包含某个软件所需的所有内容，如代码、运行库、配置文件等。镜像是一个静态的概念，不包含任何动态数据，其内容在构建之后也不会被改变。\n\n​	当要进行应用项目的服务器迁移时，只需要将项目和环境封装成一个Docker镜像，然后在指定服务器运行即可。\n\n\n\n### 4.1.1 搜索远程镜像\n\n​	Docker本身提供了很多镜像能够直接使用，在官网直接搜索即可。\n\n\n搜索远程仓库镜像\n\n```shell\ndocker search 镜像名称   #如docker search tomcat\n```\n\n\n**NAME:** 镜像仓库源的名称\n\n**DESCRIPTION:** 镜像的描述\n\n**OFFICIAL:** 是否 docker 官方发布\n\n**stars:** 类似 Github 里面的 star，表示点赞、喜欢的意思。\n\n**AUTOMATED:** 自动构建。\n\n### 4.1.2 查询本地镜像\n\n```shell\ndocker images\n```\n\n**REPOSITORY**：镜像名称 \n\n**TAG**：镜像标签 \n\n**IMAGE ID**：镜像ID \n\n**CREATED**：镜像的创建日期 \n\n**SIZE**：镜像大小\n\n### 4.1.3 从远程仓库拉取镜像\n\n```shell\ndocker pull 镜像名称  #如docker pull tomcat\n```\n\n\n\n### 4.1.4 删除镜像\n\n```shell\n#指定删除镜像\ndocker rmi 镜像名称  #如docker rmi tomcat\n\n#删除本地所有镜像，慎用\ndocker rmi `docker images -q` \n```\n\n\n## 4.2 容器\n\n​	容器是由镜像产生的运行实例，最终在服务器上运行的就是一个个容器。对于容器和镜像的关系，可以理解为Java中的类与对象的关系。\n\n### 4.2.1 查看容器\n\n**1）查看所有容器**\n\n```\ndocker ps -a\n```\n\n**2）查看正在运行的容器**\n\n```\ndocker ps\n```\n\n### 4.2.2 创建并运行容器\n\n​	当拥有了镜像后，就可以根据镜像创建出可运行的容器实例，指令为：`docker run 参数`\n\n**参数说明：**\n\n**-i**：表示运行容器\n\n**-t**：表示容器启动后会进入其命令行。加入这两个参数后，容器创建就能登录进去。即分配一个伪终端。\n\n**--name** :为创建的容器命名。\n\n**-d**：在run后面加上-d参数,则会创建一个守护式容器在后台运行（这样创建容器后不会自动登录容器，如果只加-i -t\n两个参数，创建后就会自动进去容器）。\n\n**-v**：表示目录映射关系（前者是宿主机目录，后者是映射到宿主机上的目录），可以使用多个-v做多个目录或文件\n映射。注意：最好做目录映射，在宿主机上做修改，然后共享到容器上。\n\n**-p**：表示端口映射，前者是宿主机端口，后者是容器内的映射端口。可以使用多个-p做多个端口映射\n\n#### 4.2.2.1 交互式容器\n\n​	所谓交互式容器，即容器创建成功即启动，并直接进入当前容器，当退出容器(exit)时，容器就会进入停止状态。简单理解。即用完就销毁。\n\n​	适用于开发、测试环境或临时性任务。\n\n```shell\n#下载镜像\ndocker pull centos:7\n\n#创建交互式容器 docker run -it --name=自定义的容器名称 镜像名称:镜像tag /bin/bash\ndocker run -it --name=mycentos7 centos:7 /bin/bash\n```\n\n\n\n#### 4.2.2.2 守护式容器\n\n​	所谓守护式容器，即容器创建后，会以后台进行形式运行，不会直接进入容器内部。对于一些需要长期运行的容器，会选择创建守护式容器。\n\n​	适用于生产环境下的应用服务。\n\n```shell\n#创建守护式容器\ndocker run -di --name=mycentos2 centos:7\ndocker run -p 8081:8081 -di --name=jdk8 jdk1.8:latest\ndocker run -p 8080:8080 -di --name=tomcat tomcat:latest\n```\n\n\n```shell\n#启动容器\ndocker start 容器名称|容器id\n```\n\n\n```shell\n#进入容器\ndocker exec -it 容器名称|容器id /bin/bash\ndocker exec -it tomcat /bin/bash\n```\n\n\n```shell\n#停止容器\ndocker stop 容器名称|容器id\n```\n\n\n### 4.2.3 目录挂载\n\n​	在创建容器时，可以将宿主机的目录与容器内的目录进行映射，从而可以通过修改宿主机的目录文件来间接修改容器内文件。\n\n创建容器时添加**-v**参数，格式为：-v 宿主机目录:容器目录，例如： \n\n```shell\ndocker run -di -v /usr/local/test:/usr/local/test --name=mycentos3 centos:7\n```\n\n操作演示：\n\n```shell\n#创建宿主机的挂载目录\nmkdir /usr/local/test\n\n#创建mycentos3容器，并创建宿主机目录与容器目录的映射\ndocker run -di -v /usr/local/test:/usr/local/test --name=mycentos3 centos:7\n\n#宿主机目录下创建文件\ntouch /usr/local/test/demo.txt\n\n#进入容器\ndocker exec -it mycentos3 /bin/bash\n\n#查看容器内映射目录下是否存在相同文件\nll -s /usr/local/test/\n```\n\n\n`注意：如果你共享的是多级的目录，可能会出现权限不足的提示。 这是因为CentOS7中的安全模块selinux把\n权限禁掉了，需要添加参数 --privileged=true 来解决挂载的目录没有权限的问题。`\n\n### 4.2.4 端口映射\n\n​	docker容器在启动的时候，如果不指定端口映射参数，在容器外部是无法通过网络来访问容器内的网络应用和服务的。\n\n```shell\n#下载nginx镜像\ndocker pull nginx\n\n#创建nginx容器，并完成宿主机与容器的80端口映射\ndocker run -di --name=mynginx -p 80:80 nginx\n```\n\n\n\n### 4.2.5 文件拷贝\n\n#### 4.2.5.1 宿主机拷贝到容器\n\n`docker cp 需要拷贝的文件或目录 容器名称:容器目录`\n\n```shell\n#宿主机下创建demo.txt\ntouch demo.txt\n\n#复制demo.txt到mycentos2的容器的 / 目录下\ndocker cp demo.txt mycentos2:/\n\n#进入容器\ndocker exec -it mycentos2 /bin/bash\ndocker exec -it 4773d99b2969 /bin/bash\n\n#查看容器内文件列表\nls -l\n```\n\n\n#### 4.5.2.2 容器拷贝到宿主机\n\n`docker cp 容器名称:容器目录 需要拷贝的文件或目录`\n\n```shell\n#容器内创建abc.txt\ntouch abc.txt\n\n#退出容器\nexit\n\n#将容器内文件拷贝到宿主机指定位置\ndocker cp mycentos2:/abc.txt /opt\n\n#查看宿主机文件列表\nll -s\n```\n\n\n### 4.2.6 查看容器详情\n\n`docker inspect 容器名称`\n\n```shell\ndocker inspect mycentos2\n```\n可以找到该容器的ip\n\n### 4.2.7 查看容器日志\n\n`docker logs -f 容器名称|容器id`\n\n```shell\ndocker logs -f mycentos2\n```\n\n### 4.2.8 删除容器\n\n`删除指定容器：docker rm 容器名称|容器id`\n\n```shell\n#停止容器\ndocker stop mycentos2\n\n#删除容器\ndocker rm mycentos2\n```\n\n# 5 迁移与备份\n\n\n\n涉及到的命令有：\n\n- **docker commit** ：将容器保存为镜像\n- **docker save** ：将镜像备份为tar文件\n- **docker load** ：根据tar文件恢复为镜像\n\n## 5.1 Docker容器保存为镜像\n\n使用docker commit命令可以将容器保存为镜像。\n\n命令形式：**docker commit 容器名称 自定义镜像名称**\n\n```shell\n# 保存nginx容器为镜像\ndocker commit mynginx mynginx\n```\n\n此镜像的内容就是当前容器的内容，可以用此镜像再次运行新的容器\n\n## 5.2 镜像备份\n\n使用docker save命令可以将已有镜像保存为tar 文件。\n\n命令形式：**docker save –o tar 自定义tar文件名 镜像名**\n\n```shell\n# 保存镜像为文件\ndocker save -o mynginx.tar mynginx\n```\n\n## 5.3 镜像恢复与迁移\n\n使用docker load命令可以根据tar文件恢复为docker镜像。\n\n命令形式：**docker load -i tar文件名**\n\n```shell\n# 停止mynginx容器\ndocker stop mynginx\n\n# 删除mynginx容器\ndocker rm mynginx\n\n# 删除mynginx镜像\ndocker rmi mynginx\n\n# 加载恢复mynginx镜像  注意：在执行docker load命令恢复镜像时，需要先删除原镜像。\ndocker load -i mynginx.tar\n\n# 在镜像恢复之后，基于该镜像再次创建启动容器\ndocker run -di --name=mynginx -p 80:80 mynginx\n```\n\n# 6 DockerFile\n\n## 6.1 什么是DockerFile\n\n​	前面的课程中已经知道了，要获得镜像，可以从Docker仓库中进行下载。那如果我们想自己开发一个镜像，那该如何做呢？答案是：Dockerfile\n\n​	Dockerfile其实就是一个文本文件，由一系列命令和参数构成，用于编写docker镜像生成过程。\n\nDockerfile文件内容一般分为4部分：\n\n- 基础镜像信息\n- 维护者信息\n- 镜像操作指令\n- 容器启动时执行的指令\n\n## 6.2 DockerFile常用命令\n\n| 命令       | 用法                                   | 作用                                                         |\n| ---------- | -------------------------------------- | ------------------------------------------------------------ |\n| FROM       | FROM  image_name:tag                   | 指定一个构建镜像的基础源镜像，如果本地没有就会从公共库中拉取，没有指定镜像的标签会使用默认的latest标签，可以出现多次，如果需要在一个Dockerfile中构建多个镜像。 |\n| MAINTAINER | MAINTAINER user_name                   | 描述镜像的创建者，名称和邮箱                                 |\n| RUN        | RUN \"command\" \"param1\" \"param2\"        | 是DockerFile的核心(可以写多条，通过&进行连接)，执行完成之后会成为一个新的镜像。 |\n| USER       | USER daemon                            | 指定运行容器时的用户名或UID，后续的RUN、CMD、ENTRYPOINT也会使用指定的用户运行命令。 |\n| ENV        | ENV key value                          | 设置容器的环境变量，可以写多条。                             |\n| ADD        | ADD source_dir/file                    | 将宿主机的文件复制到容器内，如果是压缩文件，则复制后自动解压 |\n| COPY       | COPY source_dir/file                   | COPY除了不能自动解压，也不能复制网络文件。其它功能和ADD相同。 |\n| EXPOSE     | EXPOSE [...]                           | 设置Docker服务器容器对外映射的容器端口号，在docker run -p的时候生效。 |\n| CMD        | CMD command param1 param2              | 在Dockerfile中只能出现一次，用于在启动容器的时候提供一个默认的命令项，如果用户执行docker run的时候提供了命令项，就会覆盖掉这个命令 |\n| ENTRYPOINT | ENTRYPOINT \"command\" \"param1\" \"param2\" | 和CMD一样，区别是不能被docker run命令的执行命令覆盖，如果要覆盖需要带上选项--entrypoint，如果有多个选项，只有最后一个会生效。 |\n| WORKDIR    | WORKDIR path_dir                       | 设置工作目录                                                 |\n\n## 6.3 基于Dockerfile创建自定义镜像\n\n```shell\n# 1、创建目录\nmkdir –p /usr/local/dockerjdk8\ncd /usr/local/dockerjdk8\n  \n# 2、下载jdk-8u241-linux-x64.tar.gz并上传到服务器（虚拟机）中的/usr/local/dockerjdk8目录\n# 3、在/usr/local/dockerjdk8目录下创建Dockerfile文件，文件内容如下：\nvi Dockerfile\n\nFROM centos:7\nMAINTAINER ACHAI\nWORKDIR /usr\nRUN mkdir /usr/local/java\n\nADD jdk-8u241-linux-x64.tar.gz /usr/local/java/	\nADD apache-tomcat-8.5.72.tar.gz /usr/local/java/	\n\nENV JAVA_HOME /usr/local/java/jdk1.8.0_241\nENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\nENV CATALINA_HOME /usr/local/java/apache-tomcat-8.5.72\nENV CATALINA_BASE /usr/local/java/apache-tomcat-8.5.72\nENV PATH $PATH:$JAVA_HOME/bin:$CATALINA_HOME/lib:$CATALINA_HOME/bin\n\n#ENV PATH $PATH:$JAVA_HOME/bin\n\n#把java与tomcat添加到容器中\nADD jdk-8u31-linux-x64.tar.gz /usr/local/\nADD apache-tomcat-8.5.72.tar.gz /usr/local/\n \n#配置java与tomcat环境变量\nENV JAVA_HOME /usr/local/jdk1.8.0_31\nENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n\nENV CATALINA_HOME /usr/local/java/apache-tomcat-8.5.72\nENV CATALINA_BASE /usr/local/java/apache-tomcat-8.5.72\nENV PATH $PATH:$JAVA_HOME/bin:$CATALINA_HOME/lib:$CATALINA_HOME/bin\n\n\n#设置tomcat 自启动\nCMD [\"/usr/local/java/apache-tomcat-8.5.72/bin/catalina.sh\",\"run\"]\n\n\n# 4、执行命令构建镜像；不要忘了后面的那个 .\ndocker build -t=\'jdk1.8\' .\n\ndocker build -t=\'mytomcat\' .\n\n\n# 5、查看镜像是否建立完成\ndocker images\n```\n\n\n测试：\n\n```shell\n# 创建并启动容器\ndocker run -di --name=myjdk jdk1.8 /bin/bash\ndocker run -p 8080:8080 -di --name=tomcat mytomcat:latest\n#容器内查看java版本\njava -version\n```\n\n\n\n# 7 可视化管理工具-Portainer\n\n​	Portainer是Docker的图形化管理工具，提供状态显示面板、应用模板快速部署、容器镜像的基本操作（包括上传下载镜像，创建容器等操作）、事件日志显示、容器控制台操作、登录用户管理和控制等功能。功能十分全面，基本能满足中小型单位对容器管理的全部需求。\n\n## 7.1 安装与启动\n\n官方安装教程： https://www.portainer.io/installation/\n\n```shell\n#创建文件存储文件\ndocker volume create portainer_data\n\n#创建并启动容器\ndocker run -d -p 9000:9000 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer\n```\n\n`--restart=always   开机自动启动`\n\n访问：ip:9000   第一次登陆需要设置登陆密码，密码不得少于8位\n\n\n**选择管理本地docker还是远程。此处选择暂选Local**,之后点击connect\n\n\n\n## 7.2 容器信息查看\n\n**查看本地Docker服务器的列表信息**\n\n\n\n**选择一个Docker服务，即可查看其内部的详情信息，如镜像、容器等**\n\n这里面可以选择将镜像变成容器，也可以对镜像和容器进行删除，创建等功能。\n\n\n\n', '2021-10-20 11:57:04', 0, '2022-01-26 14:23:31', 0);
INSERT INTO `m_blog` VALUES (9, 1, '非关系型数据库--redis 02', 'redis-02', '# Redis-02\n\n# 1 事务机制\n\n## 1.1 场景分析\n\n​	以关注为例，在B站上我关注了你，同时你也关注了我，那么两者之间就形成了互相关注，互为粉丝的关系。\n\n​	如果要通过Redis描述这种关系的话，最好的数据类型就是set， 每个用户定义两个set集合，分别用于描述我的关注和我的粉丝：\n\n```yacas\n#我的关注 user:用户id:concern 被关注的用户id\n#我的粉丝 user:用户id:fans 粉丝用户id\n\n#黑马程序员用户为1001 ， 传智教育用户id为1002\nsadd user:1001:concern 1002\nsadd user:1001:fans 1002\n\nsadd user:1002:concern 1001\nsadd user:1002:fans 1002\n```\n\n​	但是假设在执行四条指令的过程中，某一条指令出现错误运行失败，就会有可能出现A关注了B，而B的粉丝里没有A，以及相类似的情况。\n\n## 1.2 事务介绍\n\n​	Redis是支持事务的， 对于上述问题可以通过事务控制解决。 举一个事务的经典例子：转账。A给B汇款，那么A账户会扣钱，B账户会加钱。  这两个步骤一定会存在于一个事务中，要么都成功，要么都失败。\n\n​	Redis事务是基于队列实现的，创建一个事务队列，然后将事务操作都放入队列中，最后依次执行。\n\n\n\n\n```yacas\n#开启事务\nmulti\n\n#添加命令\nsadd user:1001:concern 1002\nsadd user:1002:concern 1001\n\n\nsadd user:1001:fans 1002\nsadd user:1002:fans 1002\n\n#执行事务\nexec\n```\n\n\n## 1.3 事务处理机制\n\n​	假设这四条指令在事务执行中，某一条命令执行出错， 此时事务会如何处理呢？ 现在可能很多人会说，刚才不是已经说了嘛，要么都成功，要么都失败， 有一个出错，那就都失败呗。 \n\n​	这么想不能算错，但只是对于事务理解的皮毛。 Redis对于命令执行错误处理，有两种解决方式： **语法错误**、**执行错误**。\n\n### 1.3.1 语法错误\n\n​	语法错误：**执行命令的语法不正确**。\n\n```yacas\n#开启事务\nmulti\n\n#命令\nset name zhangsan\nset age\nseterror sex male\n\n#执行事务\nexec\n\n#获取正确指令数据\nget name\n```\n\n\n​	此时整个事务队列中，存在**一条正确指令，两条语法错误指令**， 当执行exec后，会直接返回错误，正确的命令也不会执行。\n\n### 1.3.2 执行错误\n\n​	执行错误：**命令在运行过程中出现错误**。\n\n```yacas\n#开启事务\nmulti\n\n#命令\nset lesson java\nrpush lesson eureka feign nacos\nset lesson redis\n\n#执行事务\nexec\n\n#获取数据\nget lesson\n```\n\n\n​	通过上面事务执行可以看到，语法本身是没有问题的，所以运行之前redis无法发现错误，但是在执行时出现了错误，因此只会错误的命令不执行， 而正确的命令仍然能够正常执行。 \n\n## 1.4 SpringBoot实现事务操作\n\n1）修改RedisConfig配置类，开启事务控制\n\n```java\n//开启redis事务控制\nredisTemplate.setEnableTransactionSupport(true);\n```\n\n2）自定义方法，测试事务效果\n\n```java\n@Test\n@Transactional(rollbackFor = Exception.class)\npublic void multiTest(){\n    //开启事务\n    redisTemplate.multi();\n    try{\n        redisTemplate.opsForValue().set(\"lesson\",\"java\");\n        redisTemplate.opsForSet().add(\"lesson\",\"eureka\",\"feign\",\"gateway\");\n        redisTemplate.opsForValue().set(\"lesson\",\"redis\");\n        System.out.println(redisTemplate.opsForValue().get(\"lesson\"));\n    }catch (Exception e){\n        //回滚\n        System.out.println(\"出现异常\");\n        redisTemplate.discard();\n    }finally {\n        redisTemplate.exec();\n    }\n}\n}\n```\n\n# 2 持久化机制\n\n## 2.1 场景分析\n\n​	Redis将数据保存在内存中。一旦服务器宕机重启，内存中的数据就会丢失。当出现这种情况后，为了能够让Redis进行数据恢复，因此\n\nRedis提供了持久化机制，将内存中的数据保存到磁盘中，避免数据意外丢失。\n\n​	Redis提供了两种持久化机制：**RDB**、**AOF**。 根据不同的场景，可以选择只使用其中一种或一起使用。\n\n## 2.2 RDB\n\n### 2.2.1 概述\n\n​	RDB（Redis DataBase）是Redis默认存储方式。其基于快照思想，当符合一定条件（手动或自动触发）时，Redis会将这一刻的内存数据进行快照并保存在磁盘上，产生一个经过压缩的二进制文件，文件后缀名.rdb。\n\n\n​	因为RDB文件是保存在磁盘上的，因此即使Redis进程退出，甚至服务器宕机重启。只要RDB文件存在，就可以利用它来还原Redis数据。\n\n### 1.2.2 RDB触发条件\n\n#### 1.2.2.1 符合配置文件中的快照规则\n\n​	在redis.conf文件中配置了一些默认触发机制。\n\n```yacas\nsave \"\"  # 不使用RDB存储  不能主从\n\nsave 900 1     #表示15分钟（900秒钟）内至少1个键被更改则进行快照。\nsave 300 10    #表示5分钟（300秒）内至少10个键被更改则进行快照。\nsave 60 10000  #表示1分钟内至少10000个键被更改则进行快照。\n```\n\n\n#### 1.2.2.2 手动执行save或bgsave命令\n\n​	在redis客户端执行save或bgsave命令，手动触发RDB快照。\n\n```yacas\n#进入客户端\ndocker exec -it myredis redis-cli\n\n#执行save命令\nsave\n\n#执行bgsave命令\nbgsave\n```\n\n那么这两个命令都会触发快照的话，他们两个又有什么区别呢？\n\n**save：**同步处理，阻塞Redis服务进程，服务器不会处理任何命令，直到RDB文件保存完毕。\n\n**bgsave：**会创建一个子线程负责操作RDB文件，不会阻塞Redis服务进程，操作RDB文件的同时仍然可以处理命令。\n\n#### 1.2.2.3 执行flushall命令\n\n```yacas\n#刷新redis\nflushall\n```\n\n### 1.2.3 执行过程\n\n\n1）Redis服务进程判断，当前是否有子线程在执行save或bgsave。\n\n2）如果有，则直接返回，不做任何处理。\n\n3）如果没有，则以阻塞式创建子线程，在创建子线程期间，Redis不处理任何命令。\n\n4）创建完子线程后，取消阻塞，Redis服务继续响应其他命令。\n\n5）同时基于子线程操作RDB文件，将此刻数据保存到磁盘。\n\n### 1.2.4 优缺点\n\n**优点：**\n\n- 基于二进制文件完成数据备份，占用空间少，便于文件传输。\n- 能够自定义规则，根据Redis繁忙状态进行数据备份。\n\n**缺点：**\n\n- 无法保证数据完整性，会丢失最后一次快照后的所有数据。\n- bgsave执行每次执行都会阻塞Redis服务进程创建子线程，频繁执行影响系统吞吐率。\n\n## 2.3 AOF\n\n### 2.3.1 概述\n\n​	RDB方式会出现数据丢失的问题，对于这个问题，可以通过Redis中另外一种持久化方式解决：**AOF**。\n\n​	AOF（append only file）是Redis提供了另外一种持久化机制。与RDB记录数据不同，当开启AOF持久化后，Redis会将客户端发送的所有更改数据的命令，记录到磁盘中的AOF文件。 这样的话，当Redis重启后，通过读取AOF文件，按顺序获取到记录的数据修改命令，即可完成数据恢复。\n\n\n​	举个例子，对Redis执行三条写命令：\n\n```yacas\nset name itheima\n\nhset cart shop nike\n\nsadd lesson java python hadoop\n```\n\n​	RDB会将name、cart、lesson三个键值对数据进行保存，而AOF会将set、hset、sadd三个命令保存到AOF文件中。\n\n### 2.3.2 基础使用\n\n​	AOF方式需要手动开启，修改**redis.conf**\n\n```yacas\n# 是否开启AOF，默认为no\nappendonly yes\n\n#设置AOF文件名称\nappendfilename  appendonly.aof\n```\n\n\n当开启了AOF机制之后，Redis何时会向aof文件中记录内容呢？\n\n对于AOF的触发方式有三种：**always**、**everysec**、**no**。 默认使用everysec。可以通过redis.conf中appendfsync属性进行配置。\n\n那么这三种参数各自都代表什么意思呢？ 为什么默认使用everysec呢？这里我们做一个预留，因为涉及到一些其他知识，后面再给大家详细介绍。\n\n开启AOF后，重启Redis，进入Redis客户端并执行多条写命令，这些命令会被保存到appendonly.aof文件中。\n\n```yacas\nset name zhangsan\nset age 18\nset sex male\nget name\nget age\nget sex\n```\n\n此时查看**redis/data**目录，会新产生一个appendonly.aof文件。 查看文件内容\n\n```yacas\n*2\n$6\nSELECT\n$1\n0\n*3\n$3\nset\n$4\nname\n$8\nzhangsan\n*3\n$3\nset\n$3\nage\n$2\n18\n*3\n$3\nset\n$3\nsex\n$4\nmale\n```\n\n​	通过文件查看，可以看到，在aof文件中，记录了对redis操作的所有写命令，读命令并不会记录。\n\n### 2.3.3 执行原理\n\n​	AOF功能实现的整个执行过程可以分为三个部分：**命令追加**、**文件写入**、**文件同步**。\n\n\n1）客户端向Redis发送写命令。\n\n2）Redis将接收到的写命令保存到缓冲文件**aof_buf的末尾**。 **这个过程是命令追加。**\n\n3）redis将缓冲区文件内容写入到AOF文件，**这个过程是文件写入**。\n\n4）redis根据策略将AOF文件保存到磁盘，**这个过程是文件同步。**\n\n5）何时将AOF文件同步到磁盘的策略依据就是**redis.conf**文件中**appendfsync**属性值：**always**、**everysec**、**no**\n\n- **always**：每次执行写入命令都会将aof_buf缓冲区文件全部内容写入到AOF文件中，并将AOF文件同步到磁盘。该方式效率最低，安全性最高。\n- **everysec**：每次执行写入命令都会将aof_buf缓冲区文件全部内容写入到AOF文件中。 并且每隔一秒会由子线程将AOF文件同步到磁盘。该方式兼备了效率与安全，即使出现宕机重启，也只会丢失不超过两秒的数据。\n- **no**：每次执行写入命令都会将aof_buf缓冲区文件全部内容写入到AOF文件中，但并不对AOF文件进行同步磁盘。 同步操作交由操作系统完成（每30秒一次），该方式最快，但最不安全。\n\n| 模式     | aof_buf写入到AOF是否阻塞 | AOF文件写入磁盘是否阻塞 | 宕机重启时丢失的数据量              | 效率 | 安全 |\n| -------- | ------------------------ | ----------------------- | ----------------------------------- | ---- | ---- |\n| always   | 阻塞                     | 阻塞                    | 最多只丢失一个命令的数据            | 低   | 高   |\n| everysec | 阻塞                     | 不阻塞                  | 不超过两秒的数据                    | 中   | 中   |\n| no       | 阻塞                     | 阻塞                    | 操作系统最后一次对AOF写入磁盘的数据 | 高   | 低   |\n\n### 2.3.4 AOF重写优化\n\n#### 2.3.4.1 概述\n\n​	AOF会将对Redis操作的所有写命令都记录下来，随着服务器的运行，AOF文件内保存的内容会越来越多。这样就会造成两个比较严重的问题：**占用大量存储空间**、**数据还原花费的时间多**。\n\n​	举个例子：\n\n```yacas\nsadd lessons java\nsadd lessons python go\nsadd lessons hive\nsadd lessons hadoop rocketmq\nsadd lessons redis\n```\n\n​	当这些命令执行完，AOF文件中记录5条命令。但是实际生产环境下，写命令会出现非常多，文件的体积也会非常庞大。\n\n​	为了解决AOF文件巨大的问题，Redis提供了AOF文件重写功能。 当AOF文件体积超过阈值时，则会触发AOF文件重写，Redis会开启子线程创建一个新的AOF文件替代现有AOF文件。 新的AOF文件不会包含任何浪费空间的冗余命令，只存在恢复当前Redis状态的最小命令集合。\n\n#### 2.3.4.2 触发配置\n\n​	那么AOF文件达到多大时，会对其进行重写呢？   对于重写阈值的配置，可以通过修改redis.conf进行配置。\n\n```yacas\n#当前aof文件大小超过上一次aof文件大小的百分之多少时进行重写。如果之前没有重写过，以\n启动时aof文件大小为准\nauto-aof-rewrite-percentage 100\n\n#限制允许重写最小aof文件大小，也就是文件大小小于64mb的时候，不需要进行优化\nauto-aof-rewrite-min-size 64mb\n```\n\n​	除了让Redis自动执行重写外，也可以手动让其进行执行：`bgrewriteaof`\n\n\n执行`bgrewriteaof`手动进行aof文件重写。重写后内容如下：\n\n\n## 2.4 RDB与AOF对比\n\n1. RDB默认开启，AOF需手动开启。\n2. RDB性能优于AOF。\n3. AOF安全性优于RDB。\n4. AOF优先级高于RDB。\n5. RDB存储某个时刻的数据快照，AOF存储写命令。\n6. RDB在配置触发状态会丢失最后一次快照以后更改的所有数据，AOF默认使用everysec，每秒保存一次，最多丢失两秒以内的数据。\n\n## 2.5 生产环境下持久化实践\n\n1. 如当前只追求高性能，不关注数据安全性，则关闭RDB和AOF，如redis宕机重启，直接从数据源恢复数据。\n2. 如需较高性能且关注数据安全性，则开启RDB，并定制触发规则。当开启RDB后发现，Redis数据量过多，服务线程被频繁阻塞，造成系统性能严重下降，则开启AOF。\n3. 如更关注数据安全性，则开启AOF。\n\n# 3 主从复制\n\n## 3.1 概述\n\n​	通过持久化机制的学习， 可以发现，不管是RDB还是AOF，都并不能百分百的避免数据丢失。关键是现在只有一台服务器，持久化数据都是保存在这台服务器的磁盘上，假设这台服务器的磁盘损坏，数据仍然会全部丢失。 那这个问题该怎么解决呢？\n\n​	那我们想一下，现在所有持久化数据只是保存在一台服务器上，能不能让它们同时保存在多台服务器上，这样即使一台服务器出现问题，仍然可以从其他服务器同步数据。\n\n​	这样就需要当一台服务器中数据更新后，可以自动的将更新的数据同步到其他服务器上， 这就是所谓的复制。\n\n\n## 3.2 复制搭建&使用\n\n​	\n1）参照day01搭建第二台redis容器，端口为：6380。作为从机。\n\n2）连接端口为6380的redis客户端\n\n```yacas\ndocker exec -it myredisslave redis-cli -p 6380\n```\n\n3）连接端口为6379的主节点redis\n\n```yacas\nslaveof 192.168.200.151 6379\n```\n\n\n4）主节点存储数据\n\n```yacas\n#存储数据\nset company itheima\n```\n\n\n5）从节点获取数据\n\n```yacas\n#获取数据\nget company\n```\n\n\n## 3.3 生产环境下主从复制实践\n\n### 3.3.1 读写分离\n\n​	在生产环境下，读请求会远远多于写请求，大概10:1的比率。 当单机无法应对大量读请求时，可以通过主从复制机制，实现读写分离。主节点只负责写请求，从节点只负责读请求。\n\n\n### 3.3.2 持久化优化\n\n现在如果master和所有的slave都开启持久化的话，性能相对来说比较低。该如何优化提升性能呢？\n\n我们可以在**从节点上开启持久化、在主节点关闭持久化**。 但是这样的话，数据不会丢失吗？\n\n在主从复制的结构下，无非要么主节点宕机，要么从节点宕机。\n\n- 当从节点宕机重启后，主节点会自动的将数据同步到从节点上。所以不会出现数据丢失。  \n- 当主节点宕机后，可以将从节点提升为主节点(**slaveof no one**)，继续对外提供服务。 并且当原先的主节点重启后，使用slaveof命令将其设置为新主节点的从节点，即可完成数据同步。\n\n```yacas\n#中断端口为6379的redis服务进程\ndocker stop myredis\n\n#将6380从节点提升为新的主节点\nslaveof no one\n\n#在6380节点添加数据\nsadd lessons java redis rocketmq\n\n#启动6379节点\ndocker start myredis\n\n#将6379节点作为从节点连接到新的主节点6380\ndocker exec -it myredis redis-cli\nslaveof 192.168.200.151 6380\n\n#6379节点获取断开连接期间数据\nsmembers lessons\n```\n\n​	现在可能有人在想，那要是主节点和从节点同时宕机了呢？ 数据这不还是会丢吗？  首先服务器宕机的问题本身出现的几率就非常低，并且采用合理的部署方式，如异地部署。 主节点和从节点同时宕机的几率更是微乎其微的。\n\n# 4 过期删除策略\n\n​	看到过期删除策略，大家现在脑袋里面可能会想为什么要学这个？ 这有什么好说的，之前不是已经学过EXPIRE命令了， 给key设置过期时间，到期了不就删除了吗？  \n\n​	大家这个想法是没有任何问题的， 但是，绝对没有大家想象的那么简单。我们现在思考一个问题：**如果一个key过期了，那么它实际是在什么时候被删除的呢？** \n\n​	可能很多同学的答案是： **到期了就直接被删除了**。 但是这里告诉大家，这个答案是错误的。\n\n​	这就需要给大家介绍下，Redis中对于过期键的过期删除策略：\n\n- 定时删除\n- 惰性删除\n- 定期删除\n\n下面我就来逐一学习这三种过期删除策略的工作机制。\n\n## 4.1 定时删除\n\n​	它会在设置键的过期时间的同时，创建一个定时器， 当键到了过期时间，定时器会立即对键进行删除。  这个策略能够保证过期键的尽快删除，快速释放内存空间。  \n\n\n​	 但是有得必有失。 Redis的操作频率是非常高的。绝大多数的键都是携带过期时间的，这样就会造成出现大量定时器执行，严重降低系统性能。\n\n​	总的来说：**该策略对内存空间足够友好， 但对CPU非常不友好，会拉低系统性能，因此不建议使用。**\n\n## 4.2 惰性删除\n\n​	为了解决定时删除会占用大量CPU资源的问题， 因此产生了惰性删除。\n\n​	**它不持续关注key的过期时间， 而是在获取key时，才会检查key是否过期，如果过期则删除该key。**简单来说就是：平时我不关注你，我用到你了，我才关注你在不在。 \n\n\n​	根据惰性删除来说，大家感觉它存在什么问题呢？\n\n​	虽然它解决了定时删除会占用大量CPU资源的问题， 但是它又会造成内存空间的浪费。假设Redis中现在存在大量过期key，而这些过期key如果都不被使用，它们就会保留在redis中，造成内存空间一直被占用。\n\n​	总的来说：**惰性删除对CPU足够友好，但是对内存空间非常不友好，会造成大量内存空间的浪费**。\n\n## 4.3 定期删除\n\n​	根据刚才的学习大家可以发现，不管是定时删除还是惰性删除优缺点都非常明显：\n\n- 定时删除对内存空间友好，对CPU不友好。\n- 惰性删除对CPU友好，对内存空间不友好。\n\n那现在有没有一种策略，能够平衡这两者的优缺点呢？  因此出现了定期删除。\n\n### 4.3.1 工作机制\n\n​	定期删除，顾名思义，就是每隔一段时间进行一次删除。 那么大家想一下，应该隔多久删一次？ 一次又删除多少过期key呢？\n\n- 如果删除操作执**行次数过多**、**执行时间过长**，就会导致和定时删除同样的问题：**占用大量CPU资源去进行删除操作**。\n- 如果删除操作执**行次数过少**、**执行时间过短**，就会导致和惰性删除同样的问题：**内存资源被持续占用，得不到释放**。\n\n所以定期删除最关键的就在于执行时长和频率的设置。\n\n\n- 默认每秒运行10次会对具有过期时间的key进行一次扫描，但是并不会扫描全部的key，因为这样会大大延长扫描时间。\n- 每次默认只会随机扫描20个key，同时删除这20个key中已经过期的key。\n- 如果这20个key中过期key的比例达超过25%，则继续扫描。\n\n### 4.3.2 参数配置\n\n​	默认每秒扫描10次，对于这个参数能不能手动调整呢？ \n\n​	当然是可以的，只需要修改**redis.conf**中的**hz**参数即可。\n\n对于hz参数，官方建议不要超过100，否则会对CPU造成比较大的压力。\n\n# 5 内存淘汰策略\n\n## 5.1 为什么需要内存淘汰策略\n\n学习完过期删除策略后， 大家思考两个问题：\n\n- **通过惰性+定期删除，能不能百分百避免过期key没有被删除的情况？**   \n- **当大量插入插入到Redis，但内存空间不足时，Redis会如何处理呢？**\n\n举个例子： \n\n**有一些已经过期的key，定期扫描一直都没有扫描到它，而且这些key也一直没有被使用。 那么它们就会一直在内存中存在。同时继续向Redis不断插入新数据，最终造成内存空间不足的问题。**\n\n​	对于这种问题的解决，就用到了**内存淘汰策略**。\n\n## 5.2 最大内存参数配置\n\n那么现在有的同学可能会想，那我把内存空间设置的很大不就可以了。 ok，你可以把它设置的大一些，但是怎么设置呢？\n\n修改**redis.conf**中的**maxmemory <bytes>** 来设置最大内存。\n\n\n在64位操作系统中，如果未设置或设置0，代表无限制。而在32位系统中，默认内存大小为3GB。但是实际生产环境下，一般会设置**物理内存的四分之三**左右。\n\n## 5.3 策略详解\n\n​	**当客户端执行命令，添加数据时，Redis会检查内存空间大小，如超过最大内存，则触发内存淘汰策略**。 \n\n\n在Redis中默认提供了三类八种淘汰策略。\n\n​	对于这些策略各自的含义，我们还需要一点前置知识的铺垫，这里我们可以看到两个名称：**lru**、**lfu**，他俩是什么意思呢？\n\n他们的学名叫做：**数据驱逐策略**。 其实所谓的**驱逐就是将数据从内存中删除掉**。\n\n- **lru：**Least Recently Used，它是以**时间**为基准，删除最近**最久**未被使用的key。\n- **lfu：**Least Frequently Used，它是以**频次**为基准，删除最近**最少**未被使用的key。\n\n那理解了lru和lfu之后，我们再回来看这三类八种内存淘汰策略各自的机制。\n\n\n**知识小贴士：**\n\n​	对于**LRU**和**TTL**相关策略，每次触发时，redis会默认从5个key中一个key符合条件的key进行删除。如果要修改的话，可以修改**redis.conf**中**maxmemory-samples**属性值\n\n\n## 5.4 生产环境下的策略设置&选择\n\n​	刚才已经为大家介绍完了redis中的八种内存淘汰策略，那么此时大家可能在想，这些策略我应该如何设置？何时来选择哪种策略使用？\n\n​	对于这两个问题，来给大家做一个一一解答：\n\n### 5.4.1 策略设置\n\n​	**redis默认使用noeviction**，我们可以通过修改**redis.conf**中**maxmemory-policy**属性值设置不同的内存淘汰策略。\n\n\n### 5.4.2 不同策略的使用场景\n\n1、Redis只做缓存，不做DB持久化，使用allkeys。如状态性信息，经常被访问，但数据库不会修改。\n\n2、同时用于缓存和DB持久化，使用volatile。如商品详情页。\n\n3、存在冷热数据区分，则选择LRU或LFU。如热点新闻，热搜话题等。\n\n4、每个key被访问概率基本相同，选择使用random。如企业内部系统，访问量不大，删除谁对数据库也造成太大压力。\n\n5、根据超时时间长久淘汰数据，选择选用ttl。如微信过期好友请求。``', '2021-11-10 11:47:44', 0, '2022-02-08 10:18:11', 0);
INSERT INTO `m_blog` VALUES (10, 1, '非关系型数据库--redis 03', 'redis-03', '\n\n# Redis-day03\n\n# 1 Redis-Cluster\n\n​	通过之前的学习，相信大家对于Redis的使用与关键性原理已经学会了，但是在生产环境下，Redis又是如何部署的呢？ 可能有的同学会说：这关我鸟事儿，这不是运维该关心的吗。但是作为一个合格的开发人员来说，方方面面都应该有所涉猎，才能让自身有更多的成长。\n\n- 主从复制无法实现自动主从切换。\n- 单机性能可能无法满足业务需求。\n- 单机数据存储安全性不高。\n\n​	那么对于这种种类类的问题， 我们只需要一个方案就可以解决，它就是Redis集群，也称之为Redis-Cluster。\n\n## 1.1 什么是Redis-Cluster\n\n​	Redis-Cluster是Redis3.0提供的分布式解决方案，其由多个Redis实例组成，官方建议六台，三台主节点，三台从节点。每个节点都会保存数据和整个集群状态，同时每个节点都和其他所有节点连接。\n\n\n\n- **数据自动分片**\n- **主从复制**\n- **自动故障转移**\n- **线性扩容缩容**\n\n## 1.2 集群搭建\n\n\n**1）创建集群数据文件夹**\n\n```yacas\nmkdir -p /mydata/rediscluster/node1\nmkdir -p /mydata/rediscluster/node2\nmkdir -p /mydata/rediscluster/node3\nmkdir -p /mydata/rediscluster/node4\nmkdir -p /mydata/rediscluster/node5\nmkdir -p /mydata/rediscluster/node6\n\nmkdir -p /mydata/rediscluster/node1/data\nmkdir -p /mydata/rediscluster/node2/data\nmkdir -p /mydata/rediscluster/node3/data\nmkdir -p /mydata/rediscluster/node4/data\nmkdir -p /mydata/rediscluster/node5/data\nmkdir -p /mydata/rediscluster/node6/data\n```\n\n**2）上传redis.conf配置文件分别上传至node1、node2、node3、node4、node5、node6目录下**\n\n**3）修改redis.conf文件权限**\n\n```yacas\nchmod 777 /mydata/rediscluster/node1/redis.conf\nchmod 777 /mydata/rediscluster/node2/redis.conf\nchmod 777 /mydata/rediscluster/node3/redis.conf\nchmod 777 /mydata/rediscluster/node4/redis.conf\nchmod 777 /mydata/rediscluster/node5/redis.conf\nchmod 777 /mydata/rediscluster/node6/redis.conf\n```\n\n**4）修改redis.conf，允许开启集群**\n\n```yacas\n#修改端口为7001,7002,7003,7004,7005,7006\n\n#开启集群\ncluster-enabled yes\n```\n\n**5）创建并运行Redis容器**\n\n```yacas\n#redis01\ndocker run \\\n--name redis01 \\\n-p 7001:7001 \\\n--network host \\\n-v /mydata/rediscluster/node1/data:/data \\\n-v /mydata/rediscluster/node1/redis.conf:/etc/redis/redis.conf \\\n--privileged=true \\\n-d redis:6.0.11 redis-server /etc/redis/redis.conf\n\n#redis02\ndocker run \\\n--name redis02 \\\n-p 7002:7002 \\\n--network host \\\n-v /mydata/rediscluster/node2/data:/data \\\n-v /mydata/rediscluster/node2/redis.conf:/etc/redis/redis.conf \\\n--privileged=true \\\n-d redis:6.0.11 redis-server /etc/redis/redis.conf\n\n#redis03\ndocker run \\\n--name redis03 \\\n-p 7003:7003 \\\n--network host \\\n-v /mydata/rediscluster/node3/data:/data \\\n-v /mydata/rediscluster/node3/redis.conf:/etc/redis/redis.conf \\\n--privileged=true \\\n-d redis:6.0.11 redis-server /etc/redis/redis.conf\n\n#redis04\ndocker run \\\n--name redis04 \\\n-p 7004:7004 \\\n--network host \\\n-v /mydata/rediscluster/node4/data:/data \\\n-v /mydata/rediscluster/node4/redis.conf:/etc/redis/redis.conf \\\n--privileged=true \\\n-d redis:6.0.11 redis-server /etc/redis/redis.conf\n\n#redis05\ndocker run \\\n--name redis05 \\\n-p 7005:7005 \\\n--network host \\\n-v /mydata/rediscluster/node5/data:/data \\\n-v /mydata/rediscluster/node5/redis.conf:/etc/redis/redis.conf \\\n--privileged=true \\\n-d redis:6.0.11 redis-server /etc/redis/redis.conf\n\n#redis06\ndocker run \\\n--name redis06 \\\n-p 7006:7006 \\\n--network host \\\n-v /mydata/rediscluster/node6/data:/data \\\n-v /mydata/rediscluster/node6/redis.conf:/etc/redis/redis.conf \\\n--privileged=true \\\n-d redis:6.0.11 redis-server /etc/redis/redis.conf\n```\n\n**8）进入redis01容器**\n\n```yacas\ndocker exec -it redis01 /bin/bash\n```\n\n**9）执行创建集群命令**\n\n```yacas\nredis-cli --cluster create 192.168.217.134:7001 192.168.217.134:7002 192.168.217.134:7003 192.168.217.134:7004 192.168.217.134:7005 192.168.217.134:7006 --cluster-replicas 1\n```\n\n\n**10）查看下Redis集群节点信息**\n\n```yacas\nredis-cli -p 7001 cluster nodes\n```\n\n\n## 1.3 工作原理\n\n​	Redis-Cluster基于数据分片实现，不同的节点中存在不同的数据。 \n\n\n​	那么它又是如何保证不同节点存储不同数据的呢？  它的设计中引入了槽的概念，在集群中总共设计了16384个槽位， 集群中每个节点实例会被分配不同范围的槽位。\n\n\n\n​	当存入数据时，Redis-Cluster会根据：Hash槽算法确定这条数据被存入哪个节点中：**CRC16(\'key\') % 16384 = 对应槽值**。然后将这条数据存入对应的节点实例中。\n\n\n```yacas\n#连接集群中任意节点客户端， 需携带 -c 参数，代表以集群方式连接\ndocker exec -it redis01 redis-cli -p 7001 -c\n\n#存入数据\nset name lisi\n```\n\n\n​	当获取数据时，客户端首先会保存一份Redis-Cluster槽信息表，接着通过Hash槽算法计算出槽值，从而确定节点实例，完成数据获取。\n\n\n## 1.5 主从复制\n\n​	Redis-Cluster在搭建时，可以非常方便的完成主从配置， Redis-Cluster为了提升整个系统的高可用性， 提供了自动故障发现与转移的机制。 当从节点发现自己的主节点宕机下线，它就自动的接替主节点继续对外提供服务。\n\n### 1.5.1 效果演示\n\n**1） 查看集群中节点信息**\n\n```yacas\n#进入集群中某个节点\ndocker exec -it redis01 /bin/bash\n\n#查看集群信息\nredis-cli -p 7001 cluster nodes\n```\n\n\n当前存在三台master，三台slave。 并且根据标识可以看出其对应关系。\n\n**2）将其中一个主节点停止**\n\n```yacas\ndocker stop redis02\n```\n\n**3）查看集群中节点信息**\n\n```yacas\nredis-cli -p 7001 cluster nodes\n```\n\n\n此时可以发现，redis02之前的slave现在已经被提升为master，继续对外提供服务。\n\n**当重新启动redis02后，可以发现它会变为原master的slave。**\n\n### 1.5.2 原理分析\n\n​	主从节点间，会定时的进行PING/PONG通信。 一旦slave发现自己的master下线，便会尝试故障转移，将自己提升为新的master。 但一个master下有可能存在多个slave，就会出现多个slave竞争成为master。那么应该让哪个slave成为新的master就是一个非常关键的问题。 那如何从多个slave中选择出一个新的master呢？ 这里就涉及到了**选举机制**。\n\n**选举过程如下：**\n\n1. slave发现对应的mater下线。\n2. 广播给集群中的其他master，等待master的投票。\n3. 当某个slave收到了，集群中超过半数master的投票，则该slave变成新的master。\n4. 广播消息通知集群中的其他节点。\n\n通过上述过程也就解释了，为什么Redis官方推荐集群中主节点数量为奇数台，因为如果是偶数台的话，很有可能出现平票的情况。\n\n**但是此时仍然有可能出现平票的情况：**\n\n\n 	假设现在A实例的master宕机，它的两台从节点发起选举，B给Slave1投了一票，C给Slave2投了一票，这样就出现了平票，又会进入下一次选举。 那么这个问题Redis又是如何解决的呢？\n\n​	从节点并不是在主节点一进入宕机就立即发起选举，而是有一定的延迟，通过这个延迟时间确保主节点宕机状态在集群中被传播通知。这么做的原因是为了确保集群中其他主节点已经知晓该主节点已宕机，否则其他主节点可能拒绝投票。 同时通过延迟时间可以有效避免多个Slave同时发起选举， 那么延迟时间是多久呢？\n\n**延迟时间 = 500ms + random(0 ~ 500)+SLAVE_RANK*1000ms**\n\n`SLAVE_RANK表示此slave已经从master复制数据的总量的rank。Rank越小代表已复制的数据越新`\n\n​	同时默认情况下，当整个集群中，某个实例的主从结构整体宕机的话，则整个集群不可用。因为每个实例中存储的数据是不同的。  但是如果想考虑更高的可用性，不会因为某个实例的数据缺失而导致整个集群宕机的话， 则可以修改**redis.conf**中**cluster-require-full-coverage**属性为no。 表示当集群中某个实例的主从结构整体挂掉的时候集群仍然可用，也是说 0-16383个槽位中，落在该主从对应的slots上面的key是用不了的，但是如果key落在其他的范围是仍然可用的。\n\n## 1.6 线性扩容缩容\n\n### 1.6.1 扩容\n\n​	在实际生产环境下，随着访问量与数据量的提升，现有Redis-Cluster的节点数量可能无法应对，因此需要在现有集群中添加节点，对集群中节点数量进行扩容\n\n**1）参照之前方式，启动两个实例，一主一从**\n\n**2）向集群中新增节点**\n\n```yacas\n#进入节点中任意节点\ndocker exec -it redis01 /bin/bash\n\n#将新创建的redis实例添加到集群中\n#第一个节点为新加入的节点   第二个节点为集群中已存在的任意一个节点\nredis-cli --cluster add-node 192.168.200.151:7007 192.168.200.151:7001\n```\n\n\n**4）查看集群节点信息**\n\n```yacas\nredis-cli -p 7001 cluster nodes\n```\n\n\n**5）增加从节点**\n\n```yacas\n#第一个ip是新节点ip  第二个ip是集群中现有的任意节点ip  最后为当前从节点要对应的主节点id\nredis-cli --cluster add-node 192.168.200.151:7008 192.168.200.151:7001 --cluster-slave --cluster-master-id 486be1e189c4bbaacaceb872d7c0153e3ee32231\n```\n\n\n**6）重新分配槽位**\n\n```yacas\n#ip为集群中现有任意节点地址\nredis-cli --cluster reshard 192.168.200.151:7001\n```\n\n\n- **第一次确认：指定分配的槽位数量。**\n- **第二次确认：指定获取这些槽位的主节点id。**\n- **第三次确认：填写`all`表示要迁移的这些槽位由集群中原有的各个主节点平均分摊给新加入的主节点。**\n- **第四次确认：会有一次确认，输入yes即可。**\n\n**7）查看集群中各节点信息**\n\n```yacas\nredis-cli -p 7001 cluster nodes\n```\n\n\n### 1.6.2 缩容\n\n**1）迁移槽**\n\n```yacas\n#redis-cli --cluster reshard --cluster-from 要删除的主节点id --cluster-to 收迁移槽的主节点id --cluster-slots 迁移槽的数量 集群中现有任意节点id\n\nredis-cli --cluster reshard --cluster-from d18ab0e38603a8b0e8dee1e4e82f23c99c164b54 --cluster-to f2c3774ebb115fd5e17999e5755fae5aeb5f0f62 --cluster-slots 3300 192.168.200.151:7001\n```\n\n**2）删除节点**\n\n```yacas\n# 集群中任意节点ip  ， 被删除的节点id\nredis-cli --cluster del-node 192.168.200.151:7001 d18ab0e38603a8b0e8dee1e4e82f23c99c164b54\nredis-cli --cluster del-node 192.168.200.151:7001 b8b9c38ad9fefb6f2e09cbeb7b312020d98c9c50\n```\n\n**3）查看集群节点信息**\n\n```yacas\nredis-cli -p 7001 cluster nodes\n```\n\n## 1.7 SpringBoot工程连接RedisCluster\n\n```yml\nspring:\n  redis:\n    cluster:\n      nodes: 192.168.200.151:8001,192.168.200.151:8002,192.168.200.151:8003  #配置集群主节点连接信息\n```\n\n# 2 缓存穿透解决方案\n\n## 2.1 问题描述\n\n​	之前已经介绍了缓存使用时的执行流程：\n\n\n​	但是这是一个理想的过程， 假设现在前端要查询的数据在缓存中没有，同时在数据库中也没有，那么按照现在的流程来说，则很有可能压垮数据源。比方说前端一直查询一个不存在的商品，那么无论缓存还是数据库都不会这条数据，如果有人想恶意攻击，则很有可能通过这种方式压垮数据源。  这种问题就是： **缓存穿透**。\n\n​	对于缓存穿透问题的解决，常见的有两种方式：\n\n**基础方案：**\n\n​	如果一条数据在数据库中不存在，仍将这个空结果在缓存中存储，这样的话，就算数据库中不存在，缓存中也存在空值的key，从而避免了缓存穿透问题的出现。\n\n**高阶方案：**\n\n​	布隆过滤器。\n\n## 2.2 布隆过滤器介绍\n\n​	布隆过滤器在 NoSQL 数据库领域使用非常广泛，通过它可以显著降低数据库的 IO 请求数量。当用户来查询某个数据时，可以先通过内存中的布隆过滤器过滤掉大量不存在的数据请求，然后再去磁盘进行查询。\n\n​	它现在是很多公司都会采用的避免缓存穿透的解决方案。**当布隆过滤器说某个值存在时，这个值可能不存在；当它说不存在时，那就肯定不存在。**\n\n​	它会将所有可能存在的数据通过Hash计算放入到一个足够大的bitmap中，通过之前的学习，我们也知道Bitmap中只可以存放0和1。当布隆过滤器认定某个数据不存在时，则将请求直接拦截掉，从而避免对后端系统的访问压力。\n\n\n​	现在有一组key：a、b、c。 \n\n​	当存储数据时，对每个key会经过多次hash运算，从而得到多个bitmap的位置，然后将这些位置为1。\n\n​	在查询数据时，通过对key的计算，得到其在bitmap上的多个位置，如果都为1，则认定该数据存在，请求放行让其访问后端获取数据。  如果该key对应的bitmap上的多个位置，有一个位置的值是0，则判断该key不存在，拦截请求，直接向客户端返回结果。\n\n\n\n**布隆过滤器的缺点：**\n\n​	在使用布隆过滤器时，有可能存在误判，造成缓存穿透问题出现。  假设当存储数据时，**AKEY**经过多次hash计算，将其在bitmap对应位置改为1， 但在获取数据时，客户端要查询**BKEY**，但是**BKEY**经过多次hash计算后，和AKEY的位置全部正好相同，此时误判出现。一个之前并不存在的key，因为计算的位置与其他存在key相同，而出现误判，造成缓存穿透。\n\n\n## 2.3 布隆过滤器安装&使用\n\n### 2.3.1 安装\n\nRedis官方本身已经提供了布隆过滤器，并且在Redis4.0开始作为一个插件加载到 Redis Server 中。\n\n```yacas\n#安装具备布隆过滤器的插件的redis容器\ndocker pull redislabs/rebloom\ndocker run -di -p 6379:6379 redislabs/rebloom\n```\n\n### 2.3.2 常用命令\n\n| 命令       | 功能                                                  |\n| :--------- | :---------------------------------------------------- |\n| BF.RESERVE | 创建一个大小为capacity，错误率为error_rate的空的Bloom |\n| BF.ADD     | 向key指定的Bloom中添加一个元素                        |\n| BF.MADD    | 向key指定的Bloom中添加多个元素                        |\n| BF.EXISTS  | 检查一个元素是否可能存在于key指定的Bloom中            |\n| BF.INFO    | 查询key指定的Bloom的信息                              |\n| BF.DEBUG   | 查看BloomFilter的内部详细信息                         |\n\n```yacas\n# 在redis中添加一个布隆过滤器 错误率是0.01 大小为1万（bitmap的长度）\nBF.RESERVE bftest 0.01 10000 NONSCALING\n\n# 在bftest 的布隆过滤器添加一个key\nBF.ADD bftest key1\n\n# 在bftest 的布隆过滤器添加多个key\nBF.MADD bftest key2 key3 key4\n\n# 验证布隆过滤器中某个key是否存在\nBF.EXISTS bftest key2\n\n# 查询布隆过滤器信息\nBF.INFO bftest\n\n# 查询布隆过滤器的详情信息\nBF.DEBUG bftest\n```\n\n### 2.3.3 功能实现\n\n```java\n/**\n * 布隆过滤器工具类\n */\npublic class BloomFilterUtil {\n\n    //默认bitmap集合大小\n    private final static int DEFAULT_SIZE = 2 << 24;\n\n    private final static int[] SEEDS = new int[]{23,35,56,74,89,101};\n\n    private BitSet bits;\n\n    public SimpleHash[] func = new SimpleHash[6];\n\n    /**\n     * 构造BloomFilterUtil\n     */\n    public BloomFilterUtil(){\n        bits = new BitSet(DEFAULT_SIZE);\n        for (int i=0; i<SEEDS.length; i++){\n            func[i] = new SimpleHash(DEFAULT_SIZE, SEEDS[i]);\n        }\n    }\n\n    /**\n     * 向布隆过滤器中添加元素\n     * @param value 数据\n     */\n    public void add(Object value){\n        for (SimpleHash f : func) {\n            bits.set(f.hash(value), true);\n        }\n    }\n\n    /**\n     * 判断布隆过滤器中是否存在\n     * @param value 数据\n     * @return\n     */\n    public boolean contains(Object value){\n        boolean ret = true;\n        for (SimpleHash f : func) {\n            ret = ret && bits.get(f.hash(value));\n            if (!ret){\n                break;\n            }\n        }\n        return ret;\n    }\n\n    /**\n     * 内部类，用于计算hash值。\n     */\n    public static class SimpleHash{\n        private int cap;\n        private int seed;\n\n        public SimpleHash(int cap, int seed) {\n            this.cap = cap;\n            this.seed = seed;\n        }\n        /**\n         * 计算 hash 值\n         */\n        public int hash(Object value) {\n            int h;\n            return (value == null) ? 0 : Math.abs(seed * (cap - 1) & ((h = value.hashCode()) ^ (h >>> 16)));\n        }\n    }\n}\n```\n\n### 2.3.4 适用场景\n\n**1）防止重复请求**\n\n​	用户发送请求时，先判断请求在布隆过滤器中是否存在。 如果不存在，则判定为第一次请求，放行且将请求放入布隆过滤器中。如果存在，则不允许访问。\n\n**2）邮件黑名单**\n\n​	当一个邮箱地址被判定为垃圾邮箱后，就将此地址添加进布隆过滤器中即可。 \n\n**3）推荐去重**\n\n​	对于资讯类平台，应该尽可能的不给用户推荐重复的信息，对于这种需求，可以将已推荐的资讯存入布隆过滤器， 当要再次给用户推荐时， 则判断布隆过滤器，只推荐在布隆过滤器中不存在的资讯。\n\n**4）爬虫系统URL去重**\n\n​	对于爬虫系统来说，需要对URL去重，已经爬取过的URL则不再爬取了。 此时可以将已经爬取的URL存入布隆过滤器， 当要爬取URL时，先判断该URL在布隆过滤器中是否存在。\n\n### 2.3.5 生产环境使用实践\n\n​	之前在创建布隆过滤器时，指定了错误率和bitmap的容量。 那么这两个参数为什么需要存在？ 他们能起到什么样的效果呢？\n\n- 当布隆过滤器的错误率越小，需要的存储空间就越大。因为它需要更多的位置去存储比对。 对于一些不是严格要求精确的场景下，可以将错误率适当调大。\n- bitmap的容量是用于存储0和1的值空间，过大的话，会浪费存储空间，过小的话，又会降低准确度。使用之前一定要尽可能地精确估计好元素数量，还需要加上一定的冗余空间以避免实际元素可能会意外高出估计值很多。\n\n# 3 缓存击穿解决方案\n\n## 3.1 问题描述\n\n​	在一些业务场景下，某条数据可能会在某些时间点被高并发读取，它就属于热点数据，如秒杀商品。 但是此时可能在这个时间点，数据的过期时间到了， 造成缓存中没有数据，客户端的大量请求，直接透过缓存访问数据库获取数据，造成数据库压力瞬间增大。这种情况就是**缓存击穿**。\n\n​	缓存击穿与缓存穿透不同点在于： **击穿是缓存中没有，但数据库中有。 而穿透是缓存中没有，数据库中也没有**\n\n​	对于缓存击穿问题的解决，比较常见的解决方案是通过互斥锁（setnx）控制。它的特点是当key不存在时才存储，key存在则不做任何操作。\n\n## 3.2 功能实现\n\n```java\npublic GoodsEntity findGoodsInfoById(Long goodsId) {\n\n    //先查询缓存\n    GoodsEntity redisGoods = (GoodsEntity) redisTemplate.opsForValue().get(\"goods:\" + goodsId);\n\n    if (redisGoods == null){\n        //数据已过期\n        if (redisTemplate.opsForValue().setIfAbsent(goodsId+\"_ex\",\"1\",5, TimeUnit.MINUTES)){\n            GoodsEntity goodsEntity = goodsMapper.selectById(goodsId);\n            redisTemplate.opsForValue().set(\"goods:\"+goodsId,goodsEntity,30,TimeUnit.MINUTES);\n            redisTemplate.delete(goodsId+\"_ex\");\n            return goodsEntity;\n        }else {\n            //其他线程睡眠等待\n            try {\n                TimeUnit.MILLISECONDS.sleep(30);\n            } catch (InterruptedException e) {\n                e.printStackTrace();\n            }\n            //重新获取\n            System.out.println(\"重新尝试获取数据\");\n            return findGoodsInfoById(goodsId);\n        }\n    }\n    return redisGoods;\n}\n```\n\n# 4 缓存雪崩解决方案\n\n​	当有大量数据在某个时间同时失效，这样就会造成，大量请求透过缓存访问数据库。 与缓存击穿不同的是： **缓存击穿只一条数据，缓存雪崩是大量数据**。 当出现缓存雪崩后，很有可能导致数据库延迟或宕机，并且数据库会被其他服务依赖，造成其他服务也出现问题，最终可能导致整个系统瘫痪，这就是缓存雪崩。  缓存雪崩只会在非常高并发的场景下出现，一般流量基本不会出现缓存雪崩的问题。\n\n​	对于缓存雪崩的解决方案如下：\n\n- **缓存预热：**提前将数据缓存好，不等用户请求再缓存数据，如果数据量大，启动后运维手动触发，数据量不大，启动自动加载。\n- **随机过期时间：**设置不同的过期时间，让缓存失效时间尽量均匀，这样不会大量用户同时缓存失效。\n- **多级缓存：**当缓存A失效时，请求缓存备份B，A失效时间短，B失效时间长。\n- 让数据永不过期\n\n# 5 缓存一致性解决方案\n\n## 5.1 问题描述\n\n​	根据之前的学习，我们可以知道，Redis中的数据都是从MySQL中获取来的，那现在如果mysql中数据发生改变了怎么办呢？ 此时Mysql和Redis中的数据就不一样了。假设之前已经将商品id为1的数据存储在了缓存中， 但是业务人员又对商品id为1的商品在MySQL中进行了修改，但是缓存是并不知道的。当客户端来查询时，因为缓存中已经有了这条数据，所以仍然直接从缓存中获取，而这条数据已经是一个老数据了，造成客户端数据与MySQL中数据的不一致。\n\n## 5.2 原始解决方案\n\n​	对于这个问题的解决，可以通过业务编码进行解决， 每次在修改MySQL时，都要将修改后的数据更新到MySQL中。\n\n```java\n@Transactional\npublic String updateInfoById(GoodsEntity goodsEntity) {\n    try {\n        goodsMapper.updateById(goodsEntity);\n        //修改缓存\n        redisTemplate.opsForValue().set(\"goods:\"+goodsEntity.getId(),goodsEntity,30,TimeUnit.MINUTES);\n        return \"success\";\n    }catch (Exception e){\n        e.printStackTrace();\n        return \"fail\";\n    }\n}\n```\n\n这种方式的实现很简单，但是会造成大量冗余代码的出现， 每次修改数据库都要手动的去更新缓存，对开发效率会造成影响。\n\n## 5.3 基于Canal的一致性解决方案\n\n### 5.3.1 Canal介绍\n\n​	阿里的服务器主要部署在杭州和美国，因此业务上需要将杭州和美国的数据同步，但是阿里早期对于数据同步的解决方案并不好，因此在2010年开始转而开发Canal并在阿里内部大量应用。\n\n​	Canal主要用于数据的增量更新。它可以监控数据库**日志**的变化，从而获取到数据库新增的数据，或修改的数据。\n\n\n### 5.3.2 环境搭建\n\n启动mysql\n\n```shell\n#docker 拉取mysql\ndocker pull mysql:5.7\n#创建 mysql挂载目录\nmkdir -p /mydata/mysql/logs\nmkdir -p /mydata/mysql/data\n#启动mysql\n\n\n\ndocker run -p 3306:3306 --name mysql-master \\\n-v /mydata/mysql/conf:/etc/mysql \\\n-v /mydata/mysql/logs:/var/log/mysql \\\n-v /mydata/mysql/data:/var/lib/mysql \\\n-e MYSQL_ROOT_PASSWORD=root \\\n-d mysql:5.7\n```\n\n\n\n#### 5.3.2.1 MySQL环境配置\n\n**1）开启MySQL中BinLog日志**\n\n​	进入mysql配置文件目录，添加**my.cnf**文件\n\n```yacas\n\n#进入目录\ncd /etc/mysql\n\n#编辑my.cnf文件\nvim my.cnf\n\n#文件内容如下所示：\n\n[mysqld]\nlog-bin=mysql-bin\nbinlog-format=ROW\n# 这里的id只要是唯一的就行\nserver_id=123456\ncharacter_set_server=utf8\n```\n\n**2）重启并进入容器**\n\n```yacas\n#重启容器\ndocker restart mysql-master\n\n#进入容器\ndocker exec -it mysql-master /bin/bash\n```\n\n**3）进入mysql客户端，查看binlog日志是否开启**\n\n```yacas\n#容器中进入mysql客户端\nmysql -uroot -p\n\n#执行指令\nshow master status;\n```\n\n**4）创建数据同步账号并授权**\n\n```yacas\ngrant all privileges on *.* to root@\'%\' identified by \'root\';\n#创建canal数据同步账户\nCREATE USER canal IDENTIFIED BY \'canal\';  \nGRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO \'canal\'@\'%\';\nFLUSH PRIVILEGES;\n\n#重启mysql容器\ndocker restart mysql-master\n```\n\n#### 5.3.2.2 Canal安装配置\n\n**1）创建canal容器**\n\n```yacas\ndocker run --name canal-server \\\n-e canal.instance.master.address=192.168.217.134:3306 \\\n-e canal.instance.dbUsername=canal \\\n-e canal.instance.dbPassword=canal \\\n-e canal.instance.master.journal.name=mysql-bin.000003 \\\n-e canal.instance.connectionCharset=UTF-8 \\\n-e canal.instance.filter.regex=.*\\\\..* \\\n-p 11111:11111 \\\n-d canal/canal-server\n```\n\n**2）查看canal容器日志**\n\n```yacas\ndocker logs -f canal\n```\n\n\n### 5.3.3 SpringBoot整合Canal实现增量更新\n\n#### 5.3.3.1 安装Canal依赖\n\n​	阿里官方的Canal原生依赖，在使用时较为繁琐，这里使用一款开源的自定义Canal依赖，使用起来非常方便。但是需要将源码包安装在本地仓库。\n\n**源码包下载地址：**https://github.com/chenqian56131/spring-boot-starter-canal\n\n**将源码工程打开并执行mvn clean install**\n\n\n#### 5.3.3.2 SpringBoot整合\n\n```xml\n<dependency>\n    <groupId>com.xpand</groupId>\n    <artifactId>starter-canal</artifactId>\n    <version>0.0.1-SNAPSHOT</version>\n</dependency>\n```\n\n**1）修改启动类，添加允许canal使用注解**\n\n```java\n@SpringBootApplication\n@EnableCanalClient //声明开启canal\npublic class GoodsApplication {\n\n    public static void main(String[] args) {\n        SpringApplication.run(GoodsApplication.class,args);\n    }\n}\n```\n\n**2）修改核心配置文件application.yml，声明canal连接信息**\n\n```yml\ncanal:\n  client:\n    instances:\n      example:\n        host: 192.168.200.151 #canal所在服务器IP\n        port: 11111 #canal的IP\n        batchSize: 1000 #允许批量操作数\n```\n\n**3）创建数据监听类**\n\n```java\n@CanalEventListener\npublic class GoodsListener {\n\n    @ListenPoint(schema = \"redis\")\n    public void goodsUpdate(CanalEntry.EventType eventType, CanalEntry.RowData rowData){\n        //获取改变之前的数据\n        rowData.getBeforeColumnsList().forEach((c)-> System.out.println(\"改变前的数据:\"+c.getName()+\"::\"+c.getValue()));\n\n        //获取改变之后的数据\n        rowData.getAfterColumnsList().forEach((c)-> System.out.println(\"改变之后的数据:\"+c.getName()+\"::\"+c.getValue()));\n    }\n}\n```\n\n\n**4）修改监听类，当数据库数据发生改变，则触发更新redis数据**\n\n```java\n@CanalEventListener\npublic class GoodsListener {\n\n    @Autowired\n    private RedisTemplate redisTemplate;\n\n    @ListenPoint(schema = \"redis\")\n    public void goodsUpdate(CanalEntry.EventType eventType, CanalEntry.RowData rowData){\n        //获取改变之前的数据\n        rowData.getBeforeColumnsList().forEach((c)-> System.out.println(\"改变前的数据:\"+c.getName()+\"::\"+c.getValue()));\n\n        //获取改变之后的数据\n        rowData.getAfterColumnsList().forEach((c)-> System.out.println(\"改变之后的数据:\"+c.getName()+\"::\"+c.getValue()));\n\n        Map<String,String> newData = new HashMap<>();\n        rowData.getAfterColumnsList().forEach((c)->newData.put(c.getName(),c.getValue()));\n\n        String jsonString = JSON.toJSONString(newData);\n        GoodsEntity goodsEntity = JSON.parseObject(jsonString, GoodsEntity.class);\n        System.out.println(goodsEntity);\n\n        //放入缓存\n        redisTemplate.opsForValue().set(\"goods:\"+goodsEntity.getId(),goodsEntity,30, TimeUnit.MINUTES);\n\n    }\n}\n```\n\n', '2021-11-20 11:47:45', 0, NULL, 0);
INSERT INTO `m_blog` VALUES (11, 1, '非关系型数据库--MongoDB', 'MongoDB数据库的学习', '#  MongoDB\n\n# 1 什么是MongoDB\n\n​	MongoDB是NoSQL数据库中的一种文档型数据库，其基于C++语言编写，将数据以BSON的形式保存在磁盘。其支持多种编程语言，如：Java、python、php、C++等。其主要适用于：**海量数据** 且 **数据价值低** 且 具有**格式的数据**。\n\n\n​	其现在的使用热度非常高，很多互联网类型公司，都会使用到它。如腾讯，淘宝，爱奇艺，摩拜，字节等等。\n\n\n**适用场景：**\n\n- 游戏场景，使用 MongoDB 存储游戏用户信息，用户的装备、积分等直接以内嵌文档 的形式存储，方便查询、更新\n- 物流场景，使用 MongoDB 存储订单信息，订单状态在运送过程中会不断更新，以 MongoDB 内嵌数组的形式来存储，一次查询就能将订单所有的变更读取出来。\n- 社交场景，使用 MongoDB 存储存储用户信息，以及用户发表的朋友圈信息，通过地 理位置索引实现附近的人、地点等功能\n- 物联网场景，使用 MongoDB 存储所有接入的智能设备信息，以及设备汇报的日志信 息，并对这些信息进行多维度的分析\n- 视频直播，使用 MongoDB 存储用户信息、礼物信息等\n\n**不适用场景：**\n\n 高度事务性的系统：例如，银行或会计系统。传统的关系型数据库目前还是更适用于需要大量原子性复杂事务的应用程序。\n\n# 2 Mongodb安装\n\n```yacas\nmkdir -p /mydata/mongodb\n\ndocker run -p 27017:27017 -v /mydata/mongodb:/data/db --name mongodb -d mongo\n```\n\n**docker指令连接mongodb**\n\n```yacas\ndocker exec -it mongodb mongo\n```\n\n\n**客户端工具studio3T连接**\n\n\n# 3 Mongodb核心概念\n\n​	要来使用Mongodb的话，首先需要先来知道，其内部的核心概念， 在Mongodb中其核心概念主要有：数据库、集合、文档、域、索引。\n\n与MySQL对于如下：\n\n| MongoDB    | MySQL    | 说明   |\n| ---------- | -------- | ------ |\n| database   | database | 数据库 |\n| collection | table    | 集合   |\n| field      | column   | 域     |\n| document   | row      | 文档   |\n| index      | index    | 索引   |\n\n# 4 Mongdb常用指令\n\n## 4.1 数据库\n\n​	一个mongodb中可以建立多个数据库。每个数据库都会存在各自的集合。\n\n### 4.1.1 查看数据库\n\n```yacas\nshow dbs\n```\n\n\n\n![image-20210320214124213](assets/image-20210320214124213.png)\n\n### 4.1.2 使用指定数据库\n\n​	如数据库不存在，则直接创建\n\n```yacas\nuse students\n```\n\n\n### 4.1.3 查看当前数据库\n\n```yacas\ndb\n```\n\n\n### 4.1.4 删除当前数据库\n\n```yacas\ndb.dropDatabase()\n```\n\n\n## 4.2 集合\n\n​	mongodb中集合可以理解为是mysql中的一张表， 其从属于某个数据库下。\n\n### 4.2.1 创建集合\n\n```yacas\n#语法\n#name: 要创建的集合名称\n#options: 可选参数, 指定有关内存大小及索引的选项\n\ndb.createCollection(name, options)\n```\n\noptions可选值\n\n| 参数名 | 类型 | 描述                                                         |\n| ------ | ---- | ------------------------------------------------------------ |\n| capped | 布尔 | （可选）如果为 true，则创建固定集合。固定集合是指有着固定大小的集合，当达到最大值时，它会自动覆盖最早的文档。**当该值为 true 时，必须指定 size 参数。** |\n| size   | 布尔 | （可选）为固定集合指定一个最大值，即字节数。**如果 capped 为 true，也需要指定该字段。** |\n| max    | 数值 | （可选）指定固定集合中包含文档的最大数量。                   |\n\n```yacas\ndb.createCollection(\"student\")\n```\n\n![image-20210320215320341](assets/image-20210320215320341.png)\n\n### 4.2.2 查看已有集合\n\n```yacas\nshow collections\n```\n\n\n### 4.2.3 删除集合\n\n```yacas\ndb.集合名称.drop()\n```\n\n```yacas\ndb.student.drop()\n```\n\n\n## 4.3 文档\n\n​	mongodb中文档可以理解为mysql中表里的每条数据。 其从属于集合。\n\n### 4.3.1 插入文档\n\n```yacas\n#语法\ndb.集合名称.insert(数据);\n```\n\n```yacas\ndb.comment.insert({\n	_id: \"1\",\n	articleId: \"1\",\n	userId: \"1\",\n	likeNums: 168,\n    content:\"加班到半夜\",\n    lastModifiedDate:new Date(),\n	reply: [{\n        _id: \"2\",\n		articleId: \"1\",\n		userId: \"2\",\n		likeNums: 168,\n        content:\"按时吃饭\",\n        lastModifiedDate:new Date(),\n        reply:[]\n	},\n    {\n        _id: \"2\",\n		articleId: \"1\",\n		userId: \"2\",\n		likeNums: 2,\n        content:\"你真猛\",\n        lastModifiedDate:new Date(),\n        reply:[]\n	},\n    {\n        _id: \"3\",\n		articleId: \"1\",\n		userId: \"3\",\n		likeNums: 3,\n        content:\"社畜\",\n        lastModifiedDate:new Date(),\n        reply:[]\n	}]\n})\n\ndb.comment.insert({\n	_id: \"4\",\n	articleId: \"1\",\n	userId: \"4\",\n	likeNums: 50,\n    content:\"年轻就要努力\",\n	reply: [{\n        _id: \"5\",\n		articleId: \"1\",\n		userId: \"5\",\n		likeNums: 0,\n        content:\"时刻准备着\",\n        lastModifiedDate:new Date(),\n        reply:[]\n	},\n    {\n        _id: \"6\",\n		articleId: \"1\",\n		userId: \"6\",\n		likeNums: 10,\n        content:\"我不想努力了\",\n        lastModifiedDate:new Date(),\n        reply:[]\n	}\n    ]\n})\n\ndb.comment.insert({\n	_id: \"7\",\n	articleId: \"1\",\n	userId: \"7\",\n	likeNums: 3,\n    content:\"富婆在哪里\",\n    lastModifiedDate:new Date(),\n	reply: [{\n        _id: \"8\",\n		articleId: \"1\",\n		userId: \"8\",\n		likeNums: 5,\n        content:\"这里呢\",\n        lastModifiedDate:new Date(),\n        reply:[]\n	},\n    {\n        _id: \"9\",\n		articleId: \"1\",\n		userId: \"9\",\n		likeNums: 0,\n        content:\"如何让富婆爱上你\",\n        lastModifiedDate:new Date(),\n        reply:[]\n	},\n    {\n        _id: \"10\",\n		articleId: \"1\",\n		userId: \"10\",\n		likeNums: 20,\n        content:\"努力学习,天天向上\",\n        lastModifiedDate:new Date(),\n        reply:[]\n	}]\n})\n```\n\n### 4.3.2 查询文档\n\n**1）查看全部文档**\n\n```yacas\ndb.comment.find()\n```\n\n\n**2）按条件查询**\n\n```yacas\ndb.comment.find({articleId:1})\n#注意区分数据类型\n```\n\n\n**3）查询单一记录**\n\n```yacas\ndb.comment.findOne({userId:\"2\"})\n```\n\n\n**4）查询指定条数记录**\n\n```yacas\ndb.comment.find().limit(2)\n```\n\n\n### 4.3.3 修改文档\n\n```yacas\ndb.集合名.update({修改文档的条件},{$set:{需要修改的属性名:属性值}})\n```\n\n```yacas\ndb.comment.update({userId:\"1\"},{$set:{likeNums:256}})\n```\n\n\n### 4.3.4 删除文档\n\n```yacas\ndb.集合名称.remove(条件)\n```\n\n```yacas\ndb.comment.remove({userId:\"2\"})\n```\n\n\n```yacas\n#删除全部文档,慎用！！！\ndb.comment.remove({})\n```\n\n### 4.3.5 统计记录数\n\n```yacas\ndb.comment.count()\n```\n\n```yacas\n#带条件统计\ndb.comment.count(条件)\n\ndb.comment.count({articleId:\"1\"})\n```\n\n\n### 4.3.6 模糊查询\n\nMongoDB的模糊查询是通过正则表达式的方式实现的。格式为：\n\n```yacas\n/模糊查询字符串/\n```\n\n查询所有包含努力的数据\n\n```yacas\ndb.comment.find({content:/努力/})\n```\n\n查询所有以加班开头的数据\n\n```yacas\ndb.comment.find({content:/^加班/})\n```\n\n### 4.3.7 比较查询\n\n<, <=, >, >= 这个操作符也是很常用的，格式如下:\n\n```yacas\ndb.集合名称.find({ \"field\" : { $gt: value }}) // 大于: field > value\ndb.集合名称.find({ \"field\" : { $lt: value }}) // 小于: field < value\ndb.集合名称.find({ \"field\" : { $gte: value }}) // 大于等于: field >= value\ndb.集合名称.find({ \"field\" : { $lte: value }}) // 小于等于: field <= value\ndb.集合名称.find({ \"field\" : { $ne: value }}) // 不等于: field != value\n```\n\n查询所有点赞数大于100的数据\n\n```yacas\ndb.comment.find({likeNums:{$gt:1000}})\n```\n\n\n### 4.3.8 多条件查询\n\n如果需要**查询条件间是并列关系**，需要使用**$and**操作符将条件进行关联（相当于SQL的and）\n\n```yacas\n$and:[ {条件},{条件},{条件} ]\n```\n\n如果需要**查询条件间是或者关系**，需要使用**$or**操作符将条件进行关联（相当于SQL的or）\n\n```yacas\n$or:[ {条件},{条件},{条件} ]\n```\n\n**查询点赞数大于100，小于300的数据**\n\n```yacas\ndb.comment.find({$and:[ {likeNums:{$gte:100}} ,{likeNums:{$lt:300} }]})\n```\n\n\n**查询userId为2，或者点赞数小于100的数据**\n\n```yacas\ndb.comment.find({$or:[ {userId:\"2\"} ,{likeNums:{$lt:100} }]})\n```\n\n\n### 4.3.9 列值增长\n\n对某列值在原有值的基础上进行增加或减少，可以使用**$inc**运算符：\n\n```yacas\ndb.comment.update({_id:\"4\"},{$inc:{likeNums:1}})\n```\n\n\n# 5 Springboot整合MongoDB\n\n## 5.1 基础整合\n\n添加依赖\n\n```xml\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-data-mongodb</artifactId>\n</dependency>\n```\n\n修改核心配置文件，设置mongodb连接\n\n```yml\nspring:\n  data:\n    mongodb:\n      host: 192.168.200.131\n      port: 27017\n      database: commentdb\n```\n\n修改实体类，设置与collection映射关系\n\n```java\n@Document(collection = \"comment\")\npublic class DiscussEntity implements Serializable {\n\n    @Id\n    private String id;\n\n    private String articleId;\n\n    private String userId;\n\n    private int likeNums;\n\n    private String content;\n\n    private List<DiscussEntity> reply;\n}\n```\n\n## 5.2 业务实现\n\n### 5.2.1 添加评论\n\n```java\npublic void addDiscuss(DiscussEntity discussEntity) {\n    String id = idWorker.nextId() + \"\";\n    discussEntity.setId(id);\n    mongoTemplate.save(discussEntity);\n}\n```\n\n### 5.2.2 查看评论\n\n```java\npublic List<DiscussEntity> getDiscuss(String articleId) {\n    Query query = new Query(Criteria.where(\"articleId\").is(articleId));\n    List<DiscussEntity> discussEntityList = mongoTemplate.find(query, DiscussEntity.class);\n    return discussEntityList;\n}\n```\n\n### 5.2.3 追加回复\n\n```java\npublic void addReply(String discussId, DiscussEntity discussEntity) {\n    Query query = new Query(Criteria.where(\"_id\").is(discussId));\n    Update update = new Update().addToSet(\"replay\",discussEntity);\n    mongoTemplate.updateFirst(query,update,DiscussEntity.class);\n}\n```\n\n### 5.2.4 评论点赞\n\n```java\npublic void incrLikeNums(String discussId) {\n    Query query = new Query(Criteria.where(\"_id\").is(discussId));\n    Update update = new Update().inc(\"likeNums\",1);\n    mongoTemplate.updateFirst(query,update,DiscussEntity.class);\n}\n```\n\n# 6 聚合查询\n\n​	MongoDB不仅提供了基础CRUD的功能实现，同时还提供了聚合查询的功能，聚合查询主要用于统计计算的场景， 主要操作包括如：max，min，avg，count，group，mapreduce，aggregate等等。\n\n## 6.1 count\n\n```yacas\n#语法\ndb.collectionName.count()\n```\n\n统计当前集合中的评论数量\n\n```yacas\ndb.comment.count()\n```\n\n\n统计文章id为2的评论数量\n\n```yacas\ndb.comment.count({articleId:\"2\"})\n```\n\n\n```java\npublic Long getTotalCommentNum(Integer articleId) {\n    Query query = new Query(Criteria.where(\"articleId\").is(articleId+\"\"));\n    long count = mongoTemplate.count(query, DiscussEntity.class);\n    return count;\n}\n```\n\n## 6.2 aggregate\n\n```yacas\n#语法\ndb.collectionName.aggregate()\n```\n\n| 表达式    | 描述                                           |\n| --------- | ---------------------------------------------- |\n| $sum      | 计算总和。                                     |\n| $avg      | 计算平均值                                     |\n| $max      | 获取集合中所有文档对应值得最大值。             |\n| $min      | 获取集合中所有文档对应值得最小值。             |\n| $push     | 在结果文档中插入值到一个数组中。               |\n| $addToSet | 在结果文档中插入值到一个数组中，但不创建副本。 |\n| $first    | 根据资源文档的排序获取第一个文档数据。         |\n| $last     | 根据资源文档的排序获取最后一个文档数据。       |\n\n**按文章分组，并获取每个文章的总点赞数**\n\n```yacas\ndb.comment.aggregate([{$group:{_id:\"$articleId\",total:{$sum:\"$likeNums\"}}}])\n```\n\n```java\npublic List<Map> getArticleLikeNums() {\n    TypedAggregation<DiscussEntity> aggregation = Aggregation.newAggregation(DiscussEntity.class,\n                                                                             Aggregation.group(\"articleId\").sum(\"likeNums\").as(\"totalLikeNums\")\n                                                                            );\n    AggregationResults<Map> aggregate = mongoTemplate.aggregate(aggregation, mongoTemplate.getCollectionName(DiscussEntity.class), Map.class);\n    return aggregate.getMappedResults();\n}\n```\n\n**按文章分组，获取点赞数最多的文章**\n\n```yacas\n#对分组结果数据排序，并按降序排序， 1代表升序，-1代表降序\ndb.comment.aggregate([{$group:{_id:\"$articleId\",total:{$sum:\"$likeNums\"}}},{$sort:{total:-1}}])\n```\n\n```yacas\n#对排序后结果，限制结果数量返回\ndb.comment.aggregate([{$group:{_id:\"$articleId\",total:{$sum:\"$likeNums\"}}},{$sort:{total:-1}},{$limit:1}])\n```\n\n```java\npublic Map getMaxLikeNumsArticle() {\n    TypedAggregation<DiscussEntity> aggregation = Aggregation.newAggregation(DiscussEntity.class,\n                                                                             Aggregation.group(\"articleId\").sum(\"likeNums\").as(\"total\"),\n                                                                             Aggregation.sort(Sort.Direction.DESC,\"total\"),\n                                                                             Aggregation.limit(1));\n    AggregationResults<Map> aggregate = mongoTemplate.aggregate(aggregation, mongoTemplate.getCollectionName(DiscussEntity.class), Map.class);\n    return aggregate.getUniqueMappedResult();\n}\n```\n\n# 7 索引\n\n## 7.1 概述\n\n​	MongoDB在读取数据时，会扫描集合中每个文档并选取符合查询条件的记录，这种方式称为全表扫描，查询效率是非常低下的，并且随着数据量的增加，效率会不断下降。\n\n```yacas\ndb.comment.find({\"articleId\":\"1\"}).explain(\"executionStats\")\n```\n\n\n​	为了提升查询效率，MongoDB同MySQL一样也增加了索引， 通过索引能够极大的提高查询效率。 索引是一种特殊的数据结构，存储在单独的数据集合中。\n\n```yacas\n#建立索引\ndb.collectionName.createIndex(keys,[options])\n\n#升序索引:1   降序索引：-1  不同的索引方式，当进行排序操作时，会产生性能影响。\ndb.comment.createIndex({articleId:1})\n```\n\n\n## 7.2 索引属性\n\n| Parameter          | Type          | Description                                                  |\n| :----------------- | :------------ | :----------------------------------------------------------- |\n| background         | Boolean       | 建索引过程会阻塞其它数据库操作，background可指定以后台方式创建索引，即增加 \"background\" 可选参数。 \"background\" 默认值为**false**。 |\n| unique             | Boolean       | 建立的索引是否唯一。指定为true创建唯一索引。默认值为**false**. |\n| name               | string        | 索引的名称。如果未指定，MongoDB的通过连接索引的字段名和排序顺序生成一个索引名称。 |\n| sparse             | Boolean       | 对文档中不存在的字段数据不启用索引；这个参数需要特别注意，如果设置为true的话，在索引字段中不会查询出不包含对应字段的文档.。默认值为 **false**. |\n| expireAfterSeconds | integer       | 指定一个以秒为单位的数值，完成 TTL设定，设定集合的生存时间。 |\n| v                  | index version | 索引的版本号。默认的索引版本取决于mongod创建索引时运行的版本。 |\n| weights            | document      | 索引权重值，数值在 1 到 99,999 之间，表示该索引相对于其他索引字段的得分权重。 |\n| default_language   | string        | 对于文本索引，该参数决定了停用词及词干和词器的规则的列表。 默认为英语 |\n| language_override  | string        | 对于文本索引，该参数指定了包含在文档中的字段名，语言覆盖默认的language，默认值为 language. |\n\n## 7.3 索引类型\n\n### 7.3.1 唯一索引\n\n​	当设置某个域为索引时，则该域的值在集合中不允许出现重复。\n\n```yacas\n#设置userId为唯一索引\ndb.comment.createIndex({userId:1},{\"unique\":true})\n```\n\n```yacas\n#查看索引信息\ndb.comment.getIndexes()\n```\n\n### 7.3.2 复合索引\n\n​	在查询时，当存在多个过滤条件，并且要提升查询效率时，则可以创建复合索引。复合索引是两个以上字段的索引，可以基于这 多个字段进行查询。\n\n```yacas\n#语法\ndb.collectionName.createIndex({key1:1,key2:1})\n```\n\n```yacas\ndb.collectionName.createIndex({articleId:1,content:1})\n```\n\n### 7.3.3 多键索引\n\n​	如果文档中含有array类型字段，可以直接对其名称建立索引，这样MongoDB就会为内嵌数组中的每个元素建立一个独立的索引。但是注意，多键索引不等同于复合索引。\n\n```yacas\n#语法\ndb.collectionName.createIndex({key:< 1 or -1 >})\n```\n\n```yacas\ndb.comment.createIndex({replay:1})\n```\n\n### 7.3.4 TTL索引\n\n​	TTL索引是一种特殊类型的单字段索引，主要用于当满足某个特定时间之后自动删除相应的文档。当设置TTL索引后，超过有效期的文档会被移除。但是对于非日期字段或不包含日期数组的索引字段，文档不会失效。主要适用于过期数据无需保留的场景，如日志，会话信息等。\n\n```yacas\n#语法\ndb.collectionName.createIndex(keys,options)\n\ndb.comment.createIndex({\"lastModifiedDate\":1},{ expireAfterSeconds: 10 })\n```\n\n​	TTL索引的删除不能完全保证失效期后一定删除，存在一定延迟(取决于mongod的工作负载)，同时MongoDB会每隔60s移除一次失效文档，所以可能会存在已过失效期，文档还在的情况。\n\n使用注意事项：\n\n- 不能基于已经存在索引的字段创建TTL索，文档不会失效。\n- 不能基于非日期字段创建TTL索引，文档不会失效 。   \n- TTL索引不支持基于多个字段的复合索引。\n\n## 7.4 注意事项\n\n**1）性能开销**\n\n当对文档会频繁产生修改，如插入，修改和删除时，会产生额外的性能开销，降低性能。因为每个索引占据一定的存储空间。当对文档进行修改时，索引也会相对应发生修改。 所以，如果很少对集合进行读取操作，建议不使用索引。\n\n**2）空间使用**\n\n由于索引是存储在内存(RAM)中,你应该确保该索引的大小不超过内存的限制。如果索引的大小大于内存的限制，MongoDB会删除一些索引，这将导致性能下降。\n\n**3）索引失效**\n\n索引不能被以下的查询使用：\n\n- 正则表达式及非操作符，如 $nin, $not, 等。\n- 算术运算符，如 $mod, 等。\n- $where 子句\n\n**4）索引范围**\n\n- 集合中索引不能超过64个\n- 索引名的长度不能超过128个字符\n- 一个复合索引最多可以有31个字段\n\n# 8 数据存储技术选型对比\n\n现在最常用的数据存储技术有MySQL、Redis、MongoDB、ElasticSearch。\n\n**MySQL**： 支持事务、在海量数据查询情况下，性能低下。 表关系间存在强制关系，数据操作不够灵活。在进行复杂功能查询时，功能相对较弱。适用于存储敏感数据。\n\n**Redis**：直接基于内存，读写性能最高，每个操作都是原子操作，不存在并发问题。四者中存储数据量最少，适用于热点数据场景。 数据不安全，存在丢失的可能，事务性较弱，不适合存储敏感数据，无法像MySQL进行复杂关系建模。\n\n**Mongodb**：查询性能仅次于Redis。但是写入性能仅优于ES，因为写入时，还需要维护索引信息。但其数据格式灵活，通过BSON格式可以描述复杂对象。同时其查询功能非常强大，仅次于ES，但无法完成跨表级联查询。虽然4.0之后版本开始支持事务，但是官方并不建议开启事务。**适用于存储海量，具备结构模型且价值较低的数据，如评论等。**\n\n**ElasticSearch**：其主要关注搜索功能，适用于海量数据查询，且查询功能非常强大。但是数据更新比较慢，需要建立索引，以及数据同步。适用于搜索引擎，数据分析等场景。\n\n数据量：mongoDB>ElasticSearch>Redis\n\n查询性能：Redis>MongoDB>ElasticSearch\n\n写入性能：Redis>MongoDB>ElasticSearch\n\n复杂查询功能：ElasticSearch>MongoDB>Redis', '2021-11-30 10:26:00', 0, '2022-02-08 10:27:33', 0);
INSERT INTO `m_blog` VALUES (12, 1, '非关系型数据库--ElasticSearch 01', 'ElasticSearch-01', '#   ElasticSearch-day01\n\n# 1 关系型数据库查询存在的问题\n\n​	在进行数据操作时，很多时候都是操作的关系型数据库，如Mysql。但当Mysql中数据量非常庞大后，会造成数据查询效率明显下降，那么此时就会考虑进行一些优化措施，如添加索引。但当添加索引后，在一些查询情况下，也有可能造成索引失效的问题，如 LIKE ‘%手’。总结两点：\n\n- 海量数据搜索效率低\n- 查询功能不完备\n\n# 2 搜索引擎介绍\n\n## 2.1 概述\n\n\n\n​	搜索在现代日常生活场景中都非常常见，如百度、京东、天猫等等。数据量都是庞大的，所以直接基于数据库搜索必定不是他们的首选，在这些场景下，要完成数据的高效搜索，都会基于搜索引擎实现。\n\n​	而对于搜索实现来说，市面上常见三种技术：Lucene、Solr、ElasticSearch。Lucene严格意义来讲，并不能称为搜索引擎，其本身是一套类库，需要开发人员根据其内部API完成具体功能实现。而Solr和ElasticSearch都是基于Lucene进行了封装，他俩可以称为搜索引擎。但由于实现细节的不同，所以ElasticSearch是目前搜索引擎的首选。\n\n​	ElasticSearch是一个开源的、支持分布式的、能够进行近实时搜索和分析、能够处理PB级数据量的搜索引擎。目前有很多平台和工作场景会涉及到对ElasticSearch的使用\n\n- 维基百科数据搜索\n- Github数据搜索\n- 电商平台商品搜索\n- 数据分析和挖掘\n\n## 2.2 ElasticSearch和MySQL的区别\n\n- Mysql数据操作具备事务性，而ElasticSearch没有\n- MySQL支持外键，而ElasticSearch不支持\n- Mysql采用B+树索引，而ElasticSearch采用倒排索引\n\n# 3 基于docker安装ElasticSearch与kibana客户端\n\n## 3.1 安装ElasticSearch\n\n1）下载ElasticSearch7.10.1镜像\n\n```yacas\ndocker pull elasticsearch:7.10.1\n```\n\n2）创建ElasticSearch配置文件夹\n\n```shell\nmkdir -p /mydata/elasticsearch/{config,data,plugins}\n```\n\n3）配置中配置ip信息\n\n```shell\necho \"http.host: 0.0.0.0\" > /mydata/elasticsearch/config/elasticsearch.yml\n```\n\n4）配置文件夹权限\n\n```shell\nchmod -R 775 /mydata/elasticsearch/\n```\n\n5）启动容器并配置端口映射与目录映射\n\n```shell\ndocker run --name elasticsearch -p 9200:9200 -p 9300:9300 \\\n-e \"discovery.type=single-node\" \\\n-e ES_JAVA_OPTS=\"-Xms64m -Xmx128m\" \\\n-v /mydata/elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml \\\n-v /mydata/elasticsearch/data:/usr/share/elasticsearch/data \\\n-v /mydata/elasticsearch/plugins:/usr/share/elasticsearch/plugins \\\n-d elasticsearch:7.10.1\n```\n\n6）确定是否启动成功\n\n\n\n## 3.2 安装Kibana\n\n​	Kibana是一个开源的分析与可视化平台，主要和ElasticSearch搭配使用。从而可以通过可视化界面完成对于ElasticSearch的各种操作。\n\n1）下载Kibana7.10.1镜像\n\n```yacas\ndocker pull kibana:7.10.1\n```\n\n2）创建配置文件夹\n\n```shell\nmkdir -p  /mydata/kibana/config\ncd   /mydata/kibana/config\ntouch kibana.yml\n```\n\n3）创建并修改配置文件\n\n```yml\n#\n# ** THIS IS AN AUTO-GENERATED FILE **\n#\n\n# Default Kibana configuration for docker target\n# 根据自己实际IP修改elasticsearch地址\nserver.name: kibana\nserver.host: \"0\"\nelasticsearch.hosts: [ \"http://192.168.217.134:9200\" ]\nxpack.monitoring.ui.container.elasticsearch.enabled: true\ni18n.locale: \"zh-CN\"\n```\n\n4）启动容器\n\n```shell\ndocker run -d \\\n  --name=kibana \\\n  --restart=always \\\n  -p 5601:5601 \\\n  -v /mydata/kibana/config/kibana.yml:/usr/share/kibana/config/kibana.yml \\\n  kibana:7.10.1\n```\n\n5）访问效果如下\n\n\n\n6）使用演示\n\n点击页面中的`Dev Tools`\n\n\n\n进入如下页面\n\n\n\n点击`执行`按钮，查询ES中所有数据\n\n\n# 4 ElasticSearch核心概念介绍\n\n​	ES在使用时，会涉及到五个核心概念：索引（Index）、映射（Mapping）、域（Field）、文档（Document）、倒排索引。以一张MySQL中数据表为例。\n\n\n\n| ElasticSearch    | Mysql            |\n| ---------------- | ---------------- |\n| 索引（Index）    | 表（Table）      |\n| 映射（Mapping）  | 表结构           |\n| 域（Field）      | 字段列（Column） |\n| 文档（Document） | 一条数据（Row）  |\n\n`注：在老版本ElasticSearch中还有一个概念Type，用于进行数据分类，但是在ES7开始已经将Type移除`\n\n## 4.1 索引（Index）\n\n​	索引相当于关系型数据库中的一张表，一个index包含若干document，通过Index代表一类类似的或者相同的document。\n\n### 4.1.1 添加索引\n\n```yacas\n#PUT 索引名称\nPUT person\n```\n\n\n\n### 4.1.2 查询索引\n\n```yacas\n#查询单个索引 GET 索引名称\nGET person\n```\n\n\n\n```yacas\n# 查询多个索引信息 GET 索引名称,索引名称\nPUT person1\nGET person,person1\n```\n\n\n```yacas\n# 查询所有索引信息\nGET _all\n```\n\n\n\n### 4.1.3 删除索引\n\n```yacas\n#删除索引 DELETE 索引名称\nDELETE person1\n```\n\n## 4.2 域（Field）\n\n​	域（Field）相当于数据表中的字段列，当有了索引之后，需要**在索引中设置域的相关信息**如：名称，类型等。这个过程称为：**映射（Mapping）**。相当于关系型数据库中设置表的信息。\n\n\n### 4.2.1 数据类型\n\n**字符串**\n\n- text：会进行分词，如华为手机，会分成：华为，手机。 **被分出来的每一个词，称为term（词条）**\n- keyword：不会进行分词，如华为手机，只有一个词条，即华为手机。\n\n**数值**\n\n- long：带符号64位整数\n- integer：带符号32位整数\n- short：带符号16位整数\n- byte：带符号8位整数\n- double：双精度64位浮点数\n- float：单精度32位浮点数\n- half_float：半精度16位浮点数\n\n**布尔：**\n\n- boolean\n\n**二进制：**\n\n- binary\n\n**日期：**\n\n- date\n\n**范围类型：**\n\n- integer_range\n- float_range\n- long_range\n- double_range\n- date_range\n\n**数组**\n\n**对象**\n\n### 4.2.2 添加映射\n\n**1）为已存在的索引库添加映射**\n\n```yacas\nPUT person/_mapping\n{\n  \"properties\":{\n    \"name\":{\n      \"type\":\"text\"\n    },\n    \"age\":{\n      \"type\":\"integer\"\n    }\n  }\n}\n```\n\n\n```yacas\n#查看索引映射信息\nGET person/_mapping\n```\n\n\n**2）创建索引并添加映射**\n\n```yacas\nPUT user\n{\n  \"mappings\": {\n    \"properties\": {\n      \"name\": {\n        \"type\": \"text\"\n      },\n      \"age\": {\n        \"type\": \"integer\"\n      }\n    }\n  }\n}\n```\n\n\n**3）添加字段**\n\n对于映射，只能进行字段添加，不能对字段进行修改或删除，如有需要，则重新创建映射。\n\n```yacas\nPUT user/_mapping\n{\n  \"properties\":{\n    \"name\": {\n        \"type\": \"text\"\n      },\n      \"age\": {\n        \"type\": \"integer\"\n      },\n      \"address\":{\n        \"type\":\"text\"\n      }\n  }\n}\n```\n\n\n## 4.3 文档（Document）\n\nES中最小的数据单元，代表索引中的一条数据，通常是使用json的数据格式表示的\n\n### 4.3.1 添加文档\n\n**1）添加文档，手动设置id**\n\n```yacas\nPOST person/_doc/1\n{\n  \"name\":\"张三\",\n  \"age\":18,\n  \"address\":\"北京\"\n}\n```\n\n\n**2）添加文档，自动生成id**\n\n```yacas\nPOST person/_doc\n{\n  \"name\":\"李四\",\n  \"age\":20,\n  \"address\":\"北京\"\n}\n```\n\n### 4.3.2 查询文档\n\n**1）根据id查询文档**\n\n```yacas\n#GET 索引名称/_doc/文档id\nGET person/_doc/1\n```\n\n\n**2）查询所有文档**\n\n```yacas\n#GET 索引名称/_search\nGET person/_search\n```\n\n\n### 4.3.3 修改文档\n\n```yacas\nPUT person/_doc/1\n{\n  \"name\": \"张三丰\",\n  \"age\": 180,\n  \"address\": \"武当山\"\n}\n```\n\n### 4.3.4 删除文档\n\n```yacas\n#DELETE 索引名称/_doc/文档id\nDELETE person/_doc/1\n```\n\n\n## 4.4 倒排索引\n\n​	要想理解倒排索引，首先先思考一个问题，获取某个文件夹下所有文件名中包含Spring的文件\n\n```\n1）确定要搜索的文件夹\n2）遍历文件夹下所有文件\n3）判断文件名中是否包含Spring\n```\n\n这种思维可以理解为是一种正向思维的方式，从外往内，根据key找value。这种方式可以理解为正向索引。\n\n而ElasticSearch为了提升查询效率，采用反向思维方式，根据value找key。\n\n以下列数据为例\n\n\n当将这部分数据从MySQL存入ElasticSearch时，表中的每条记录转换为document存入到索引库中。而ElasticSearch会根据每一个需要分词的域建立词条映射结构，这个结构就是倒排索引\n\n\n当客户端要进行搜索时，假设输入华为，都会根据倒排索引结构，快速定位到id为1和3的文档，然后将数据返回给客户端。\n\n# 5 ElasticSearch入门API\n\n## 5.1 SpringBoot整合ElasticSearch\n\n**1）建立Maven工程，并引入相关坐标**\n\n```xml\n<!--引入es的坐标-->\n<dependency>\n    <groupId>org.elasticsearch.client</groupId>\n    <artifactId>elasticsearch-rest-high-level-client</artifactId>\n    <version>7.10.1</version>\n</dependency>\n<dependency>\n    <groupId>org.elasticsearch.client</groupId>\n    <artifactId>elasticsearch-rest-client</artifactId>\n    <version>7.10.1</version>\n</dependency>\n<dependency>\n    <groupId>org.elasticsearch</groupId>\n    <artifactId>elasticsearch</artifactId>\n    <version>7.10.1</version>\n</dependency>\n```\n\n**2）创建核心配置文件application.yml**\n\n```yml\nelasticsearch:\n  host: 192.168.200.155\n  port: 9200\n```\n\n**3）创建启动类EsApplication**\n\n```java\n@SpringBootApplication\npublic class EsApplication {\n\n    public static void main(String[] args) {\n        SpringApplication.run(EsApplication.class,args);\n    }\n}\n```\n\n**4）创建es配置类**\n\n```java\n@Configuration\n@ConfigurationProperties(prefix=\"elasticsearch\")\npublic class ElasticSearchConfig {\n\n    private String host;\n\n    private int port;\n\n\n    public String getHost() {\n        return host;\n    }\n\n    public void setHost(String host) {\n        this.host = host;\n    }\n\n    public int getPort() {\n        return port;\n    }\n\n    public void setPort(int port) {\n        this.port = port;\n    }\n\n    @Bean\n    public RestHighLevelClient restHighLevelClient(){\n        RestClientBuilder builder = RestClient.builder(new HttpHost(host, port, \"http\"));\n        builder.setRequestConfigCallback(requestConfigBuilder ->{\n            requestConfigBuilder.setConnectionRequestTimeout(500000);\n            requestConfigBuilder.setSocketTimeout(500000);\n            requestConfigBuilder.setConnectTimeout(500000);\n            return requestConfigBuilder;\n        });\n        return new RestHighLevelClient(builder);\n    }\n}\n```\n\n**5）创建测试类ESTest**\n\n```java\n@SpringBootTest\n@RunWith(SpringRunner.class)\npublic class ESTest {\n    \n    @Autowired\n    private RestHighLevelClient restHighLevelClient;\n}\n```\n\n## 5.2 创建索引\n\n```java\n@Test\npublic void createIndex() throws IOException {\n\n    IndicesClient indicesClient = restHighLevelClient.indices();\n\n    CreateIndexRequest createIndex = new CreateIndexRequest(\"itheima\");\n\n    String info = \"{\\n\" +\n        \"  \\\"properties\\\":{\\n\" +\n        \"    \\\"name\\\":{\\n\" +\n        \"      \\\"type\\\":\\\"keyword\\\"\\n\" +\n        \"    },\\n\" +\n        \"    \\\"age\\\":{\\n\" +\n        \"      \\\"type\\\":\\\"integer\\\"\\n\" +\n        \"    },\\n\" +\n        \"    \\\"address\\\":{\\n\" +\n        \"      \\\"type\\\":\\\"text\\\"\\n\" +\n        \"    }\\n\" +\n        \"  }\\n\" +\n        \"}\";\n    createIndex.mapping(info, XContentType.JSON);\n\n    CreateIndexResponse response = indicesClient.create(createIndex, RequestOptions.DEFAULT);\n\n    System.out.println(response.isAcknowledged());\n}\n```\n\n## 5.3 查询索引\n\n```java\n@Test\npublic void findIndex() throws IOException {\n\n    IndicesClient indicesClient = restHighLevelClient.indices();\n\n    GetIndexRequest getIndexRequest = new GetIndexRequest(\"itheima\");\n    \n    GetIndexResponse response = indicesClient.get(getIndexRequest, RequestOptions.DEFAULT);\n\n    Map<String, MappingMetadata> mappings = response.getMappings();\n    for (String key : mappings.keySet()) {\n        System.out.println(key+\"===\"+mappings.get(key).getSourceAsMap());\n    }\n}\n```\n\n## 5.4 删除索引\n\n```java\n@Test\npublic void delIndex() throws IOException {\n\n    IndicesClient indicesClient = restHighLevelClient.indices();\n\n    DeleteIndexRequest delIndexRequest = new DeleteIndexRequest(\"person\");\n    \n    AcknowledgedResponse response = indicesClient.delete(delIndexRequest, RequestOptions.DEFAULT);\n\n    System.out.println(response.isAcknowledged());\n}\n```\n\n## 5.5 添加文档\n\n**1）以Map作为数据源**\n\n```java\n@Test\npublic void addDoc1() throws IOException {\n\n    Map<String, Object> map=new HashMap<>();\n    map.put(\"name\",\"张三\");\n    map.put(\"age\",18);\n    map.put(\"address\",\"北京二环\");\n    \n    IndexRequest indexRequest = new IndexRequest(\"itheima\").id(\"1\").source(map);\n    \n    IndexResponse response = restHighLevelClient.index(indexRequest, RequestOptions.DEFAULT);\n\n    System.out.println(response.getId());\n}\n```\n\n**2）以对象作为数据源**\n\n```java\n@Data\npublic class Person {\n    private String id;\n\n    private String name;\n\n    private int age;\n\n    private String address;\n}\n```\n\n```java\n@Test\npublic void addDoc2() throws IOException {\n\n    Person person=new Person();\n    person.setId(\"2\");\n    person.setName(\"李四\");\n    person.setAge(30);\n    person.setAddress(\"北京北五环\");\n\n    String source = JSON.toJSONString(person);\n    \n    IndexRequest indexRequest = new IndexRequest(\"itheima\").id(\"2\").source(source,XContentType.JSON);\n\n    IndexResponse response = restHighLevelClient.index(indexRequest, RequestOptions.DEFAULT);\n    \n    System.out.println(response.getId());\n}\n```\n\n`在ES中，对于文档修改和文档添加代码相同，如果id在索引中不存在则进行文档添加，如果id在索引中存在则进行文档修改`\n\n## 5.6 根据id查询文档\n\n```java\n@Test\npublic void findDocById() throws IOException {\n\n    GetRequest getRequest = new GetRequest(\"itheima\").id(\"2\");\n    \n    GetResponse getResponse = restHighLevelClient.get(getRequest, RequestOptions.DEFAULT);\n\n    System.out.println(getResponse.getSourceAsString());\n}\n```\n\n## 5.7 删除文档\n\n```java\n@Test\npublic void delDocById() throws IOException {\n\n    DeleteRequest delRequest = new DeleteRequest(\"itheima\").id(\"2\");\n    \n    DeleteResponse response = restHighLevelClient.delete(delRequest, RequestOptions.DEFAULT);\n    \n    System.out.println(response.status());\n}\n```\n\n# 6 环境准备与案例工程导入\n\n## 6.1 前端环境准备\n\n​	当前采用前后端分离开发，前端需要安装node.js 和 npm。具体安装步骤请查看`前端环境准备帮助手册`\n\n## 6.2 数据库数据准备\n\n​	导入`/05_资料/es.sql文件`，完成初始化库表创建与数据准备\n\n## 6.3 索引及映射准备\n\n```json\nPUT hotel\n{\n  \"mappings\": {\n    \"properties\": {\n      \n      \"name\":{\n        \"type\": \"text\"\n      },\n      \"address\":{\n        \"type\": \"text\"\n      },\n      \"brand\":{\n        \"type\": \"keyword\"\n      },\n      \"type\":{\n        \"type\": \"keyword\"\n      },\n       \"price\":{\n        \"type\": \"integer\"\n      },\n      \"specs\":{\n        \"type\": \"keyword\"\n      },\n       \"salesVolume\":{\n        \"type\": \"integer\"\n      },\n      \"area\":{\n        \"type\": \"text\"\n      },\n      \"imageUrl\":{\n        \"type\": \"text\"\n      },\n      \"synopsis\":{\n        \"type\": \"text\"\n      },\n      \"createTime\":{\n        \"type\": \"date\",\n        \"format\": \"yyyy-MM-dd\"\n      },\n      \"isAd\":{\n        \"type\":\"integer\"\n      }\n    }\n  }\n}\n```\n\n## 6.4 ES工程导入\n\n​	初始工程已上传Gitee，下载地址：\n\n```yacas\nhttps://gitee.com/Hui900521/es.git\n```\n\n​	或导入`05_资料/基础工程`\n\n# 7 批量数据导入\n\n## 7.1 kibana演示\n\n​	在ES中提供了批量操作的方式，可以将多个操作合并到一起进行执行。\n\n```yacas\n#新增一号用户\n#删除一号用户\n#新增二号用户\nPOST _bulk\n{\"create\":{\"_index\":\"user\",\"_id\":\"1\"}}\n{\"name\":\"张三\",\"age\":18,\"address\":\"北京\"}\n{\"delete\":{\"_index\":\"user\",\"_id\":\"1\"}}\n{\"create\":{\"_index\":\"user\",\"_id\":\"2\"}}\n{\"name\":\"李四\",\"age\":20,\"address\":\"黑龙江\"}\n```\n\n## 7.2 功能实现\n\n**1）新增接口方法**\n\n```java\nint addDocToES();\n```\n\n**2）修改业务层实现类，对其实现**\n\n```java\npublic int addDocToES() {\n\n    BulkRequest bulkRequest = new BulkRequest();\n\n    List<HotelEntity> hotelEntityList = hotelMapper.selectList(null);\n\n    for (HotelEntity hotelEntity : hotelEntityList) {\n\n         String data = JSON.toJSONStringWithDateFormat(hotelEntity,\"yyyy-MM-dd\", SerializerFeature.WriteDateUseDateFormat);\n        IndexRequest indexRequest = new IndexRequest(\"hotel\").source(data, XContentType.JSON);\n        bulkRequest.add(indexRequest);\n    }\n\n    try {\n        BulkResponse response = restHighLevelClient.bulk(bulkRequest, RequestOptions.DEFAULT);\n\n        return response.status().getStatus();\n    } catch (IOException e) {\n        e.printStackTrace();\n    }\n    return 0;\n}\n```\n\n**3）修改controller层**\n\n```java\n@PostMapping(\"/addAll\")\npublic int addAll(){\n    return hotelService.addDocToES();\n}\n```\n\n**4）postman测试**\n\n**5）kibana查询数据**\n\n# 8 查询所有酒店\n\n## 8.1 Kibana演示\n\n```yacas\nGET hotel/_search\n{\n  \"query\": {\n    \"match_all\": {}\n  }\n}\n```\n\n\n## 8.2 功能实现\n\n**1）业务层接口新增方法**\n\n```java\nMap<String, Object> matchAllQuery();\n```\n\n**2）修改业务层实现类**\n\n```java\npublic Map<String, Object> matchAllQuery() {\n\n    SearchRequest searchRequest = new SearchRequest(\"hotel\");\n\n    SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();\n\n    QueryBuilder queryBuilder = QueryBuilders.matchAllQuery();\n    searchSourceBuilder.query(queryBuilder);\n    searchRequest.source(searchSourceBuilder);\n    try {\n        SearchResponse searchResponse = restHighLevelClient.search(searchRequest, RequestOptions.DEFAULT);\n\n        SearchHits hits = searchResponse.getHits();\n\n        long totalHits = hits.getTotalHits().value;\n\n        SearchHit[] searchHits = hits.getHits();\n\n        List<HotelEntity> list = new ArrayList<>();\n\n        for (SearchHit searchHit : searchHits) {\n            String sourceAsString = searchHit.getSourceAsString();\n            list.add(JSON.parseObject(sourceAsString,HotelEntity.class));\n        }\n        Map<String, Object> map = new HashMap<>();\n        map.put(\"list\", list);\n        map.put(\"totalResultSize\", totalHits);\n\n        return map;\n    } catch (IOException e) {\n        e.printStackTrace();\n    }\n\n    return null;\n}\n```\n\n**3）修改表现层**\n\n```java\n@GetMapping(\"/list\")\npublic Map<String, Object> queryHotelList() {\n    Map<String, Object> map = hotelService.matchAllQuery();\n    return this.getJsonMap(true, \"\", map);\n}\n```\n\n**4）postman测试**\n\n\n**5）前端工程效果展示**\n\n访问前端工程：http://localhost:8088/dist/view/list.html\n\n\n# 9 分页查询酒店列表\n\n## 9.1 Kibana演示\n\n```yacas\nGET hotel/_search\n{\n  \"query\": {\n    \"match_all\": {}\n  },\n  \"from\": 0,\n  \"size\": 5\n}\n```\n\n## 9.2 功能实现\n\n**1）修改业务层接口**\n\n```java\nMap<String, Object> pageQuery(int current, int size);\n```\n\n**2）修改业务层实现类**\n\n```java\npublic Map<String, Object> pageQuery(int current, int size) {\n\n    SearchRequest searchRequest = new SearchRequest(\"hotel\");\n\n    SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();\n\n    QueryBuilder queryBuilder = QueryBuilders.matchAllQuery();\n    searchSourceBuilder.query(queryBuilder);\n\n    //设置分页\n    searchSourceBuilder.from((current-1)*size);\n    searchSourceBuilder.size(size);\n\n    searchRequest.source(searchSourceBuilder);\n    try {\n        SearchResponse searchResponse = restHighLevelClient.search(searchRequest, RequestOptions.DEFAULT);\n\n        SearchHits hits = searchResponse.getHits();\n\n        long totalHits = hits.getTotalHits().value;\n\n        SearchHit[] searchHits = hits.getHits();\n\n        List<HotelEntity> list = new ArrayList<>();\n\n        for (SearchHit searchHit : searchHits) {\n            String sourceAsString = searchHit.getSourceAsString();\n            list.add(JSON.parseObject(sourceAsString,HotelEntity.class));\n        }\n\n        Map<String, Object> map = new HashMap<>();\n        map.put(\"list\", list);\n        map.put(\"totalResultSize\", totalHits);\n        map.put(\"current\", current);\n        //设置总页数\n        map.put(\"totalPage\",(totalHits+size-1)/size);\n\n        return map;\n    } catch (IOException e) {\n        e.printStackTrace();\n    }\n\n    return null;\n}\n```\n\n**3）修改表现层**\n\n```java\n@GetMapping(\"/page/list\")\npublic Map<String, Object> page(@PathParam(\"current\") Integer current, @PathParam(\"pageSize\") Integer pageSize) {\n    Map<String, Object> map = hotelService.pageQuery(current, pageSize);\n    return this.getJsonMap(true, \"\", map);\n}\n```\n\n**4）postman测试**\n\n\n**5）前端工程效果展示**\n\n访问前端工程：http://localhost:8088/dist/view/listPage.html\n', '2021-12-01 11:47:42', 0, NULL, 0);
INSERT INTO `m_blog` VALUES (13, 1, '非关系型数据库--ElasticSearch 02', 'ElasticSearch-02', '#  ElasticSearch-day02\n\n# 1 搜索框-品牌精确搜索\n\n## 1.1 需求分析\n\n​	在搜索页面条件栏上：当点击选择不同酒店名称时，需展示出该品牌下的所有酒店信息，并且分页形式进行数据展示。\n## 1.2 Kibana查询\n\n**termQuery：不会对查询条件进行分词**\n\n**查询设置**\n\n```yacas\nGET hotel/_search\n{\n  \"query\": {\n    \"term\": {\n      \"brand\": \"万豪\"\n    }\n  }\n}\n```\n\n**返回结果**\n\n\n## 1.3 JavaAPI查询\n\n**1）HotelController**\n\n```java\n//根据品牌精确查询\n@GetMapping(\"/searchTermQuery\")\npublic Map<String, Object> searchTermQuery(@RequestParam Map<String, Object> searchParam, @PathParam(\"current\") Integer current, @PathParam(\"pageSize\") Integer pageSize) {\n    Map<String, Object> map = hotelService.brandTermQuery(current, pageSize, searchParam);\n    return this.getJsonMap(true, \"\", map);\n}\n```\n\n**2）HotelService**\n\n```java\n/**\n     * 根据品牌精确查询\n     * @param searchParam\n     * @return\n     */\nMap<String, Object> brandTermQuery(int currentPage, int size,Map<String,Object> searchParam);\n```\n\n**3）HotelServiceImpl**\n\n```java\npublic Map<String, Object> brandTermQuery(int current, int size, Map<String, Object> searchParam) {\n	\n    SearchRequest searchRequest = new SearchRequest(\"hotel\");\n\n    SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();\n\n    //设置精确查询\n    if (!StringUtils.isEmpty(searchParam.get(\"brand\"))) {\n        QueryBuilder queryBuilder = QueryBuilders.termQuery(\"brand\", searchParam.get(\"brand\").toString());\n        searchSourceBuilder.query(queryBuilder);\n    }\n\n    //设置分页\n    searchSourceBuilder.from((current - 1) * size);\n    searchSourceBuilder.size(size);\n\n    searchRequest.source(searchSourceBuilder);\n    try {\n        SearchResponse searchResponse = restHighLevelClient.search(searchRequest, RequestOptions.DEFAULT);\n\n        SearchHits hits = searchResponse.getHits();\n\n        long totalHits = hits.getTotalHits().value;\n\n        SearchHit[] searchHits = hits.getHits();\n\n        List<HotelEntity> list = new ArrayList<>();\n\n        for (SearchHit searchHit : searchHits) {\n            String sourceAsString = searchHit.getSourceAsString();\n            list.add(JSON.parseObject(sourceAsString, HotelEntity.class));\n        }\n\n        Map<String, Object> map = new HashMap<>();\n        map.put(\"list\", list);\n        map.put(\"totalResultSize\", totalHits);\n        map.put(\"current\", current);\n        //设置总页数\n        map.put(\"totalPage\", (totalHits + size - 1) / size);\n\n        return map;\n    } catch (IOException e) {\n        e.printStackTrace();\n    }\n\n    return null;\n}\n```\n\n## 1.4 测试&效果展示\n\n### 1.4.1 **PostMan访问：**\n\n```\nlocalhost:9001/hotel/searchTermQuery?current=1&pageSize=10\n```\n\n**body中携带数据：KEY: brand   Value:查询条件**\n\n### 1.4.2 前端效果展示：\n\n​	http://localhost:8088/dist/view/listBrand.html\n\n\n# 2 中文分词器\n\n## 2.1 分词问题演示&分析\n\n### 2.1.1 问题效果演示\n\n​	根据刚才的搜索结果，可以看到查询出了很多万豪相关的酒店，现在以`北京市东城区万豪酒店`查询name域，可以发现无法查询到结果。\n\n```yacas\nGET hotel/_search\n{\n  \"query\": {\n    \"term\": {\n      \"name\": \"北京市东城区万豪酒店\"\n    }\n  }\n}\n```\n\n\n### 2.1.2 问题原因分析\n\n​	在创建索引时，对于name域，数据类型是`text`。当添加文档时，对于该域的值会进行分词，形成若干term（词条）存储在倒排索引中。\n\n​	根据倒排索引结构，当查询条件在词条中存在，则会查询到数据。如果词条中没有，则查询不到数据。\n\n​	那么对于`北京市东城区万豪酒店`的分词结果是什么呢？\n\n```yacas\nGET _analyze\n{\n  \"text\": \"北京市东城区万豪酒店\"\n}\n```\n\n\n​	此时可以发现，每个字形成了一个词，所以并没有找到相匹配的词，导致无法查询到结果\n\n## 2.2 分词器介绍\n\n在ElasticSearch默认内置了多种分词器：\n\n• **Standard Analyzer** - 默认分词器，按英文空格切分 \n\n• Simple Analyzer - 按照非字母切分(符号被过滤)\n\n• Stop Analyzer - 小写处理，停用词过滤(the,a,is) \n\n• Whitespace Analyzer - 按照空格切分，不转小写 \n\n• Keyword Analyzer - 不分词，直接将输入当作输出 \n\n• Patter Analyzer - 正则表达式，默认\\W+(非字符分割) \n\n对于默认的Standard Analyzer分词器，会将每个汉字形成一个词。效果如下：\n\n```yacas\nGET _analyze\n{\n  \"analyzer\": \"standard\",\n  \"text\": \"北京市东城区万豪酒店\"\n}\n```\n\n\n​	而我们想要的是，分词器能够智能的将中文按照词义分成若干个有效的词。此时就需要额外安装中文分词器。 对于中文分词器的类型也有很多，其中首选的是：IK分词器。\n\n​	IK分词器是中国人开发的一款智能中文分词器，其基于Java语言开发、具有60万字/秒的高速处理能力。并且用户可以按需求，设置停用词与扩展词。\n\n## 2.3 IK分词器安装\n\n1）上传IK安装包\n\n​	将`05_资料/elasticsearch-analysis-ik-7.10.1.zip`上传到服务器的/tmp目录下\n\n2）将压缩包移动到容器中\n\n```yacas\ndocker cp /tmp/elasticsearch-analysis-ik-7.10.1.zip elasticsearch:/usr/share/elasticsearch/plugins\n```\n\n3）进入ES容器\n\n```yacas\ndocker exec -it elasticsearch /bin/bash\n```\n\n7）解压\n\n```yacas\nunzip elasticsearch-analysis-ik-7.10.1.zip\n```\n\n8）删除压缩包\n\n```yacas\nrm -rf elasticsearch-analysis-ik-7.10.1.zip\n\n//修改解压文件的名字\nmv elasticsearch-analysis-ik-7.10.1/ ik\n```\n\n9）退出ES容器并重启容器\n\n```yacas\nexit\n\ndocker restart elasticsearch\n```\n\n## 2.4 IK分词器使用\n\n### 2.4.1 分词模式\n\nIK分词器有两种分词模式：`ik_max_word`和`ik_smart`模式\n\n**ik_max_word：细粒度分词**\n\n```yacas\nGET /_analyze\n{\n  \"analyzer\": \"ik_max_word\",\n  \"text\": \"北京市东城区万豪酒店\"\n}\n```\n\n\n**ik_smart：粗粒度分词**\n\n```yacas\nGET /_analyze\n{\n  \"analyzer\": \"ik_smart\",\n  \"text\": \"北京市东城区万豪酒店\"\n}\n```\n\n\n### 2.4.2 配置自定义词库\n\n#### 2.4.2.1 定义扩展词\n\n​	IK虽然非常智能，但是中华语言博大精深，其并不能完全识别所有的词，如店名、网络词语等等。所以IK提供了扩展词库，用户可以按需求添加自定义分词数据。\n\n1）进入ES容器\n\n```yacas\ndocker exec -it elasticsearch /bin/bash\n```\n\n2）进入IK分词器目录\n\n```yacas\ncd /usr/share/elasticsearch/plugins/ik/config\n```\n\n3）创建my.dic文件，并且设置编码格式为UTF-8 无BOM格式。编辑该文件填入`万豪`并上传到config目录下。\n\n\n4）重启es容器，并在Kibana进行测试。\n\n\n#### 2.4.2.2 定义停用词\n\n​	在进行搜索时，有时对于一些敏感词汇需要不能进行结果查询，这时就需要将这些词禁用，在IK分词器中也提供了该功能，用户可以自定义一些停用词\n\n\n1）在Kibana中对`金小胖真帅`进行分词。可以发现`小胖`会作为一个词出现。\n\n\n2）如要将该次禁用，则将容器内的extra_stopword.dic拷贝到宿主机下\n\n```yacas\ndocker cp elasticsearch:/usr/share/elasticsearch/plugins/ik/config/extra_stopword.dic /tmp\n```\n\n3）编辑该文件，新增`小胖`\n\n\n4）将文件从宿主机拷贝到es容器内\n\n```yacas\ndocker cp extra_stopword.dic elasticsearch:/usr/share/elasticsearch/plugins/ik/config\n```\n\n5）修改容器内IKAnalyzer.cfg.xml\n\n```yacas\ndocker exec -it elasticsearch /bin/bash\n\ncd /usr/share/elasticsearch/plugins/ik/config\n\nvi IKAnalyzer.cfg.xml\n\n#修改配置文件\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<!DOCTYPE properties SYSTEM \"http://java.sun.com/dtd/properties.dtd\">\n<properties>\n	<comment>IK Analyzer 扩展配置</comment>\n	<!--用户可以在这里配置自己的扩展字典 -->\n	<entry key=\"ext_dict\">my.dic</entry>\n	 <!--用户可以在这里配置自己的扩展停止词字典-->\n	<entry key=\"ext_stopwords\">extra_stopword.dic</entry>\n	<!--用户可以在这里配置远程扩展字典 -->\n	<!-- <entry key=\"remote_ext_dict\">words_location</entry> -->\n	<!--用户可以在这里配置远程扩展停止词字典-->\n	<!-- <entry key=\"remote_ext_stopwords\">words_location</entry> -->\n</properties>\n```\n\n6）重启ES容器\n\n```yacas\ndocker restart elasticsearch\n```\n\n7）Kibana中重新分词，可以发现`小胖`已经消失\n\n\n### 2.4.3 重建索引指定分词器\n\n```yacas\nDELETE hotel\n\nPUT hotel\n{\n  \"mappings\": {\n    \"properties\": {\n      \n      \"name\":{\n        \"type\": \"text\",\n        \"analyzer\": \"ik_max_word\"\n      },\n      \"address\":{\n        \"type\": \"text\",\n        \"analyzer\": \"ik_max_word\"\n      },\n      \"brand\":{\n        \"type\": \"keyword\"\n      },\n      \"type\":{\n        \"type\": \"keyword\"\n      },\n       \"price\":{\n        \"type\": \"integer\"\n      },\n      \"specs\":{\n        \"type\": \"keyword\"\n      },\n       \"salesVolume\":{\n        \"type\": \"integer\"\n      },\n      \"area\":{\n        \"type\": \"text\",\n        \"analyzer\": \"ik_max_word\"\n      },\n      \"imageUrl\":{\n        \"type\": \"text\"\n      },\n      \"synopsis\":{\n        \"type\": \"text\",\n        \"analyzer\": \"ik_max_word\"\n      },\n      \"createTime\":{\n        \"type\": \"date\",\n        \"format\": \"yyyy-MM-dd\"\n      },\n      \"isAd\":{\n        \"type\":\"integer\"\n      }\n    }\n  }\n}\n```\n\n# 3 搜索框-酒店名称分词搜索\n\n## 3.1 需求分析\n\n​	当在搜索框中输入酒店名称时，需要将搜索条件分词，然后展示出所有与分词匹配的酒店信息\n\n\n## 3.2 Kibana查询\n\nmatchQuery：会对查询条件分词，将分词后的结果进行逐一匹配，默认取结果并集。\n\n```yacas\nGET hotel/_search\n{\n  \"query\": {\n    \"match\": {\n     \"name\":\"北京市东城区瑞麟湾酒店\"\n    }\n  }\n}\n```\n\n\n## 3.3 JavaAPI查询\n\n**1）HotelController**\n\n```java\n@GetMapping(\"/searchMatchQuery\")\npublic Map<String, Object> searchMatchQuery(@RequestParam Map<String, Object> searchParam, @PathParam(\"current\") Integer current, @PathParam(\"pageSize\") Integer pageSize) {\n    Map<String, Object> map = hotelService.nameMatchQuery(current, pageSize, searchParam);\n    return this.getJsonMap(true, \"\", map);\n}\n```\n\n**2）HotelService**\n\n```java\n/**\n     * 根据酒店名称条件分词查询\n     * @param current\n     * @param size\n     * @param searchParam\n     * @return\n     */\nMap<String, Object> nameMatchQuery(Integer current, Integer size, Map<String,Object> searchParam);\n```\n\n**3）HotelServiceImpl**\n\n```java\npublic Map<String, Object> nameMatchQuery(Integer current, Integer size, Map<String, Object> searchParam) {\n\n    //设置查询\n    SearchRequest searchRequest = new SearchRequest(\"hotel\");\n\n    SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();\n\n\n    //todo 根据酒店名称匹配查询实现\n    MatchQueryBuilder queryBuilder = QueryBuilders.matchQuery(\"name\", searchParam.get(\"name\"));\n    searchSourceBuilder.query(queryBuilder);\n\n    //设置分页\n    searchSourceBuilder.from((current - 1) * size);\n    searchSourceBuilder.size(size);\n\n    searchRequest.source(searchSourceBuilder);\n\n    //处理查询结果\n    try {\n        SearchResponse searchResponse = restHighLevelClient.search(searchRequest, RequestOptions.DEFAULT);\n\n        SearchHits hits = searchResponse.getHits();\n\n        long totalHits = hits.getTotalHits().value;\n\n        SearchHit[] searchHits = hits.getHits();\n\n        List<HotelEntity> list = new ArrayList<>();\n\n        for (SearchHit searchHit : searchHits) {\n            String sourceAsString = searchHit.getSourceAsString();\n            list.add(JSON.parseObject(sourceAsString, HotelEntity.class));\n        }\n\n        Map<String, Object> map = new HashMap<>();\n        map.put(\"list\", list);\n        map.put(\"totalResultSize\", totalHits);\n        map.put(\"current\", current);\n        //设置总页数\n        map.put(\"totalPage\", (totalHits + size - 1) / size);\n\n        return map;\n    } catch (IOException e) {\n        e.printStackTrace();\n    }\n    return null;\n}\n```\n\n## 3.4 测试&效果展示\n\n### 3.4.1 **PostMan测试**\n\n```\nlocalhost:9001/hotel/searchMatchQuery?current=1&pageSize=10\n```\n\n\n### 3.4.2 **前端效果展示**\n\nhttp://localhost:8088/dist/view/listHotelName.html\n\n\n# 4 搜索框-酒店品牌模糊搜索\n\n## 4.1 需求分析\n\n​	当在搜索框进行搜索时，展示出所有品牌以`美`开头的酒店。\n\n\n## 4.2 Kibana查询\n\nwildcardQuery：会对查询条件进行分词。还可以使用通配符 ?（任意单个字符） 和  * （0个或多个字符）\n\n```yacas\nGET hotel/_search\n{\n  \"query\": {\n    \"wildcard\": {\n     \"brand\":{\n     \"value\": \"美*\"\n    }\n  }\n}\n}\n```\n\n\n## 4.3 JavaAPI查询\n\n**1）HotelController**\n\n```java\n//根据酒店品牌模糊查询\n@GetMapping(\"/searchWildcardQuery\")\npublic Map<String, Object> searchWildcardQuery(@RequestParam Map<String, Object> searchParam, @PathParam(\"current\") Integer current, @PathParam(\"pageSize\") Integer pageSize) {\n    Map<String, Object> map = hotelService.nameWildcardQuery(current, pageSize, searchParam);\n    return this.getJsonMap(true, \"\", map);\n}\n```\n\n**2）HotelService**\n\n```java\n/**\n     * 根据酒店品牌模糊查询\n     * @param current\n     * @param size\n     * @param searchParam\n     * @return\n     */\nMap<String, Object> nameWildcardQuery(Integer current, Integer size, Map<String,Object> searchParam);\n```\n\n**3）HotelServiceImpl**\n\n```java\npublic Map<String, Object> nameWildcardQuery(Integer current, Integer size, Map<String, Object> searchParam) {\n\n    //设置查询\n    SearchRequest searchRequest = new SearchRequest(\"hotel\");\n\n    SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();\n\n    //todo 根据酒店名称模糊查询\n    WildcardQueryBuilder queryBuilder = QueryBuilders.wildcardQuery(\"brand\", searchParam.get(\"name\")+\"*\");\n    searchSourceBuilder.query(queryBuilder);\n\n\n    //设置分页\n    searchSourceBuilder.from((current - 1) * size);\n    searchSourceBuilder.size(size);\n\n    searchRequest.source(searchSourceBuilder);\n    try {\n        SearchResponse searchResponse = restHighLevelClient.search(searchRequest, RequestOptions.DEFAULT);\n\n        SearchHits hits = searchResponse.getHits();\n\n        long totalHits = hits.getTotalHits().value;\n\n        SearchHit[] searchHits = hits.getHits();\n\n        List<HotelEntity> list = new ArrayList<>();\n\n        for (SearchHit searchHit : searchHits) {\n            String sourceAsString = searchHit.getSourceAsString();\n            list.add(JSON.parseObject(sourceAsString, HotelEntity.class));\n        }\n\n        Map<String, Object> map = new HashMap<>();\n        map.put(\"list\", list);\n        map.put(\"totalResultSize\", totalHits);\n        map.put(\"current\", current);\n        //设置总页数\n        map.put(\"totalPage\", (totalHits + size - 1) / size);\n\n        return map;\n    } catch (IOException e) {\n        e.printStackTrace();\n    }\n    return null;\n}\n```\n\n## 4.4 测试&效果展示\n\n### 4.4.1 **PostMan测试**\n\n```\nlocalhost:9001/hotel/searchWildcardQuery?current=1&pageSize=10\n```\n\n\n### 4.4.2 前端效果展示\n\nhttp://localhost:8088/dist/view/listHotelNameLike.html\n\n\n# 5 搜索框-多域搜索\n\n## 5.1 需求分析\n\n​	当用户在搜索框输入查询条件时，为了给用户展示更多的数据，该条件不应该仅仅作用于某一个域，而要让其作用于多个域进行搜索，从而搜索出更多的查询结果。\n\n​	当前需要将用户的搜索条件，作用于：酒店名称(name)、酒店描述(synopsis)、酒店地区(area)、酒店地址(address)\n\n\n## 5.2 Kibana查询\n\n**queryStringQuery**：\n\n•会对查询条件进行分词。\n\n•然后将分词后的查询条件和词条进行等值匹配\n\n•默认取并集（OR）\n\n•可以指定多个查询字段\n\n```yacas\nGET hotel/_search\n{\n \"query\": {\n    \"query_string\": {\n      \"fields\": [\"name\",\"synopsis\",\"area\",\"address\"],\n      \"query\": \"如心 OR spa\"\n    }\n  }\n}\n```\n\n\n## 5.3 JavaAPI查询\n\n**1）HotelController**\n\n```java\n//根据name,synopsis,area,address进行多域查询\n@GetMapping(\"/searchQueryStringQuery\")\npublic Map<String, Object> searchQueryStringQuery(@RequestParam Map<String, Object> searchParam, @PathParam(\"current\") Integer current, @PathParam(\"pageSize\") Integer pageSize) {\n    Map<String, Object> map = hotelService.searchQueryStringQuery(current, pageSize, searchParam);\n    return this.getJsonMap(true, \"\", map);\n}\n```\n\n**2）HotelService**\n\n```java\n/**\n     * 根据name,synopsis,area,address进行多域查询\n     * @param current\n     * @param size\n     * @param searchParam 前端查询条件\n     * @return\n     */\nMap<String, Object> searchQueryStringQuery(Integer current, Integer size, Map<String,Object> searchParam);\n```\n\n**3）HotelServiceImpl**\n\n```java\npublic Map<String, Object> searchQueryStringQuery(Integer current, Integer size, Map<String, Object> searchParam) {\n\n    //设置查询\n    SearchRequest searchRequest = new SearchRequest(\"hotel\");\n\n    SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();\n\n    //todo 根据name,synopsis,area,address进行多域查询\n    QueryStringQueryBuilder queryBuilder = QueryBuilders.queryStringQuery(searchParam.get(\"condition\").toString())\n        .field(\"name\")\n        .field(\"synopsis\")\n        .field(\"area\")\n        .field(\"address\")\n        .defaultOperator(Operator.OR);\n    searchSourceBuilder.query(queryBuilder);\n\n    //设置分页\n    searchSourceBuilder.from((current - 1) * size);\n    searchSourceBuilder.size(size);\n\n    searchRequest.source(searchSourceBuilder);\n    try {\n        SearchResponse searchResponse = restHighLevelClient.search(searchRequest, RequestOptions.DEFAULT);\n\n        SearchHits hits = searchResponse.getHits();\n\n        long totalHits = hits.getTotalHits().value;\n\n        SearchHit[] searchHits = hits.getHits();\n\n        List<HotelEntity> list = new ArrayList<>();\n\n        for (SearchHit searchHit : searchHits) {\n            String sourceAsString = searchHit.getSourceAsString();\n            list.add(JSON.parseObject(sourceAsString, HotelEntity.class));\n        }\n\n        Map<String, Object> map = new HashMap<>();\n        map.put(\"list\", list);\n        map.put(\"totalResultSize\", totalHits);\n        map.put(\"current\", current);\n        //设置总页数\n        map.put(\"totalPage\", (totalHits + size - 1) / size);\n\n        return map;\n    } catch (IOException e) {\n        e.printStackTrace();\n    }\n    return null;\n}\n```\n\n## 5.4 测试&效果展示\n\n### 5.4.1 **PostMan测试**\n\n```\nlocalhost:9001/hotel/searchQueryStringQuery?current=1&pageSize=10\n```\n\n\n### 5.4.2 **前端工程演示**\n\nhttp://localhost:8088/dist/view/listMultiDomain.html\n\n\n# 6 搜索框-自动提示\n\n## 6.1 需求分析\n\n​	当用户在搜索框进行搜索时，搜索框应该更加智能的展示出与用户搜索条件相类似的提示，供用户更加快捷的进行查询\n\n以百度为例\n\n\n## 6.2 Kibana查询\n\n**completionSuggest**：会根据搜索条件查询索引库，进行条件自动提示。\n\n### 6.2.1 效果演示\n\n**1）新建测试索引库**\n\n```yacas\nPUT news\n{\n  \"mappings\": {\n    \"properties\": {\n      \"name\":{\n        \"type\": \"completion\",\n        \"analyzer\": \"ik_max_word\"\n      }\n    }\n  }    \n}\n```\n\n**2）向测试索引库中添加记录**\n\n```yacas\nPOST _bulk\n{ \"create\" : { \"_index\" : \"news\",\"_id\":1}}\n{ \"name\": \"新闻\"}\n{ \"create\" : { \"_index\" : \"news\",\"_id\":2}}\n{ \"name\": \"新闻联播\"}\n{ \"create\" : { \"_index\" : \"news\",\"_id\":3}}\n{ \"name\": \"新闻头条\"}\n{ \"create\" : { \"_index\" : \"news\",\"_id\":4}}\n{ \"name\": \"新闻头条最新消息\"}\n{ \"create\" : { \"_index\" : \"news\",\"_id\":5}}\n{ \"name\": \"新闻联播直播\"}\n{ \"create\" : { \"_index\" : \"news\",\"_id\":6}}\n{ \"name\": \"新闻联播直播在线观看\"}\n{ \"create\" : { \"_index\" : \"news\",\"_id\":7}}\n{ \"name\": \"新闻肺炎\"}\n{ \"create\" : { \"_index\" : \"news\",\"_id\":8}}\n{ \"name\": \"新闻肺炎疫区\"}\n{ \"create\" : { \"_index\" : \"news\",\"_id\":9}}\n{ \"name\": \"新闻肺炎状况\"}\n{ \"create\" : { \"_index\" : \"news\",\"_id\":10}}\n{ \"name\": \"新闻1+1\"}\n{ \"create\" : { \"_index\" : \"news\",\"_id\":11}}\n{ \"name\": \"新闻周刊\"}\n{ \"create\" : { \"_index\" : \"news\",\"_id\":12}}\n{ \"name\": \"新闻周刊最新\"}\n{ \"create\" : { \"_index\" : \"news\",\"_id\":13}}\n{ \"name\": \"新闻国外\"}\n{ \"create\" : { \"_index\" : \"news\",\"_id\":14}}\n{ \"name\": \"新闻国外疫情\"}\n{ \"create\" : { \"_index\" : \"news\",\"_id\":15}}\n{ \"name\": \"新闻联播主持人\"}\n```\n\n**3）搜索测试**\n\n```yacas\nGET news/_search\n{\n  \"suggest\": {\n    \"my-suggest\": {\n      \"prefix\": \"新闻\",\n      \"completion\": {\n        \"field\": \"name\",\n        \"size\":10\n      }\n    }\n  }\n}\n```\n\n\n### 6.2.2 功能准备\n\n**1）新建用于存储用户搜索记录的索引库**\n\n```yacas\nPUT suggest\n{\n  \"mappings\": {\n    \"properties\": {\n      \"name\":{\n        \"type\": \"completion\",\n        \"analyzer\": \"ik_max_word\"\n      }\n    }\n  }    \n}\n```\n\n**2）数据查询**\n\n```yacas\nGET suggest/_search\n{\n  \"suggest\": {\n    \"my-suggest\": {\n      \"prefix\": \"酒店环境\",\n      \"completion\": {\n        \"field\": \"name\",\n        \"size\":10\n      }\n    }\n  }\n}\n```\n\n```yacas\nGET suggest/_search\n{\n  \"suggest\": {\n    \"my-suggest\": {\n      \"prefix\": \"酒店\",\n      \"completion\": {\n        \"field\": \"name\",\n        \"size\":10\n      }\n    }\n  }\n}\n```\n\n## 6.3 JavaAPI查询\n\n**1）HotelController**\n\n```java\n//搜索框自动提示\n@GetMapping(\"/searchSuggestInfo\")\npublic Map<String, Object> searchSuggestInfo(@RequestParam(\"key\") String key) {\n    return getJsonMap(true, \"\", hotelService.searchSuggestInfo(key));\n}\n```\n\n**2）HotelService**\n\n```java\n/**\n     * 搜索框自动提示\n     * @param key 前端输入查询\n     * @return\n     */\nList<String> searchSuggestInfo(String key);\n```\n\n**3）HotelServiceImpl**\n\n```java\npublic List<String> searchSuggestInfo(String key) {\n\n    //定义结果集\n    List<String> result = new ArrayList<>();\n\n    //设置查询\n    SearchRequest searchRequest = new SearchRequest(\"suggest\");\n    SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();\n\n    //todo 构建自动补全搜索\n    SuggestBuilder suggestBuilder = new SuggestBuilder();\n    CompletionSuggestionBuilder suggestion = SuggestBuilders.completionSuggestion(\"name\").text(key).size(10);\n    suggestBuilder.addSuggestion(\"my-suggest\",suggestion);\n    searchSourceBuilder.suggest(suggestBuilder);\n\n    searchRequest.source(searchSourceBuilder);\n\n    try {\n        SearchResponse searchResponse = restHighLevelClient.search(searchRequest, RequestOptions.DEFAULT);\n\n        //todo 处理自动补全查询结果\n        Suggest suggest = searchResponse.getSuggest();\n        CompletionSuggestion completionSuggestion = suggest.getSuggestion(\"my-suggest\");\n        List<CompletionSuggestion.Entry> entries = completionSuggestion.getEntries();\n\n        Map<String, Object> map = new HashMap<>();\n        if (entries != null && entries.size()>0){\n            entries.forEach(entry->{\n                if (!ObjectUtils.isEmpty(entry.getOptions())){\n                    entry.forEach(action->{\n                        String suggestInfo = action.getText().toString();\n                        if (suggestInfo.equals(key)){\n                            return;\n                        }\n                        result.add(suggestInfo);\n                    });\n                }else {\n                    map.put(\"name\",key);\n                }\n            });\n        }\n\n        //向索引库增量添加查询条件\n        if (!ObjectUtils.isEmpty(map)){\n            IndexRequest indexRequest = new IndexRequest(\"suggest\").source(map);\n            try {\n                restHighLevelClient.index(indexRequest, RequestOptions.DEFAULT);\n            } catch (IOException e) {\n                e.printStackTrace();\n            }\n        }\n        System.out.println(\"list\" + result);\n\n        return result;\n    } catch (IOException e) {\n        e.printStackTrace();\n    }\n\n    return null;\n}\n```\n\n## 6.4 测试&效果展示\n\n### 6.4.1 **PostMan测试**\n\n```\nlocalhost:9001/hotel/searchSuggestInfo?key=新闻联播\n\nlocalhost:9001/hotel/searchSuggestInfo?key=新闻主播\n\nlocalhost:9001/hotel/searchSuggestInfo?key=新闻\n```\n\n\n### 6.4.2 **前端效果展示**\n\nhttp://localhost:8088/dist/view/listAutomaticPrompt.html\n\n\n# 7 条件栏-销量排序查询\n\n## 7.1 需求分析\n\n​	当用户进行搜索时，有时会关注该商品的销量、评论数等信息，对这些进行进行排序，搜索出销量最高或评论数最多的商品。\n\n以京东为例\n\n\n## 7.2 Kibana查询\n\n```yacas\n#降序\nGET hotel/_search\n{\n  \"sort\": [\n    {\n      \"salesVolume\": {\n        \"order\": \"desc\"\n      }\n    }\n  ]\n}\n```\n\n\n```yacas\n#升序\nGET hotel/_search\n{\n  \"sort\": [\n    {\n      \"salesVolume\": {\n        \"order\": \"asc\"\n      }\n    }\n  ]\n}\n```\n\n\n## 7.3 JavaAPI查询\n\n**1）HotelController**\n\n```java\n//根据销量排序查询\n@GetMapping(\"/searchSortQuery\")\npublic Map<String, Object> searchSortQuery(@RequestParam Map<String, Object> searchParam, @PathParam(\"current\") Integer current, @PathParam(\"pageSize\") Integer pageSize) {\n    Map<String, Object> map = hotelService.salesSortQuery(current, pageSize, searchParam);\n    return this.getJsonMap(true, \"\", map);\n}\n```\n\n**2）HotelService**\n\n```java\n/**\n     * 根据销量排序查询\n     * @param current\n     * @param size\n     * @param searchParam\n     * @return\n     */\nMap<String, Object> salesSortQuery(Integer current, Integer size, Map<String, Object> searchParam);\n```\n\n**3）HotelServiceImpl**\n\n```java\npublic Map<String, Object> salesSortQuery(Integer current, Integer size, Map<String, Object> searchParam) {\n\n    //设置查询\n    SearchRequest searchRequest = new SearchRequest(\"hotel\");\n\n    SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();\n\n    //todo 设置按销量排序\n    if (\"desc\".equalsIgnoreCase(searchParam.get(\"sortWay\").toString())){\n        searchSourceBuilder.sort(\"salesVolume\", SortOrder.DESC);\n    }else {\n        searchSourceBuilder.sort(\"salesVolume\",SortOrder.ASC);\n    }\n\n    //设置分页\n    searchSourceBuilder.from((current - 1) * size);\n    searchSourceBuilder.size(size);\n\n    searchRequest.source(searchSourceBuilder);\n    try {\n        SearchResponse searchResponse = restHighLevelClient.search(searchRequest, RequestOptions.DEFAULT);\n\n        SearchHits hits = searchResponse.getHits();\n\n        long totalHits = hits.getTotalHits().value;\n\n        SearchHit[] searchHits = hits.getHits();\n\n        List<HotelEntity> list = new ArrayList<>();\n\n        for (SearchHit searchHit : searchHits) {\n            String sourceAsString = searchHit.getSourceAsString();\n            list.add(JSON.parseObject(sourceAsString, HotelEntity.class));\n        }\n\n        Map<String, Object> map = new HashMap<>();\n        map.put(\"list\", list);\n        map.put(\"totalResultSize\", totalHits);\n        map.put(\"current\", current);\n        //设置总页数\n        map.put(\"totalPage\", (totalHits + size - 1) / size);\n        map.put(\"sortWay\", searchParam.get(\"sortWay\"));\n\n\n        return map;\n    } catch (IOException e) {\n        e.printStackTrace();\n    }\n    return null;\n}\n```\n\n## 7.4 测试&效果展示\n\n### 7.4.1 **PostMan测试**\n\n```\nlocalhost:9001/hotel/searchSortQuery?current=1&pageSize=10\n```\n\n\n### 7.4.2 **前端效果展示**\n\nhttp://localhost:8088/dist/view/listSalesVolume.html\n\n# 8 条件栏-价格范围查询\n\n## 8.1 需求分析\n\n​	当用户要搜索商品时，有时会对某一个特定的价格区间进行查询，搜索出符合心理预期价格的商品\n\n以京东为例\n\n\n## 8.2 Kibana查询\n\n```yacas\nGET hotel/_search\n{\n  \"query\": {\n    \"range\": {\n      \"price\": {\n        \"gte\": 500,\n        \"lte\": 1500\n      }\n    }\n  }\n}\n```\n\n\n## 8.3 JavaAPI查询\n\n**1）HotelController**\n\n```java\n//根据价格范围查询\n@GetMapping(\"/searchRangeQuery\")\npublic Map<String, Object> searchRangeQuery(@RequestParam Map<String, Object> searchParam, @PathParam(\"current\") Integer current, @PathParam(\"pageSize\") Integer pageSize) {\n    Map<String, Object> map = hotelService.priceRangeQuery(current, pageSize, searchParam);\n    return this.getJsonMap(true, \"\", map);\n}\n```\n\n**2）HotelService**\n\n```java\n/**\n     * 根据价格范围查询\n     * @param current\n     * @param size\n     * @param searchParam\n     * @return\n     */\nMap<String, Object> priceRangeQuery(Integer current, Integer size, Map<String, Object> searchParam);\n```\n\n**3）HotelServiceImpl**\n\n```java\npublic Map<String, Object> priceRangeQuery(Integer current, Integer size, Map<String, Object> searchParam) {\n\n    //设置查询\n    SearchRequest searchRequest = new SearchRequest(\"hotel\");\n\n    SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();\n\n    //todo 根据价格范围查询\n    RangeQueryBuilder queryBuilder = QueryBuilders.rangeQuery(\"price\")\n        .gte(searchParam.get(\"minPrice\"))\n        .lte(searchParam.get(\"maxPrice\"));\n    searchSourceBuilder.query(queryBuilder);\n\n\n    //设置分页\n    searchSourceBuilder.from((current - 1) * size);\n    searchSourceBuilder.size(size);\n\n    searchRequest.source(searchSourceBuilder);\n\n    //处理查询结果\n    try {\n        SearchResponse searchResponse = restHighLevelClient.search(searchRequest, RequestOptions.DEFAULT);\n\n        SearchHits hits = searchResponse.getHits();\n\n        long totalHits = hits.getTotalHits().value;\n\n        SearchHit[] searchHits = hits.getHits();\n\n        List<HotelEntity> list = new ArrayList<>();\n\n        for (SearchHit searchHit : searchHits) {\n            String sourceAsString = searchHit.getSourceAsString();\n            list.add(JSON.parseObject(sourceAsString, HotelEntity.class));\n        }\n\n        Map<String, Object> map = new HashMap<>();\n        map.put(\"list\", list);\n        map.put(\"totalResultSize\", totalHits);\n        map.put(\"current\", current);\n        //设置总页数\n        map.put(\"totalPage\", (totalHits + size - 1) / size);\n\n        map.put(\"minPrice\", searchParam.get(\"minPrice\"));\n        map.put(\"maxPrice\", searchParam.get(\"maxPrice\"));\n\n        return map;\n    } catch (IOException e) {\n        e.printStackTrace();\n    }\n    return null;\n}\n```\n\n## 8.4 测试&效果展示\n\n### 8.4.1 PostMan测试\n\n```\nlocalhost:9001/hotel/searchRangeQuery?current=1&pageSize=10\n```\n\n\n### 8.4.2 前端效果展示\n\nhttp://localhost:8088/dist/view/listRangePrice.html\n\n\n# 9 条件栏-多条件查询\n\n## 9.1 需求分析\n\n​	当用户进行搜索时，不会仅仅只输入一个搜索条件，有时会传递多个条件，将符合多条件的商品搜索出来。\n\n以京东为例：\n\n\n## 9.2 Kibana查询\n\n**boolQuery**：对多个查询条件连接。\n\n连接方式：\n\n•**must（and）**：条件必须成立\n\n•**must_not（not）**：条件必须不成立\n\n•**should（or）**：条件可以成立\n\n•**filter**：条件必须成立，性能比must高。\n\n```yacas\n#must单独使用 品牌必须是万豪，地区必须是北京\nGET hotel/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": [\n        {\n          \"term\": {\n            \"brand\": {\n              \"value\": \"万豪\"\n            }\n          }\n        },\n        {\n          \"term\": {\n            \"area\": {\n              \"value\": \"北京市\"\n            }\n          }\n        }\n      ]\n    }\n  }\n}\n```\n\n```yacas\n# must与filter组合使用 查询品牌为万豪下的，区域为北京，价格范围在500和2000之间的酒店\nGET hotel/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": [\n        {\n          \"term\": {\n            \"brand\": {\n              \"value\": \"万豪\"\n            }\n          }\n        }\n      ],\n      \"filter\":[ \n        {\n        \"term\": {\n          \"area\": \"北京市\"\n        }\n       },\n       {\n         \"range\":{\n          \"price\": {\n            \"gte\": 500,\n            \"lte\": 2000\n         }\n         }\n       }\n      ]\n    }\n  }\n}\n```\n\n```yacas\n#filter 单独使用   filter可以是单个条件，也可多个条件（数组形式）\nGET hotel/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"filter\": [\n        {\n          \"term\": {\n            \"brand\": {\n              \"value\": \"万豪\"\n            }\n          }\n        }\n      ]\n    }\n  }\n}\n```\n\n## 9.3 JavaAPI查询\n\n**1）HotelController**\n\n```java\n//多条件查询\n@GetMapping(\"/searchBoolQuery\")\npublic Map<String, Object> searchBoolQuery(@RequestParam Map<String, Object> searchParam, @PathParam(\"current\") Integer current, @PathParam(\"pageSize\") Integer pageSize) {\n    Map<String, Object> map = hotelService.searchBoolQuery(current, pageSize, searchParam);\n    return this.getJsonMap(true, \"\", map);\n}\n```\n\n**2）HotelService**\n\n```java\n/**\n     * 多条件查询\n     * 多域、品牌精确、城市精确、星级精确、价格范围、销量排序\n     * @param current\n     * @param size\n     * @param searchParam\n     * @return\n     */\nMap<String, Object> searchBoolQuery(Integer current, Integer size, Map<String, Object> searchParam);\n```\n\n**3）HotelServiceImpl**\n\n```java\n//多条件查询\n//搜索框多域、品牌精确、城市精确、星级精确、价格范围、销量排序\n@Override\npublic Map<String, Object> searchBoolQuery(Integer current, Integer size, Map<String, Object> searchParam) {\n\n    //设置查询\n    SearchRequest searchRequest = new SearchRequest(\"hotel\");\n\n    SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();\n\n\n    //todo 多条件查询 ：多域、品牌精确、城市精确、星级精确、价格范围、销量排序\n    //设置查询方式\n    BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery();\n\n    //多域\n    if (ObjectUtils.isNotEmpty(searchParam.get(\"condition\"))) {\n        QueryBuilder queryBuilder = QueryBuilders.queryStringQuery(searchParam.get(\"condition\").toString())\n            .field(\"name\")\n            .field(\"synopsis\")\n            .field(\"area\")\n            .field(\"address\")\n            .defaultOperator(Operator.OR);\n        boolQueryBuilder.must(queryBuilder);\n    }\n\n    //品牌精确\n    if (ObjectUtils.isNotEmpty(searchParam.get(\"brand\"))) {\n        TermQueryBuilder termQueryBuilder = QueryBuilders.termQuery(\"brand\", searchParam.get(\"brand\"));\n        boolQueryBuilder.filter(termQueryBuilder);\n    }\n\n    //城市精确\n    if (ObjectUtils.isNotEmpty(searchParam.get(\"area\"))) {\n        TermQueryBuilder termQueryBuilder = QueryBuilders.termQuery(\"area\", searchParam.get(\"area\"));\n        boolQueryBuilder.filter(termQueryBuilder);\n    }\n\n    //星级精确\n    if (ObjectUtils.isNotEmpty(searchParam.get(\"specs\"))) {\n        TermQueryBuilder termQueryBuilder = QueryBuilders.termQuery(\"specs\", searchParam.get(\"specs\"));\n        boolQueryBuilder.filter(termQueryBuilder);\n    }\n\n    //价格范围\n    if (ObjectUtils.isNotEmpty(searchParam.get(\"minPrice\")) && !StringUtils.isEmpty(searchParam.get(\"maxPrice\"))) {\n        RangeQueryBuilder rangeQueryBuilder = QueryBuilders.rangeQuery(\"price\")\n            .gte(searchParam.get(\"minPrice\"))\n            .lte(searchParam.get(\"maxPrice\"));\n        boolQueryBuilder.filter(rangeQueryBuilder);\n    }\n\n    //销量排序\n    if (ObjectUtils.isNotEmpty(searchParam.get(\"sortWay\"))) {\n        if (\"desc\".equalsIgnoreCase(searchParam.get(\"sortWay\").toString())) {\n            searchSourceBuilder.sort(\"salesVolume\", SortOrder.DESC);\n        } else {\n            searchSourceBuilder.sort(\"salesVolume\", SortOrder.ASC);\n        }\n    }\n\n    searchSourceBuilder.query(boolQueryBuilder);\n\n\n    //设置分页\n    searchSourceBuilder.from((current - 1) * size);\n    searchSourceBuilder.size(size);\n\n    searchRequest.source(searchSourceBuilder);\n\n    //处理查询结果\n    try {\n        SearchResponse searchResponse = restHighLevelClient.search(searchRequest, RequestOptions.DEFAULT);\n\n        SearchHits hits = searchResponse.getHits();\n\n        long totalHits = hits.getTotalHits().value;\n\n        SearchHit[] searchHits = hits.getHits();\n\n        List<HotelEntity> list = new ArrayList<>();\n\n        for (SearchHit searchHit : searchHits) {\n            String sourceAsString = searchHit.getSourceAsString();\n            list.add(JSON.parseObject(sourceAsString, HotelEntity.class));\n        }\n\n        Map<String, Object> map = new HashMap<>();\n        map.put(\"list\", list);\n        map.put(\"totalResultSize\", totalHits);\n        map.put(\"current\", current);\n        //设置总页数\n        map.put(\"totalPage\", (totalHits + size - 1) / size);\n\n        map.put(\"brand\", searchParam.get(\"brand\"));\n        map.put(\"area\", searchParam.get(\"area\"));\n        map.put(\"specs\", searchParam.get(\"specs\"));\n        map.put(\"sortWay\", searchParam.get(\"sortWay\"));\n        map.put(\"minPrice\", searchParam.get(\"minPrice\"));\n        map.put(\"maxPrice\", searchParam.get(\"maxPrice\"));\n\n        return map;\n    } catch (IOException e) {\n        e.printStackTrace();\n    }\n    return null;\n}\n```\n\n## 9.4 测试&效果展示\n\n### 9.4.1 PostMan测试\n\n```\nlocalhost:9001/hotel/searchBoolQuery?current=1&pageSize=10\n```\n\n\n### 9.4.2 前端效果展示\n\nhttp://localhost:8088/dist/view/listMultipleConditions.html\n\n\n# 10 条件栏-酒店区域纠错查询\n\n## 10.1 需求分析\n\n​	当用户在进行搜索时，有可能打错字输入了错误的信息。 那么后台在处理时，应该智能的识别错误信息，更加友好的展示相关数据。\n\n\n## 10.2 Kibana查询\n\n**fuzzyQuery**\n\n​	自动纠错查询，会自动尝试将搜索条件进行纠错，然后去跟term进行匹配。\n\n- **fuzziness**：查询允许的最大编辑距离，默认为0\n- **prefix_length**：设置前几个字符不允许编辑\n\n​	在未经处理的情况下，一旦输入信息有误，对应不到分词的话，则不会有任何结果返回\n\n```yacas\n#输入错误信息\nGET hotel/_search\n{\n  \"query\": {\n    \"term\": {\n     \"area\":\"北经市\"\n  }\n}\n}\n```\n\n​	此时查询不会有任何结果，因为`北经市`信息有误。如果想要智能的识别错误条件，则需要使用fuzzy查询\n\n```yacas\nGET hotel/_search\n{\n  \"query\": {\n    \"fuzzy\": {\n      \"area\": {\n        \"value\": \"北经市\",\n        \"fuzziness\": 1,\n        \"prefix_length\": 1\n      }\n    }\n  }\n}\n```\n\n\n## 10.3 JavaAPI查询\n\n**1）HotelController**\n\n```java\n//自动纠错查询\n@GetMapping(\"/searchFuzzyQuery\")\npublic Map<String, Object> searchFuzzyQuery(@RequestParam Map<String, Object> searchParam, @PathParam(\"current\") Integer current, @PathParam(\"pageSize\") Integer pageSize) {\n    Map<String, Object> map = hotelService.searchFuzzyQuery(current, pageSize, searchParam);\n    return this.getJsonMap(true, \"\", map);\n}\n```\n\n**2）HotelService**\n\n```java\n/**\n     * 地址纠错查询\n     * @param current\n     * @param size\n     * @param searchParam\n     * @return\n     */\nMap<String, Object> searchFuzzyQuery(Integer current, Integer size, Map<String, Object> searchParam);\n```\n\n**3）HotelServiceImpl**\n\n```java\npublic Map<String, Object> searchFuzzyQuery(Integer current, Integer size, Map<String, Object> searchParam) {\n\n    //设置查询\n    SearchRequest searchRequest = new SearchRequest(\"hotel\");\n\n    SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();\n\n    //设置查询方式\n\n    //todo 设置城市为纠错查询\n    FuzzyQueryBuilder queryBuilder = QueryBuilders.fuzzyQuery(\"area\", searchParam.get(\"condition\"))\n        .fuzziness(Fuzziness.ONE)\n        .prefixLength(1);\n\n    searchSourceBuilder.query(queryBuilder);\n\n    //设置分页\n    searchSourceBuilder.from((current - 1) * size);\n    searchSourceBuilder.size(size);\n\n    searchRequest.source(searchSourceBuilder);\n\n    // 处理查询结果\n    try {\n        SearchResponse searchResponse = restHighLevelClient.search(searchRequest, RequestOptions.DEFAULT);\n\n        SearchHits hits = searchResponse.getHits();\n\n        long totalHits = hits.getTotalHits().value;\n\n        SearchHit[] searchHits = hits.getHits();\n\n        List<HotelEntity> list = new ArrayList<>();\n\n        for (SearchHit searchHit : searchHits) {\n            String sourceAsString = searchHit.getSourceAsString();\n            list.add(JSON.parseObject(sourceAsString, HotelEntity.class));\n        }\n\n        Map<String, Object> map = new HashMap<>();\n        map.put(\"list\", list);\n        map.put(\"totalResultSize\", totalHits);\n        map.put(\"current\", current);\n\n        map.put(\"brand\", searchParam.get(\"brand\"));\n        map.put(\"area\", searchParam.get(\"area\"));\n        map.put(\"specs\", searchParam.get(\"specs\"));\n        map.put(\"sortWay\", searchParam.get(\"sortWay\"));\n        map.put(\"minPrice\", searchParam.get(\"minPrice\"));\n        map.put(\"maxPrice\", searchParam.get(\"maxPrice\"));\n        //设置总页数\n        map.put(\"totalPage\", (totalHits + size - 1) / size);\n\n        return map;\n    } catch (IOException e) {\n        e.printStackTrace();\n    }\n    return null;\n}\n```\n\n## 10.4 测试&效果展示\n\n### 10.4.1 PostMan测试\n\n```\nlocalhost:9001/hotel/searchFuzzyQuery?current=1&pageSize=10\n```\n\n\n### 10.4.2 前端效果展示\n\nhttp://localhost:8088/dist/view/listErrorCorrection.html\n\n\n# 11 搜索结果-高亮展示\n\n## 11.1 需求分析\n\n​	当用户在搜索框输入搜索条件后，对于查询结果的展示，应将搜索条件以特殊的样式展示，这种查询就称为`高亮结果查询`\n\n以京东为例\n\n\n## 11.2 Kibana查询\n\n​	如需将搜索条件以高亮形式展示，则需要在查询时，设置需要对哪一个域进行高亮展示\n\n**fields**：指定要对哪个域高亮显示\n\n**pre_tags**：设置高亮样式前缀\n\n**post_tags**：设置高亮样式后缀\n\n```yacas\nGET hotel/_search\n{\n  \"query\": {\n    \"term\": {\n      \"name\": {\n        \"value\": \"北京市\"\n      }\n    }\n  },\n  \"highlight\": {\n    \"fields\": {\n      \"name\": {\n        \"pre_tags\": \"<font color=\'red\'>\",\n        \"post_tags\": \"</font>\"\n      }\n    }\n  }\n}\n```\n\n\n​	根据Kibana查询结果可知，高亮结果是以特殊字段声明，所以在结果处理时，也需将高亮数据替换原有name值。\n\n## 11.3 JavaAPI查询\n\n**1）HotelController**\n\n```java\n//高亮查询\n@GetMapping(\"/searchHighLight\")\npublic Map<String, Object> searchHighLight(@RequestParam Map<String, Object> searchParam, @PathParam(\"current\") Integer current, @PathParam(\"pageSize\") Integer pageSize) {\n    Map<String, Object> map = hotelService.searchHighLight(current, pageSize, searchParam);\n    return this.getJsonMap(true, \"\", map);\n}\n```\n\n**2）HotelService**\n\n```java\n/**\n     * 按名称高亮查询\n     * @param current\n     * @param size\n     * @param searchParam\n     * @return\n     */\nMap<String, Object> searchHighLight(Integer current, Integer size, Map<String, Object> searchParam);\n```\n\n**3）HotelServiceImpl**\n\n```java\npublic Map<String, Object> searchHighLight(Integer current, Integer size, Map<String, Object> searchParam) {\n\n    //设置查询\n    SearchRequest searchRequest = new SearchRequest(\"hotel\");\n\n    SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();\n\n    //设置查询方式\n    if (!ObjectUtils.isEmpty(searchParam.get(\"condition\"))) {\n            QueryBuilder queryBuilder = QueryBuilders.termQuery(\"name\",searchParam.get(\"condition\"));\n            searchSourceBuilder.query(queryBuilder);\n     }\n    //设置分页\n    searchSourceBuilder.from((current - 1) * size);\n    searchSourceBuilder.size(size);\n\n    //todo 查询高亮设置\n    HighlightBuilder highlightBuider = new HighlightBuilder();\n    highlightBuider.field(\"name\");\n    highlightBuider.preTags(\"<font color=\'red\'>\");\n    highlightBuider.postTags(\"</font>\");\n    searchSourceBuilder.highlighter(highlightBuider);\n\n    searchRequest.source(searchSourceBuilder);\n    try {\n        SearchResponse searchResponse = restHighLevelClient.search(searchRequest, RequestOptions.DEFAULT);\n\n        SearchHits hits = searchResponse.getHits();\n\n        long totalHits = hits.getTotalHits().value;\n\n        SearchHit[] searchHits = hits.getHits();\n\n        List<HotelEntity> list = new ArrayList<>();\n\n        for (SearchHit searchHit : searchHits) {\n            String sourceAsString = searchHit.getSourceAsString();\n            HotelEntity hotelEntity = JSON.parseObject(sourceAsString, HotelEntity.class);\n\n            //todo  处理高亮结果\n            Map<String, HighlightField> highlightFields = searchHit.getHighlightFields();\n            HighlightField highlightField = highlightFields.get(\"name\");\n            if (highlightField!=null){\n                Text[] fragments = highlightField.fragments();\n                hotelEntity.setName(fragments[0].toString());\n            }\n\n            list.add(hotelEntity);\n        }\n\n        Map<String, Object> map = new HashMap<>();\n        map.put(\"list\", list);\n        map.put(\"totalResultSize\", totalHits);\n        map.put(\"current\", current);\n        //设置总页数\n        map.put(\"totalPage\", (totalHits + size - 1) / size);\n\n        return map;\n    } catch (IOException e) {\n        e.printStackTrace();\n    }\n    return null;\n}\n```\n\n## 11.4 测试&效果展示\n\n### 11.4.1 PostMan测试\n\n```\nlocalhost:9001/hotel/searchHighLight?current=1&pageSize=10\n```\n\n\n### 11.4.2 前端效果展示\n\nhttp://localhost:8088/dist/view/listHighLight.html\n\n', '2021-12-05 11:47:35', 0, NULL, 0);
INSERT INTO `m_blog` VALUES (14, 1, '非关系型数据库--ElasticSearch 03', 'ElasticSearch-03', '# ElasticSearch-day03\n\n# 1 品牌分组聚合搜索\n\n## 1.1 聚合介绍\n\n​	在关系型数据库中，如Mysql，可以获取一组数据的Max(最大值)、Min(最小值)、Avg(平均值)等等，并且还可以对数据进行Group by(分组)。那么对于这些功能，在ES中同样也可以实现，对于这一类功能，在ES中统称为：聚合查询。 他们主要适用于对数据进行统计分析的场景。\n\n​	在ES中对于聚合查询，主要分为两类：指标(Metric)聚合 与 桶(Bucket)聚合。\n\n- 指标聚合：max、min、sum等。作用等同于Mysql中的相关聚合函数。\n- 桶聚合：group by，对数据进行分组。\n\n`注意：不能对text类型进行分组，因为text会进行分词，导致无法进行分组。`\n\n### 1.1.1 指标聚合\n\n​	统计品牌为万豪的最贵酒店价格\n\n```yacas\n#统计品牌为万豪的最贵酒店价格\nGET hotel/_search\n{\n  \"query\": {\n    \"term\": {\n      \"brand\": {\n        \"value\": \"万豪\"\n      }\n    }\n  },\n  \"aggs\": {\n    \"max_price\": {\n      \"max\": {\n        \"field\": \"price\"\n      }\n    }\n  }\n}\n```\n\n### 1.1.2 桶聚合\n\n​	统计品牌为万豪的酒店有哪些星级\n\n```yacas\n#统计品牌为万豪的酒店有哪些星级\nGET hotel/_search\n{\n  \"query\": {\n    \"term\": {\n      \"brand\": {\n        \"value\": \"万豪\"\n      }\n    }\n  },\n  \"aggs\": {\n    \"spec_group\": {\n      \"terms\": {\n        \"field\": \"specs\",\n        \"size\": 100\n      }\n    }\n  }\n}\n```\n\n## 1.2 功能实现\n\n### 1.2.1 Kibana查询\n\n```yacas\n# 根据搜索条件对品牌进行数据分组\nGET hotel/_search\n{\n  \"query\": {\n    \"query_string\": {\n      \"fields\": [\"name\",\"synopsis\",\"area\",\"address\"],\n      \"query\": \"三亚 OR 商务\"\n    }\n  },\n  \"aggs\": {\n    \"hotel_brands\": {\n      \"terms\": {\n        \"field\": \"brand\",\n        \"size\": 100\n      }\n    }\n  }\n}\n```\n\n\n\n### 1.2.2 JavaAPI查询\n\n**1）HotelController**\n\n```java\n//品牌分组聚合\n@GetMapping(\"/searchBrandGroupQuery\")\npublic Map<String, Object> searchBrandGroupQuery(@RequestParam Map<String, Object> searchParam, @PathParam(\"current\") Integer current, @PathParam(\"pageSize\") Integer pageSize) {\n    Map<String, Object> result = hotelService.searchBrandGroupQuery(current, pageSize, searchParam);\n    return this.getJsonMap(true, \"\", result);\n}\n```\n\n**2）HotelService**\n\n```java\n/**\n     * 品牌分组聚合查询\n     * @param current\n     * @param size\n     * @param searchParam\n     * @return\n     */\nMap<String, Object> searchBrandGroupQuery(Integer current, Integer size, Map<String, Object> searchParam);\n```\n\n**3）HotelServiceImpl**\n\n```java\npublic Map<String, Object> searchBrandGroupQuery(Integer current, Integer size, Map<String, Object> searchParam) {\n\n        //设置查询\n        SearchRequest searchRequest = new SearchRequest(\"hotel\");\n\n        SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();\n\n        //设置查询方式\n        if (!StringUtils.isEmpty(searchParam.get(\"condition\"))) {\n            QueryBuilder queryBuilder = QueryBuilders.queryStringQuery(searchParam.get(\"condition\").toString())\n                    .field(\"name\")\n                    .field(\"synopsis\")\n                    .field(\"area\")\n                    .field(\"address\")\n                    .defaultOperator(Operator.OR);\n            searchSourceBuilder.query(queryBuilder);\n        }\n\n        //todo 按品牌分组聚合\n        TermsAggregationBuilder aggregationBuilder = AggregationBuilders.terms(\"hotel_brands\").field(\"brand\").size(100);\n        searchSourceBuilder.aggregation(aggregationBuilder);\n\n        //设置分页\n        searchSourceBuilder.from((current - 1) * size);\n        searchSourceBuilder.size(size);\n\n        searchRequest.source(searchSourceBuilder);\n        try {\n            SearchResponse searchResponse = restHighLevelClient.search(searchRequest, RequestOptions.DEFAULT);\n\n            SearchHits hits = searchResponse.getHits();\n\n            long totalHits = hits.getTotalHits().value;\n\n            SearchHit[] searchHits = hits.getHits();\n\n            List<HotelEntity> list = new ArrayList<>();\n\n            for (SearchHit searchHit : searchHits) {\n                String sourceAsString = searchHit.getSourceAsString();\n                list.add(JSON.parseObject(sourceAsString, HotelEntity.class));\n            }\n\n            //todo 获取并处理聚合查询结果\n            Aggregations aggregations = searchResponse.getAggregations();\n            Map<String, Aggregation> aggregationMap = aggregations.asMap();\n            Terms terms = (Terms) aggregationMap.get(\"hotel_brands\");\n            List<? extends Terms.Bucket> buckets = terms.getBuckets();\n\n            List brandList = new ArrayList();\n            buckets.forEach(bucket -> {\n                System.out.println(bucket.getKey());\n                brandList.add(bucket.getKeyAsString());\n            });\n\n\n            Map<String, Object> map = new HashMap<>();\n            map.put(\"list\", list);\n            map.put(\"totalResultSize\", totalHits);\n            map.put(\"current\", current);\n            //设置总页数\n            map.put(\"totalPage\", (totalHits + size - 1) / size);\n\n            //设置品牌分组列表\n            map.put(\"brandList\", brandList);\n\n            return map;\n        } catch (IOException e) {\n            e.printStackTrace();\n        }\n        return null;\n    }\n```\n\n### 1.2.3 测试&前端效果展示\n\n**PostMan**\n\n```\nlocalhost:9001/hotel/searchBrandGroupQuery?current=1&pageSize=10\n```\n\n\n**前端工程效果展示**\n\n```\nhttp://localhost:8088/dist/view/listBrandGrouping.html\n```\n\n\n# 2 自定义时间段统计某品牌下酒店销量\n\n## 2.1 需求分析\n\n​	根据用户输入的日期，统计某品牌下所有酒店销量。  对于该功能的实现，需要进行多层聚合。\n\n1. 对日期时间段范围查询\n2. 根据品牌进行分组查询\n3. 对分组查询结果进行sum聚合\n\n## 2.2 Kibana查询\n\n```yacas\nPOST hotel/_search\n{\n \"query\": {\n   \"range\": {\n     \"createTime\": {\n       \"gte\": \"2015-01-01\",\n       \"lte\": \"2021-01-01\",\n       \"format\": \"yyyy-MM-dd\"\n     }\n   }\n },\n \"aggs\": {\n   \"hotel-brand\": {\n     \"terms\": {\n       \"field\": \"brand\",\n       \"size\": 100\n     },\n     \"aggs\": {\n       \"countSale\": {\n         \"sum\": {\n           \"field\": \"salesVolume\"\n         }\n       }\n     }\n   }\n }\n}\n```\n\n\n## 2.3  JavaAPI查询\n\n**1）HotelController**\n\n```java\n//自定义日期时间段聚合统计某品牌下酒店销量\n@GetMapping(\"/searchDateHistogram\")\npublic Map<String, Object> searchDateHistogram(@RequestParam Map<String, Object> searchParam) {\n    List<Map<String, Object>> result = hotelService.searchDateHistogram(searchParam);\n    return this.getJsonMap(true, \"\", result);\n}\n```\n\n**2）HotelService**\n\n```java\n/**\n     *自定义日期时间段聚合统计某品牌的酒店销量\n     * @param searchParam\n     * @return\n     */\nList<Map<String, Object>> searchDateHistogram(Map<String, Object> searchParam);\n```\n\n**3）HotelServiceImpl**\n\n```java\npublic List<Map<String, Object>> searchDateHistogram(Map<String, Object> searchParam) {\n\n    //定义结果集\n    List<Map<String, Object>> result = new ArrayList<>();\n\n    //设置查询\n    SearchRequest searchRequest = new SearchRequest(\"hotel\");\n\n    SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();\n\n    //todo 自定义日期时间段范围查询\n    RangeQueryBuilder queryBuilder = QueryBuilders.rangeQuery(\"createTime\")\n        .gte(searchParam.get(\"minTime\"))\n        .lte(searchParam.get(\"maxTime\"))\n        .format(\"yyyy-MM-dd\");\n    searchSourceBuilder.query(queryBuilder);\n\n    //todo 聚合查询设置\n    TermsAggregationBuilder aggregationBuilder = AggregationBuilders.terms(\"hotel_brand\").field(\"brand\").size(100);\n\n    //构建二级聚合\n    SumAggregationBuilder secondAggregation = AggregationBuilders.sum(\"hotel_salesVolume\").field(\"salesVolume\");\n    aggregationBuilder.subAggregation(secondAggregation);\n\n    searchSourceBuilder.aggregation(aggregationBuilder);\n\n\n    searchRequest.source(searchSourceBuilder);\n    try {\n\n        SearchResponse searchResponse = restHighLevelClient.search(searchRequest, RequestOptions.DEFAULT);\n\n        //todo 获取聚合结果并处理\n        Aggregations aggregations = searchResponse.getAggregations();\n        Map<String, Aggregation> aggregationMap = aggregations.asMap();\n        Terms terms = (Terms) aggregationMap.get(\"hotel_brand\");\n        List<? extends Terms.Bucket> buckets = terms.getBuckets();\n        buckets.forEach(bucket -> {\n\n            Map<String, Object> info = new HashMap<>();\n            info.put(\"brand\",bucket.getKeyAsString());\n\n            //获取二级聚合数据\n            ParsedSum parsedSum = bucket.getAggregations().get(\"hotel_salesVolume\");\n            Integer sumValue = (int) parsedSum.getValue();\n            info.put(\"sumValue\",sumValue);\n\n            result.add(info);\n        });\n\n        return result;\n    } catch (IOException e) {\n        e.printStackTrace();\n    }\n    return null;\n}\n```\n\n## 2.4 测试&前端效果展示\n\n**PostMan**\n\n```\nlocalhost:9001/hotel/searchDateHistogram\n```\n\n\n**前端工程效果演示**\n\n```\nhttp://localhost:8088/dist/view/listDateHistogram.html\n```\n\n\n# 3 酒店权重搜索\n\n## 3.1 需求分析\n\n​	当进行数据搜索时，有时需要将一些特定的商品排名更加靠前，以百度为例：\n\n\n## 3.2 权重介绍&设置\n\n### 3.2.1 权重介绍\n\n​	当搜索时，对于每条搜索结果都会有一个打分，匹配度越高，则排名越靠前。\n\n```yacas\n#查询多域展示相关结果数据\nGET hotel/_search\n{\n  \"query\": {\n    \"query_string\": {\n    \"fields\": [\"name\",\"synopsis\",\"area\",\"address\"],\n    \"query\": \"北京市万豪spa三星\"\n    }\n  }\n}\n```\n\n\n​	根据查询结果可以看出，每条搜索结果都是会`_score`字段，该字段代表搜索结果的得分，搜索结果越贴近搜索条件，则分值越高，排名越靠前。如要想将分数值设置的更高，则可以通过`权重`来进行改变。\n\n```yacas\nGET hotel/_search\n{\n  \"query\": {\n    \"query_string\": {\n    \"fields\": [\"name\",\"synopsis\",\"area\",\"address\"],\n    \"query\": \"北京市万豪spa三星\",\n    \"boost\": 50\n    }\n  }\n}\n```\n\n\n### 3.2.2 权重设置\n\n​	对于权重设置，提供了两种方式：**索引设置**、**查询设置**。\n\n**索引设置：**\n\n​	在创建索引时即配置权重，该方式在开发中不常用，因为随着业务的改变，要设置权重的域也会发生改变，而索引一旦创建则无法修改，除非删除索引重建。\n\n```yacas\nPUT hotel\n{\n  \"mappings\": {\n    \"properties\": {\n      \n      \"name\":{\n        \"type\": \"text\",\n        \"analyzer\": \"ik_max_word\",\n        \"boost\": 5\n      },\n      \"address\":{\n        \"type\": \"text\",\n        \"analyzer\": \"ik_max_word\",\n        \"boost\": 3\n      }\n    }\n  }\n}\n```\n\n**查询设置：**\n\n​	该方式在开发中很常用，根据业务条件需求，在查询时灵活的配置权重。\n\n​	在下列查询中，**query**中的内容为主查询条件，**functions**中为判断要为哪些数据加权。**weight**为加权值。\n\n```yacas\n#为品牌为万豪的酒店，权重值增加50倍\nGET hotel/_search\n{\n  \"query\": {\n    \"function_score\": {\n      \"query\": {\n        \"query_string\": {\n        \"fields\": [\"name\",\"synopsis\",\"area\",\"address\"],\n        \"query\": \"北京市spa三星\"\n        }\n      },\n      \"functions\": [\n        {\n          \"filter\": {\n            \"term\": {\n              \"brand\": \"万豪\"\n            }\n          },\n          \"weight\": 50\n        }\n      ]\n    }\n  }\n}\n```\n\n\n## 3.2 Kibana查询\n\n​	对搜索结果中，判定是广告的商品，加权100倍。\n\n**未加权的情况：**\n\n```yacas\nGET hotel/_search\n{\n  \"query\": {\n    \"function_score\": {\n      \"query\": {\n        \"query_string\": {\n        \"fields\": [\"name\",\"synopsis\",\"area\",\"address\"],\n        \"query\": \"北京市万豪spa三星\"\n        }\n      }\n    }\n  }\n}\n```\n\n\n**加权情况:**\n\n```yacas\nGET hotel/_search\n{\n  \"query\": {\n    \"function_score\": {\n      \"query\": {\n        \"query_string\": {\n        \"fields\": [\"name\",\"synopsis\",\"area\",\"address\"],\n        \"query\": \"北京市万豪spa三星\"\n        }\n      },\n      \"functions\": [\n        {\n          \"filter\": {\n            \"term\": {\n              \"isAd\": \"1\"\n            }\n          },\n          \"weight\": 100\n        }\n      ]\n    }\n  }\n}\n```\n\n\n​	此时可以发现，所有是广告的商品都排在了前面。\n\n## 3.3 JavaAPI查询\n\n**1）HotelController**\n\n```java\n//权重查询\n@GetMapping(\"/searchScoreQuery\")\npublic Map<String, Object> searchScoreQuery(@RequestParam Map<String, Object> searchParam, @PathParam(\"current\") Integer current, @PathParam(\"pageSize\") Integer pageSize) {\n    Map<String, Object> map = hotelService.searchScoreQuery(current, pageSize, searchParam);\n    return this.getJsonMap(true, \"\", map);\n}\n```\n\n**2）HotelService**\n\n```java\n/**\n     * 加权查询\n     * @param current\n     * @param size\n     * @param searchParam\n     * @return\n     */\nMap<String, Object> searchScoreQuery(Integer current, Integer size, Map<String, Object> searchParam);\n```\n\n**3）HotelServiceImpl**\n\n```java\npublic Map<String, Object> searchScoreQuery(Integer current, Integer size, Map<String, Object> searchParam) {\n\n    SearchRequest searchRequest = new SearchRequest(\"hotel\");\n\n    SearchSourceBuilder searchSourceBuilder = new SearchSourceBuilder();\n\n    //todo 构建查询\n    //构建主查询条件\n    QueryStringQueryBuilder queryStringQueryBuilder = QueryBuilders.queryStringQuery(searchParam.get(\"condition\").toString())\n        .field(\"name\")\n        .field(\"synopsis\")\n        .field(\"area\")\n        .field(\"address\")\n        .defaultOperator(Operator.OR);\n\n    //构建加权条件\n    FunctionScoreQueryBuilder.FilterFunctionBuilder[] scoreFunctionBuilder = new FunctionScoreQueryBuilder.FilterFunctionBuilder[]{\n        new FunctionScoreQueryBuilder.FilterFunctionBuilder(QueryBuilders.termQuery(\"isAd\",1), ScoreFunctionBuilders.weightFactorFunction(100))\n    };\n\n    FunctionScoreQueryBuilder queryBuilder = QueryBuilders.functionScoreQuery(queryStringQueryBuilder, scoreFunctionBuilder);\n    searchSourceBuilder.query(queryBuilder);\n\n\n    //设置分页\n    searchSourceBuilder.from((current - 1) * size);\n    searchSourceBuilder.size(size);\n\n    searchRequest.source(searchSourceBuilder);\n\n    try {\n        //处理查询结果\n        SearchResponse searchResponse = restHighLevelClient.search(searchRequest, RequestOptions.DEFAULT);\n\n        SearchHits hits = searchResponse.getHits();\n\n        long totalHits = hits.getTotalHits().value;\n\n        SearchHit[] searchHits = hits.getHits();\n\n        List<HotelEntity> list = new ArrayList<>();\n\n        for (SearchHit searchHit : searchHits) {\n            String sourceAsString = searchHit.getSourceAsString();\n            list.add(JSON.parseObject(sourceAsString, HotelEntity.class));\n        }\n\n        Map<String, Object> map = new HashMap<>();\n        map.put(\"list\", list);\n        map.put(\"totalResultSize\", totalHits);\n        map.put(\"current\", current);\n        //设置总页数\n        map.put(\"totalPage\", (totalHits + size - 1) / size);\n\n        return map;\n    } catch (IOException e) {\n        e.printStackTrace();\n    }\n    return null;\n}\n```\n\n## 3.4 测试&前端效果展示\n\n**PostMan**\n\n```\nlocalhost:9001/hotel/searchScoreQuery?current=1&pageSize=10\n```\n\n\n**前端工程效果展示**\n\n```\nhttp://localhost:8088/dist/view/listWeighting.html\n```\n\n\n# 4 数据增量更新-LogStash\n\n## 4.1 LogStash概述\n\n​	当前对于ES的数据来源是MySQL，所以当MySQL中产生新数据时，期望的是将最新的数据推送到ES中，这种操作叫做`数据增量更新`。可以通种两种方式来实现：\n\n​	**canal**：是阿里开源的产品，会监听MySQL中binlog日志的改变，一旦binlog日志发生改变，则可以获取到最新数据存储到ES，从而实现ES的数据增量更新。\n\n​	**logstash**：是Elastic的产品，著名的ELK的一个组成部分。通过定时运行logstash配置文件，来获取最新数据存储到ES中，从而实现ES的数据增量更新。\n\n​	此处讲解以logstash完成MySQL与ES的数据增量更新。\n\n## 4.2 LogStash安装&配置\n\n1）下载logstash镜像\n\n```yacas\n#注意要与ES版本一致\ndocker pull logstash:7.10.1\n```\n\n\n\n2）创建logstash容器\n\n```yacas\ndocker run -d --name logstash --privileged=true -v /mydata/logstash/:/etc/logstash/pipeline/ logstash:7.10.1\n```\n\n\n\n3）设置文件写入权限\n\n```yacas\nchown 1000:1000 /mydata/logstash/\n```\n\n\n\n4）上传mysql连接包到`/mydata/logstash/`下\n\n\n\n5）在`/mydata/logstash/`下创建文件`logstash.conf`，内容如下\n\n```yacas\ninput {\n  jdbc {\n  #设置mysql连接包,地址是容器内的地址\n  jdbc_driver_library => \"/etc/logstash/pipeline/mysql-connector-java-5.1.47.jar\"\n  #设置mysql驱动\n  jdbc_driver_class => \"com.mysql.jdbc.Driver\"\n  #设置mysql连接地址,注意必须是ip,不能是localhost\n  jdbc_connection_string => \"jdbc:mysql://192.168.1.4:3306/es\"\n  #数据库帐号\n  jdbc_user => \"root\"\n  #数据库密码\n  jdbc_password => \"root\"\n  #是否分页查询\n  jdbc_paging_enabled => \"true\"\n  #分页大小\n  jdbc_page_size => \"50000\"\n  #是否记录最后值\n  record_last_run => true\n  #是否使用列值\n  use_column_value => \"true\"\n  #追踪的列名\n  tracking_column => \"id\"\n  #追踪列的数据类型\n  tracking_column_type => \"numeric\"\n  #最后值记录在哪里\n  last_run_metadata_path => \"/etc/logstash/pipeline/logstash_metadata.txt\"\n  #执行查询的sql语句\n  statement => \"select * from t_hotel where id > :sql_last_value\"\n  #定时配置\n  schedule => \"*/5 * * * * *\"\n  }\n}\n\n\noutput {\n  elasticsearch {\n  #ES的ip地址和端口\n  hosts => \"192.168.200.151:9200\"\n  #ES的索引名称\n  index => \"hotel\"\n  #文档id\n  document_id => \"%{id}\"\n  }\n  stdout {\n   #日志输出\n   codec => json_lines\n  }\n}\n```\n\n\n\n6）进入容器\n\n```yacas\ndocker exec -it logstash /bin/bash\n```\n\n\n\n7）修改容器内配置文件\n\n```yacas\n#进入config文件\ncd config\n\n#更改logstash.yml文件\nvi logstash.yml\n```\n\n\n8）修改容器内配置文件\n\n```yacas\n#进入config文件\ncd config\n\n#更改pipelines.yml文件\nvi pipelines.yml\n```\n\n```yacas\n/etc/logstash/pipeline/logstash.conf\n```\n\n\n\n9）退出并重启容器\n\n```yacas\n#退出容器\nexit\n\n#重启容器\ndocker restart logstash\n```\n\n\n\n10）检查是否进行更新\n\n\n```sql\nINSERT INTO t_hotel(name,address,brand,type,price,specs,salesVolume,synopsis,area,imageUrl,createTime,isAd) VALUES (\'北京市昌平区绿茶酒店\', \'北京市昌平区天通苑东二区83号\', \'绿茶\', \'酒店\', 1888, \'三星级\', 153, \'高端商务按摩spa品茶\', \'北京市\', \'https://www.hilton.com.cn\', \'2020-10-26\', 1);\n```\n', '2021-12-17 11:47:38', 0, NULL, 0);
INSERT INTO `m_blog` VALUES (15, 1, 'RocketMQ--01', 'RocketMQ是阿里开源的一款非常优秀中间件产品', '# RocketMQ-day01\n\n# 1 案例场景分析\n\n​	假设存在**商品服务**和**库存服务**，每次购买商品时，都要让库存服务扣减对应库存。此时则需要商品服务调用库存服务中扣减库存方法。在原始架构中如想完成调用，则需要在商品服务中添加库存服务的依赖。\n\n## 1.1 服务耦合\n\n​	当商品服务中添加了库存服务的依赖，此时服务耦合出现。 假设库存服务出现问题，响应速度过慢或无法被调用。则势必会影响到商品服务，甚至造成服务雪崩。**在架构设计中应尽量让服务间松耦合**。\n\n## 1.2 同步低效\n\n​	对于当前功能需求来说，商品服务并不需要获取库存服务的结果返回。而按照现在来说，当商品服务调用库存服务时，则必须要等待库存服务执行完毕，商品服务才会继续向下执行。 这种就是**同步调用**。在这种上游服务并不关心下游服务的场景下，应该避免使用同步调用。**在架构设计中，能做异步的就尽量不要同步。**\n\n## 1.3 并发宕机\n\n​	在一些高并发访问的场景下，如促销、秒杀等。短时间内后端会接收到大量请求连接进行处理，这样的话，则很有可能短时间内造成后端服务OOM，从而宕机。\n\n## 1.4 数据丢失\n\n​	当前端连接后端发送数据进行业务处理时，假设后端服务出现异常或宕机，则本次请求的业务数据就会丢失，造成业务处理结果错误。\n\n# 2 消息队列概述\n\n​	随着微服务架构的兴起，原有集中式的架构，现在会被分成若干细粒度的多个微服务。这些服务可以在同一个局域网内，也可以跨机房部署。因为一方面对服务间松耦合的要求越来越高。另一方面，服务间的联系却越来越紧密。同时对通信质量的要求也越来越高。\n\n​	因此消息队列应运而生，对于消息队列的理解，可以分为两部分：\n\n- **消息：**服务调用时，被传递的数据。\n- **队列：**一种线性数据结构，能够进行数据存储，其特点是“先进先出”。队列的数据存储是如同排队一般，先入队的数据会先被出队。\n\n![在这里插入图片描述](assets\\20200526101424265.gif)\n\n## 2.1 工作模型\n\n​	消息队列的基础工作模型称为：**生产者消费者模型**。 使用消息队列时，由**生产者（producer）生产投递消息**、由**消费者（consumer）接收处理消息**。\n\n\n​	在整个过程中，生产者只负责组织生产消息到消息队列，不关注消息被谁消费、何时消费、如何消费。 而消费者只负责接收处理队列中的消息，不关注该消息被谁生产、如何生产。 从而实现服务间松耦合。\n\n## 2.2 作用\n\n### 2.2.1 应用解耦\n\n​	一个复杂的应用系统中会存在很多子服务，并且服务间会涉及到相互调用。如电商系统中的商品服务、购物车服务、订单服务、库存服务等等。如果系统内部服务间耦合性太高，则会让系统可用性大幅降低。\n\n​	如下图所示，所有服务都是耦合在一起的，假设任何一个服务的不可用，都会导致整个系统的不可用。在影响系统可用性的同时，也会降低用户的体验度。\n\n\n\n​	要想解决该问题，则可以通过消息队列改造，进行服务间解耦。假设在工作过程中，库存服务不可用。只需要将数据保存在队列中，等库存服务恢复后，再从队列中获取数据继续处理即可。 此时并不会影响整个系统运行，并且用户也是无感知的。\n\n\n### 2.2.2 异步通信\n\n​	在原始架构中，服务间采用同步方式完成调用，调用方必须要等到被调用方成功执行完毕后，才会继续执行，因此效率低下。如果上游服务并不需要等下游服务执行完就可向下执行，则可以通过异步进行改造。\n\n​	如上图所示，在原始架构中，假设每个服务耗时**10s**，则最终结果返回共计耗时**40s**。 而采用消息队列进行异步通信时，当商品服务将消息发送到消息队列后，即可向用户返回结果。 后续其他服务从队列中获取消息进行异步处理即可，从而提升系统吞吐量。\n\n\n### 2.2.3 流量消峰\n\n​	在高并发场景下，如促销、秒杀等场景，短时间内会有庞大的请求流量进入后端服务，后端服务如果承受不了这些流量的话，就会造成系统宕机。如果要提升服务能力，最简单的方式就是添加更多的服务器，但是需要额外支付大笔资金。\n\n​	而使用消息队列后，即可在后端服务前面部署消息队列。用户的请求流量都会暂存在队列中，然后后端服务批次的进行处理。\n\n\n### 2.2.4 消息分发\n\n​	商品服务发送的某些消息可能只需要订单服务处理或库存服务处理。在消息队列中，可以让不同的消息消费者只订阅接收自身需要的数据。从而避免大量的网络通信与消息的重复处理。\n\n\n## 2.3 技术选型对比\n\n​	对于消息队列的技术实现，当前市面上的主流产品主要有三个：RabbitMQ、RocketMQ、Kafka。\n\n\n```\nRabbitMQ\n优点:                            \n	1.支持AMQP协议                                       \n	2.基于erlang语言开发，高并发性能较好                     \n	3.工作模式较为灵活  \n    4.支持延迟消息\n	5.提供较为友好的后台管理页面\n	6.单机部署，1~2WTPS\n缺点：\n	1.不支持水平扩容\n	2.不支持事务\n	3.消息吞吐量三者最差\n	4.当产生消息堆积，性能下降明显\n	5.消息重发机制需要手动设置\n	6.不支持消息重复消费\n```\n\n\n```\nRocketMQ\n优点：\n	1.高可用，高吞吐量，海量消息堆积，低延迟性能上，都表现出色\n	2.api与架构设计更加贴切业务场景\n	3.支持顺序消息\n	4.支持事务消息\n	5.支持消息过滤\n	6.支持重复消费\n	7.支持延迟消息\n	8.支持消息跟踪\n	9.天然支持集群、负载均衡\n	10.支持指定次数和时间间隔的失败消息重发\n	11.单机部署，5~10WTPS\n缺点：\n	1.生态圈相较Kafka有所不如\n	2.消息吞吐量与消息堆积能力也不如Kafka\n	3.不支持主从自动切换\n	4.只支持Java\n```\n\n\n```\nKafka:\n优点：\n	1.高可用，高吞吐量，低延迟性能上，都表现出色\n	2.使用人数多，技术生态圈完善\n	3.支持顺序消息\n	4.支持多种客户端\n	5.支持重复消费\n缺点：\n	1.依赖分区，消费者数量受限于分区数\n	2.单机消息过多时，性能下降明显\n	3.不支持事务消息\n	4.不支持指定次数和时间间隔的失败消息重发\n```\n\n# 3 RocketMQ介绍&部署\n\n## 3.1 介绍\n\n​	RocketMQ是阿里开源的一款非常优秀中间件产品，脱胎于阿里的另一款队列技术MetaQ，后捐赠给Apache基金会作为一款孵化技术，仅仅经历了一年多的时间就成为Apache基金会的顶级项目。并且它现在已经在阿里内部被广泛的应用，并且经受住了多次双十一的这种极致场景的压力。（**2017年的双十一，RocketMQ流转的消息量达到了万亿级，峰值TPS达到5600万**）。并且其内部通过Java语言开发，便于阅读与修改。\n\n## 3.2 特点\n\n**1）低延迟,高吞吐：**在高压下，一毫秒内能将超过99.6%的响应返回。\n\n**2）海量消息堆积：**单机可以支持亿级消息堆积，且仍能保持低延迟率。\n\n**3）有序消息：**消息消费时，能按照发送的顺序来消费。分为全局有序和分区有序。\n\n**4）消息过滤：**消费者可以根据自定义属性对消息过滤。\n\n**5）消息高可靠：**保证99%的消息不丢，但是仍然会有极少量的消息可能丢失。\n\n**6）事务消息：**应用本地事务和发送消息操作可以被定义到全局事务中，要么同时成功，要么同时失败。\n\n**7）定时消息（延迟队列）：**消息发送到RocketMQ后，不会立即被消费，等待特定时间才会被消费。\n\n**8）消息重投：**生产者发送消息失败时会重新发送，保证消息尽可能发送成功、不丢失。\n\n**9）消息重试：**消费者处理消息失败时，会重新处理，保证消息尽可能消费成功。\n\n**10）流量控制：**分为生产者流控与消费者流控。避免生产者消费者达到能力瓶颈。\n\n**11）死信队列：**用于处理无法被正常消费的消息。\n\n## 3.3 企业图谱\n\n目前已经有超过100家企业其业务中使用RocketMQ，下图是部分使用到RocketMQ的大厂：\n\n\n## 3.4 架构\n\n### 3.4.1 角色\n\n**Producer：**\n\n​	消息的生产发送者。如发件者。\n\n**Consumer：**\n\n​	消息的接收消费者。如收件者。\n\n**Broker：**\n\n​	暂存和传输消息。如快递站。\n\n**NameServer：**\n\n​	管理Broker。如快递站管理机构。\n\n**Topic：**\n\n​	区分消息种类。一个Topic可以对应多个Broker。一个Producer可以发送消息给一个或多个Topic，一个Consumer可以接收一个或多个Topic消息。\n\n**Message Queue：**\n\n​	相当于Tipic的分区，用于并行发送和接收消息，一个Topic可以对应多个MessageQueue。\n\n### 3.4.2 执行流程\n\n1）启动NameServer后，其会Broker、Producer、Consumer连接。\n\n2）Broker启动后会与NameServer建立长连接，并定时发送心跳包。心跳包中包含Broker的元信息（IP+端口等）以及其内部存储的所有Topic信息。注册成功后，NameServer中就存在了Broker与Topic的映射关系。\n\n3）收发消息前，需要先创建Topic并指定其存在在哪个Broker上，也可以在发送消息时自动创建Topic。\n\n4）Producer启动时，先与NameServer建立长连接。当发送消息时，会从NameServer获取当前发送的Topic存储在哪些Broker上，通过轮询方式从队列列表中选择一个队列，然后与队列所在的Broker建立长连接，从而完成消息发送。\n\n5）Consumer启动时，先与NameServer建立长连接，获取被订阅的Topic存在于哪些Broker上，接着与Broker建立连接通道，进行消息消费。\n\n## 3.5 部署\n\n### 3.5.1 RocketMQ部署\n\n1）下载黑马程序员的RocketMQ镜像\n\n```yacas\ndocker pull registry.cn-hangzhou.aliyuncs.com/itheima_wzh/heimarocketmq:1.0\n```\n\n2）宿主机下创建目录\n\n```yacas\nmkdir -p /mydata/rocketmq/namesrv/logs\n\nmkdir -p /mydata/rocketmq/namesrv/store\n\nmkdir -p /mydata/rocketmq/brokersrv/logs\n\nmkdir -p /mydata/rocketmq/brokersrv/store\n\nmkdir -p /mydata/rocketmq/brokersrv/conf\n```\n\n3）创建并编辑broker配置文件\n\n```properties\ncd /mydata/rocketmq/brokersrv/conf\n\nvi broker.conf\n\n#配置文件内容\nbrokerClusterName = DefaultCluster\nbrokerName = broker-a\nbrokerId = 0\ndeleteWhen = 04\nfileReservedTime = 48\nbrokerRole = ASYNC_MASTER\nflushDiskType = ASYNC_FLUSH\nbrokerIP1 = 服务器的实际IP\n```\n\n4）启动nameserver\n\n```yacas\ndocker run -d -p 9876:9876 -v /mydata/rocketmq/namesrv/logs:/root/logs -v /mydata/rocketmq/namesrv/store:/root/store --name rmqnamesrv -e \"MAX_POSSIBLE_HEAP=100000000\" registry.cn-hangzhou.aliyuncs.com/itheima_wzh/heimarocketmq:1.0 sh mqnamesrv\n```\n\n5）启动broker\n\n```yacas\ndocker run -d -p 10911:10911 -p 10909:10909 -v  /mydata/rocketmq/brokersrv/logs:/root/logs -v  /mydata/rocketmq/brokersrv/store:/root/store -v  /mydata/rocketmq/brokersrv/conf/broker.conf:/opt/rocketmq-4.8.0/conf/broker.conf --name rmqbroker --link rmqnamesrv:namesrv -e \"NAMESRV_ADDR=namesrv:9876\" -e \"MAX_POSSIBLE_HEAP=200000000\" registry.cn-hangzhou.aliyuncs.com/itheima_wzh/heimarocketmq:1.0 sh mqbroker -c /opt/rocketmq-4.8.0/conf/broker.conf\n```\n\n### 3.5.2 管理平台-RocketMQConsole部署\n\n1）下载Rocketmq-console镜像\n\n```yacas\ndocker pull apacherocketmq/rocketmq-console:2.0.0\n```\n\n2）宿主机下创建目录\n\n```yacas\nmkdir -p /mydata/rocketmq/rocketmq-console/logs\n```\n\n3）启动Rockermq-console\n\n```yacas\ndocker run -d --restart=always --name rocketmq-console -v /mydata/rocketmq/rocketmq-console/logs:/root/logs -e \"JAVA_OPTS=-Drocketmq.namesrv.addr=nameserver所在服务器实际IP:9876 -Dcom.rocketmq.sendMessageWithVIPChannel=false\" -p 8181:8080 -t apacherocketmq/rocketmq-console:2.0.0\n```\n\n4）访问\n\n\n\n\n# 4 RocketMQ与SpringBoot整合\n\n**引入/05_资料/rocketMQ_test工程**\n\n## 4.1 生产者服务搭建\n\n1）添加rocketMQ依赖\n\n```xml\n<!--rocketmq依赖-->\n<dependency>\n    <groupId>org.apache.rocketmq</groupId>\n    <artifactId>rocketmq-spring-boot-starter</artifactId>\n    <version>2.2.0</version>\n</dependency>\n```\n\n2）修改application.yml\n\n```yml\nrocketmq:\n  name-server: 192.168.200.151:9876 #rocketmq地址\n  producer:\n    group: my-group #自定义组名\n    send-message-timeout: 5000 #消息发送超时时间\n```\n\n3）测试类\n\n```java\n@SpringBootTest\n@RunWith(SpringRunner.class)\npublic class ProducerTest {\n\n    @Autowired\n    private RocketMQTemplate rocketMQTemplate;\n\n    @Test\n    public void sendMessage(){\n        //普通发送\n        rocketMQTemplate.convertAndSend(\"demo-topic\",\"hello rocketmq\");\n        \n        //封装消息体发送\n        Message<String> message = new GenericMessage<>(\"hello rocketmq\");\n        rocketMQTemplate.convertAndSend(\"demo-topic\",message);\n    }\n}\n```\n\n4）查看控制台\n\n**主题**\n\n\n**消息**\n\n\n## 4.2 消费者服务搭建\n\n1）修改application.yml\n\n```yml\nrocketmq:\n  name-server: 192.168.200.151:9876 #rocketmq连接地址\n```\n\n2）定义消息监听类\n\n```java\n@Component\n@RocketMQMessageListener(topic = \"demo-topic\",consumerGroup = \"demo-consumer-group\")\npublic class MessageListener implements RocketMQListener<String> {\n    @Override\n    public void onMessage(String message) {\n        System.out.println(message);\n    }\n}\n```\n\n3）启动消费者，观察控制台\n\n\n# 5 消息生产&消费方式\n\n## 5.2 生产方式\n\nRocketMQ中提供了多种消息发送方式，如同步发送、异步发送等等。在不同的业务场景与需求下，配置使用不同的发送方式。\n\n**1）同步发送**\n\n​	之前通过convertAndSend发送消息本身也是同步发送，但是无法获取到返回结果。 如果需要发送结果，则需要以如下方式发送\n\n```java\n@Test\npublic void syncSendMessage(){\n    //同步发送\n    SendResult result = rocketMQTemplate.syncSend(\"sync-topic\", \"sync message\");\n    SendStatus sendStatus = result.getSendStatus();\n    /**\n         * SEND_OK(0):发送成功\n         * FLUSH_DISK_TIMEOUT(1):没有在规定时间之内完成刷盘（需要broker的刷盘策略是SYNC_FLUSH才会出现此信息）\n         * FLUSH_SLAVE_TIMEOUT(2):没有在规定时间之内完成主从同步（需要在主备环境下，且broker被设置为SYNC_MASTER，才会出现此信息）\n         * SLAVE_NOT_AVAILABLE(3):没有找到被配置成SLAVE的broker（需要在主备环境下，且broker被设置为sync_mater，才会出现此信息）\n         */\n    int ordinal = sendStatus.ordinal();\n    if (! (ordinal == 0)){\n        System.out.println(\"发送失败\");\n        return;\n    }\n    System.out.println(\"发送成功\");\n}\n```\n\n**2）异步发送**\n\n```java\n@Test\npublic void asyncSendMessage() throws InterruptedException {\n\n    rocketMQTemplate.asyncSend(\"async-topic\", \"async message\", new SendCallback() {\n        @Override\n        public void onSuccess(SendResult sendResult) {\n            System.out.println(sendResult.getMsgId());\n        }\n\n        @Override\n        public void onException(Throwable throwable) {\n            System.out.println(throwable.getMessage());\n        }\n    });\n\n    System.out.println(\"do other things\");\n\n    //等待异步结果返回\n    TimeUnit.SECONDS.sleep(1);\n}\n```\n\n**3）单向发送**\n\n​	单向发送方式只发送请求不等待应答，采用这种方式发送消息耗时可以缩短到毫秒级。适用于一些速度要求高，可靠性要求不高的场景，如日志收集。\n\n```java\n//单向发送方式只发送请求不等待应答，采用这种方式发送消息耗时可以缩短到毫秒级。适用于一些速度要求高，可靠性要求不高的场景，如日志收集。\n@Test\npublic void oneWaySendMessage(){\n\n    rocketMQTemplate.sendOneWay(\"oneway-topic\",\"oneway message\");\n}\n```\n\n## 5.2 消费方式\n\n​	任何一款消息中间件，对于消费端获取消息都会有两种消息订阅方式：**Push推模式、Pull拉模式**。\n\n**push推模式：**\n\n​	消费端与MQ建立长连接，当向MQ发送消息，MQ会立即主动的向消费者推送数据。 好处在于实时性高，缺点在于消费端处理能力存在瓶颈，如果瞬时向消费端推动大量消息，轻则造成消息堆积，重则造成消费端宕机。\n\n\n**pull拉模式：**\n\n​	消费端定期主动到MQ拉去消息。好处在于提升了消费端的可用性，缺点在于无法准确设置拉取消息的间隔，间隔太久，影响消息时效性，间隔太短，则会造成很多无效连接浪费资源。\n\n\n**思考：上述两种方式，各自都存在优缺点，那么在RocketMQ采用的是哪种方式呢？**\n\n​	RocketMQ的消费方式是基于pull拉模式，但是其内部又对pull拉模式进行了优化，引入了**长轮询机制**来平衡其缺点。在一次长轮询中：如果消费者第一次pull消息失败（如MQ中没有消息），MQ并不会立即向消费者返回响应，而是先将请求挂起保存到本地缓存中，接着MQ本身会开启一个线程**每隔五秒**从本地缓存中获取消费者请求让其获取消息，当有消息时，则会将消息返回到客户端。 **默认整个长轮询时间为30秒。**\n\n# 6 消息过滤\n\n## 6.1 需求分析\n\n​	根据基础案例工程可知，订单服务发送消息时使用的是order-topic，库存服务与短信服务都监听该topic。当订单服务发送消息，此时库存&短信服务都会被触发。此时想要不同的消费者虽然都订阅着相同的topic，但是想让他们接收到不同的消息，此时该怎么办？\n\n​	RocketMQ为了提升整体消息吞吐量性能，提供了消息过滤的功能。消息过滤是通过消息体之外增加一个自定义Tag（标签）来实现。tag标签就是一个简单的字符串，并且一个message只有一个tag。 定义格式：`topic:tag`\n\n## 6.2 发送消息\n\n\n根据源码可知，在发送消息时，可以在topic后面加上`:tag`进行拼接。\n\n```java\n//向stock服务发送消息\nSendResult sendResult = rocketMQTemplate.syncSend(\"order-topic:stock\", JSON.toJSON(orderEntity));\n```\n\n发送后，查看监控平台，可以发现消息上除了topic之外，额外还存在tag标识\n\n\n## 6.3 接收消息\n\n​	在接收消息时，可以指定具体的tag标识，默认为*，代表接收所有。\n\n\n​	根据源码可知，接收类型默认为tag，值为*。同时还有另一种接收类型为`SQL92`，但该方式只能在push模式下使用，开发中并不常用，如想指定自定义tag，则可以在`@RocketMQMessageListener`中添加`selectorExpression`属性，指定具体值。\n\n**修改库存服务的消息监听类，添加自定义tag标识**\n\n\n```java\n@RocketMQMessageListener(topic = \"order-topic\",consumerGroup = \"order-group\",selectorExpression = \"stock\")\n```\n\n**测试运行可以发现，当生产者发送消息时，此时只有库存服务接收消息，而短信服务不会接收。**\n\n# 7 延迟消息(定时消息)\n\n​	延迟消息也可以叫做定时消息，这个消息特性在很多业务场景都会有所涉及。比如在电商项目的交易系统中，当用户下单之后超过一段时间之后仍然没有支付，此时就需要将该订单关闭。要实现该功能的话，可以在用户创建订单时就发送一条包含订单内容的延迟消息，该消息在一段时间之后投递给消息消费者，当消费者接收到该消息后，判断该订单的支付状态，如果处于未支付状态，则不处理该订单。\n\n​	RocketMQ的消息延迟时间不支持任意设置，只存在十八个等级**（1s/5s/10s/30s/1m/2m/3m/4m/5m/6m/7m/8m/9m/10m/20m/30m/1h/2h）**。实现的话，只需要在发送消息时，设置与时间相对应的延迟级别即可。\n\n```java\n//发送订单延迟消息\n//封装消息对象\nMessage<String> message = new GenericMessage<>(JSON.toJSONString(orderEntity));\n/**\n * destination: 目的地，topic:tag\n * message: 消息体\n * timeout：发送消息超时时间\n * delayLevel：延迟等级,当为0代表不延迟\n*/\nSendResult sendResult = rocketMQTemplate.syncSend(\"order-topic:stock\", message, 5000, 4);\n```\n\n# 8 有序消息\n\n## 8.1 介绍\n\n​	每当生产者向一个新的Topic发送消息时，RocketMQ都会给该Topic创建四个对应的Queue。同时Producer会采用负载均衡策略向每一个Queue轮流的发送消息，并且Consumer默认也采用负载均衡策略从该topic下的四个队列进行消息消费。\n\n\n​	在某些场景下，会要求生产者按照一定的顺序发送消息，并且消费者在接收消息的时候也必须严格的按照生产者的发送顺序进行消费，比方说记录数据库操作日志、订单流转过程等。\n\n​	RocketMQ中的顺序消息分为**全局有序与局部有序**。全局有序可以保证某个Topic下的所有消息都要保证顺序，局部可以序指保证每一组消息都被顺序消费。\n\n​	RocketMQ默认不保证消息顺序，在默认的情况下，当producer创建一个Topic，会生成四个队列与之对应，并且会采用轮询的方式向这四个队列逐一发送。当接收消息的时候，也有可能存在多个consumer，每个consumer也可能启动多个线程并行处理，所以消息被哪个consumer消费，消息的写入顺序与读取顺序也是不可控的。\n\n**订单服务改造并启动**\n\n```java\nSendResult sendResult = null;\nfor (int i = 0; i < 10; i++) {\n    sendResult = rocketMQTemplate.syncSend(\"order-topic:message\", \"message : \"+i);\n}\n```\n\n**启动短信服务**\n\n**当生产者发送多条信息后，可以发现，消费者实例接收到了消息，并且是无序的。**\n\n\n\n\n## 8.1 全局有序消息\n\n​	要保证全局有序消息，需要将Topic的读写队列数设置为一，且producer与consumer的并发数也要设置为一。通过这种方式将各部分全部置为单线程，从而保证整个topic的消息有序，但是这时RocketMQ最引以为傲的高并发、高吞吐的能力就完全用不上了。从而导致整个系统的性能降低，这是绝对不可以接受的。\n\n​	**因此在实际应用中，对于消息有序的场景，经过合适的配置，只需要保证局部有序即可**。此时对于高并发、高吞吐量的能力仍然可以利用。\n\n## 8.2 局部有序消息\n\n​	要保证局部有序，需要producer与consumer配合处理。producer需要保证将同一类型的消息发送到同一个Queue中。consumer需要保证从同一个Queue中获取的消息不被并发处理。\n\n### 8.2.1 生产者发送有序消息\n\n​	生产者如想发送有序消息，需要调用xxxOrderly()，并设置消息要进入哪个队列中。\n\n\n```java\n//有序消息\nSendResult sendResult = null;\nfor (int i = 0; i < 10; i++) {\n/**\n  * destination：消息目的地\n  * payload：消息内容\n  * hashKey：该值用于判断当前消息会进入哪个队列，计算公式：传入值%队列总数=队列id，如6%4=2，值进入id为2的队列\n*/\n    sendResult = rocketMQTemplate.syncSendOrderly(\"order-topic:message\", \"message : \"+i,\"6\");\n}\n```\n\n测试发现，当前10条消息全部进入到id为2的队列中。\n\n\n### 8.2.2 消费者接收有序消息\n\n​	在消费者一方，只需要在`@RocketMQMessageListener`添加属性`consumeMode`值为`ConsumeMode.ORDERLY`，根据源码可知，该值会将消费者设置为只监听一个队列，并只使用一个线程\n\n\n```java\n@Component\n@RocketMQMessageListener(topic = \"order-topic\",consumerGroup = \"message_group\",selectorExpression = \"message\",consumeMode = ConsumeMode.ORDERLY)\npublic class OrderMessageListener implements RocketMQListener<String> {\n\n    @Override\n    public void onMessage(String message) {\n\n        try{\n            System.out.println(\"message service : \"+message);\n        }catch (Exception e){\n            System.out.println(e.getMessage());\n        }\n    }\n}\n```\n\n启动消费者实例，并重新发送消息可以发现，多条消息被消费者有序接收。\n\n\n', '2022-01-20 11:49:35', 0, NULL, 0);
INSERT INTO `m_blog` VALUES (16, 1, 'RocketMQ--02', 'RocketMQ是阿里开源的一款非常优秀中间件产品', '# RocketMQ-day02\n\n# 1 消息重试解决方案\n\n​	在生产环境下，由于环境的复杂性经常性会出现一些不可预知的问题，如网络波动、服务宕机、程序异常等问题。因此很有可能出现生产者发送消息或消费者消费消息失败。因此所有的消息中间件产品都会存在一个机制，就是重试机制。如果没有重试，则很有可能出现消息丢失的问题。\n\n## 1.1 生产者消息重试\n\n​	生产者向Broker发送消息时，因为一些不可预知异常导致消息发送失败，所以可以设置相关参数让消息进行重发。 默认情况下，当消息发送后，broker超过3秒没有应答则会触发重试。对于同步发送与异步发送，默认重试两次。 \n\n\n\n如需修改只需设置相关参数即可\n\n```yml\nrocketmq:\n  name-server: 192.168.200.151:9876 #rocketmq地址\n  producer:\n    group: producer-group #自定义组名\n    send-message-timeout: 5000 #消息发送超时时间\n    retry-times-when-send-failed: 3 #同步发送重试次数\n    retry-times-when-send-async-failed: 3 #异步发送重试次数\n```\n\n## 1.2 消费者消息重试\n\n### 1.2.1 概述\n\n​	当消费者处理消息的过程中，假设出现不可预知的情况时，则会导致消息丢失。因此消费者一方势必需要具备重试机制。\n\n​	消费者消费消息后，需要给Broker返回消费状态。\n\n```java\npublic enum ConsumeConcurrentlyStatus {\n    /**\n     * Success consumption \n     * 消费成功\n     */\n    CONSUME_SUCCESS,\n    /**\n     * Failure consumption,later try to consume\n     * 消费失败，稍后让消费者重试\n     */\n    RECONSUME_LATER;\n}\n```\n\n如果返回的是`RECONSUME_LATER`则需要进行重试，在两种情况下会触发消费者重试：**异常重试**、**超时重试**\n\n### 1.2.1 有序消息重试机制\n\n​	由于有序消息的特性，需要多条消息被逐一消费。当消费者处理某一条消息失败后，RocketMQ会自动不断的进行重试（每次间隔时间为 1 秒）。 但此时会造成其他消息被阻塞，导致系统性能下降。 因此需要系统能够及时监控并处理消费失败的情况，避免阻塞出现。\n\n```java\n@Component\n@RocketMQMessageListener(topic = \"order-topic\",consumerGroup = \"message_group\",selectorExpression = \"message\",consumeMode = ConsumeMode.ORDERLY)\npublic class OrderMessageListener implements RocketMQListener<String> {\n\n    @Override\n    public void onMessage(String message) {\n        System.out.println(\"message service : \"+message);\n        //模拟异常情况\n        if (\"3\".equals(message)){\n            int i=1/0;\n        }\n    }\n}\n```\n\n### 1.2.2 无序消息重试机制\n\n​	对于无序消息（普通、延迟等）默认重试次数16次，默认超时时间15分钟。当达到最大重试次数后仍然失败，消息将不再进行重试。\n\n| 重试次数 | 重试间隔 |\n| :------: | :------: |\n|    1     |  10 秒   |\n|    2     |  30 秒   |\n|    3     |  1 分钟  |\n|    4     |  2 分钟  |\n|    5     |  3 分钟  |\n|    6     |  4 分钟  |\n|    7     |  5 分钟  |\n|    8     |  6 分钟  |\n|    9     |  7 分钟  |\n|    10    |  8 分钟  |\n|    11    |  9 分钟  |\n|    12    | 10 分钟  |\n|    13    | 20 分钟  |\n|    14    | 30 分钟  |\n|    15    |  1 小时  |\n|    16    |  2 小时  |\n\n修改默认超时时间\n\n```java\n@RocketMQMessageListener(consumeTimeout = 1L ) #修改超时时间为1分钟\n```\n\n重试效果演示，让订单服务处理消息时出现异常，重试效果如下\n\n\n\n# 2 消息幂等性解决方案\n\n## 2.1 概述\n\n​	因为有了消息重试，所以还需要考虑消息重复问题。假设消费者处理消息过程中因为一些原因导致超时响应，此时则会对该条消息进行重试。但消费者过一阵子恢复了就又会处理这个消息，造成消息被重复消费。\n\n   业界的通常做法是在消息消费者一方进行去重，从而保证消息的幂等性。RocketMQ为了追求性能，对于防重自身没有做具体的实现，因此需要开发人员手动进行实现。比较常见的解决方式有： 1）业务数据标识判断  2）消息日志表。\n\n## 2.2 解决方案实现\n\n​	在发送消息时，可以给每个消息设置唯一的消息key作为标识。 当接收消息时，将消息唯一标识作为主键插入到消息表， 插入成功，则代表该消息之前没有被处理过，继续执行业务逻辑。 如果插入失败，则代表该消息之前被处理过，则不执行后续业务逻辑。\n\n**1）生产者实现**\n\n```java\n//消息幂等性解决方案\nMessage message = new Message();\n//封装消息体\nmessage.setBody(JSON.toJSONString(orderEntity).getBytes(StandardCharsets.UTF_8));\n//设置消息唯一标识\nmessage.setKeys(UUID.randomUUID().toString());\n//发送消息\nSendResult sendResult = rocketMQTemplate.syncSend(\"order-topic:stock\", message);\n```\n\n**2）消费者实现**\n\n```java\n@Override\npublic void onMessage(Message message) {\n\n    //以message的key作为主键id，向消息表插入数据。通过主键避免消息重复处理\n    System.out.println(LocalTime.now()+\"stock service : \"+ new String(message.getBody()));\n\n    //校验幂等\n    MessageEntity messageEntity = new MessageEntity();\n    messageEntity.setMessageId(message.getKeys());\n    try {\n        messageMapper.insert(messageEntity);\n    } catch (DuplicateKeyException e) {\n        System.out.println(\"该消息已存在，不做处理\");\n        return;\n    }\n\n    //模拟超时\n    try {\n        TimeUnit.MINUTES.sleep(2);\n    } catch (InterruptedException e) {\n        e.printStackTrace();\n    }\n\n    //解析消息\n    OrderEntity orderEntity = JSON.parseObject(new String(message.getBody()), OrderEntity.class);\n\n    //扣减库存\n    QueryWrapper<StockEntity> wrapper = new QueryWrapper<>();\n    wrapper.lambda().eq(StockEntity::getGoodsId,orderEntity.getGoodsId());\n    StockEntity stockEntity = stockService.getOne(wrapper);\n\n    stockService.reduceStock(orderEntity.getGoodsId(),orderEntity.getNumber(),stockEntity.getVersion());\n\n    //删除消息表数据\n    messageMapper.deleteById(message.getKeys());\n}\n```\n\n# 3 失败消息处理解决方案\n\n​	在业务处理时，如果某条消息持续失败，达到最大16次后将不再对其进行重试。但是这条消息不能直接丢弃，因为消息都是携带着业务数据的，RocketMQ会将达到最大重试次数的消息放入到另外一个队列： 死信队列。\n\n## 3.1 效果演示\n\n​	因为重试默认间隔时间要达到16次需要等待4小时46分钟，所以可以在broker端的**broker.conf**中修改重试间隔时间。\n\n```properties\nmessageDelayLevel = 2s 2s 2s 2s 2s 2s 2s 2s 2s 2s 2s 2s 2s 2s 2s 2s 2s 2s\n```\n\n`注意：此操作只为效果演示，生产环境下不要执行此操作`\n\n​	在库存服务中添加异常， 此时可以发现，每间隔两秒会进行一次重试，当达到16次后不会再进行重试。 同时在RocketMQ控制台产生了死信队列`%DLQ%stock-dlq-group`\n\n\n\n## 3.2 处理死信队列消息\n\n​	如想获取死信队列中的消息非常简单，只需要订阅该topic即可。\n\n**修改死信队列的读写权限**\n\n\n**查看message信息**\n\n**短信服务中定义消息监听类，获取死信队列的消息**\n\n```java\n//短信服务中定义消息监听类，获取死信队列的消息\n@Component\n@RocketMQMessageListener(topic = \"%DLQ%stock-group13\",consumerGroup = \"dlq_message_group\",selectorExpression = \"stock\")\npublic class DLQListener implements RocketMQListener<Message> {\n\n    @Override\n    public void onMessage(Message message) {\n\n        System.out.println(\"receive dlq message : \"+new String(message.getBody()));\n\n    }\n}\n```\n\n# 4 分布式事务解决方案\n\n## 4.1 需求场景分析\n\n​	在分布式场景下，有些业务需要保证多个服务的多个操作，要么一起成功，要么一起失败。但是原有的通过@Tranactional的方式，其是基于springAOP实现只能保证单一服务的事务原子性，无法保证多个服务的原子性。 因此，需要通过分布式事务来保证多服务操作的原子性，现在市面上场景的分布式事务解决方案主要有两种：seata、消息中间件。\n\n### 4.1.1 模拟分布式事务错误案例\n\n\n\n​	当前订单表中一个id为123的数据，处于未删除状态。 库存表中该订单商品数量为90。当将订单状态改为已删除，则需要恢复库存表数据。 \n\n​	但当订单服务通过本地事务修改完成，并发送完消息后，出现异常。 则会造成订单表修改失败，而库存表修改成功。\n\n#### 4.1.1.1 生产者\n\n```java\n@Transactional\npublic boolean delOrder(Integer id) {\n\n    //查询订单信息\n    OrderEntity orderEntity = orderMapper.selectById(id);\n\n    //删除订单\n    orderEntity.setIsDel(1);\n    int result = orderMapper.updateById(orderEntity);\n\n    //通知库存服务\n    Message message = new Message();\n    message.setBody(JSON.toJSONString(orderEntity).getBytes(StandardCharsets.UTF_8));\n    rocketMQTemplate.syncSend(\"order-del-topic:stock\",message);\n\n    int i=1/0;\n    return result>0;\n}\n```\n\n#### 4.1.1.2 消费者\n\n**消息监听类**\n\n```java\n@Component\n@RocketMQMessageListener(topic = \"order-del-topic\",consumerGroup = \"order-del-group\",selectorExpression = \"stock\")\npublic class DelOrderMessageListener implements RocketMQListener<Message> {\n\n    @Autowired\n    private StockService stockService;\n    \n    @Override\n    public void onMessage(Message message) {\n\n        //以message的key作为主键id，向消息表插入数据。通过主键避免消息重复处理\n        System.out.println(LocalTime.now()+\"stock service : \"+ new String(message.getBody()));\n\n        OrderEntity orderEntity = JSON.parseObject(new String(message.getBody()), OrderEntity.class);\n\n        QueryWrapper<StockEntity> wrapper = new QueryWrapper<>();\n        wrapper.lambda().eq(StockEntity::getGoodsId,orderEntity.getGoodsId());\n        StockEntity stockEntity = stockService.getOne(wrapper);\n\n        stockService.revertStock(stockEntity.getGoodsId(),orderEntity.getNumber(),stockEntity.getVersion());\n    }\n}\n```\n\n**DAO层实现**\n\n```java\n@Mapper\npublic interface StockMapper extends BaseMapper<StockEntity> {\n\n    @Update(\"update tb_stock set stock_number=stock_number+#{stockNumber},version=version+1 where goods_id=#{goodsId} and version = #{version}\")\n    void revertStock(@Param(\"goodsId\") int goodsId, @Param(\"stockNumber\") int stockNumber, @Param(\"version\") int version);\n}\n```\n\n**业务层实现**\n\n```java\n@Transactional\npublic void revertStock(int goodsId, int number, int version) {\n    stockMapper.revertStock(goodsId, number, version);\n}\n```\n\n## 4.2 执行流程\n\n\n\n1）事务发起方发送prepare信息到broker，且事务消息的发送是同步发送的方式\n\n2）broker接收到消息会将所有的事务消息写入系统默认的**RMQ_SYS_TRANS_HALF_TOPIC**\n\n2）写入成功，broker向事务发起方返回消息成功ACK通知\n\n3）事务发起方接收到ACK通知执行本地事务\n\n4）事务发起方根据本地事务的执行结果向broker返回commit或rollback，实现二次提交确认。如果提交commit，broker则把该消息发送给consumer。如果提交rollback，broker则默认将该消息丢弃。\n\n5）如果在执行本地事务过程中出现异常，出现超时，导致第四步的commit或rollback没有到达broker或 返回UNKNOWN状态。broker将在一段时间(**默认60s，可修改可通过在broker.conf文件中设置transactionCheckInterval的值来改变默认值，单位为毫秒**)后自动对该消息进行回查，总共回查15次（**默认值，可修改broker配置文件中transactionCheckMax参数值**）。同时broker在每次回查时会将消息再在**RMQ_SYS_TRANS_HALF_TOPIC**写一次\n\n6）事务发起方接收到回查信息后查询对应消息的本地事务执行结果。\n\n7）事务发起方根据本地事务的最终结果再次提交二次确认。\n\n8）当结果为commit时，MQ会将发起方的消息发送到消息消费方。\n\n9）消息消费方采用重试机制与死信队列保证消息处理成功。\n\n10）MQ回调事务发起方的后续业务处理。\n\n## 4.3 事务消息实现\n\n### 4.3.1 生产者\n\n**1）修改订单服务的业务层实现**\n\n```java\n@Transactional\npublic boolean delOrder(Integer id) {\n\n    //查询订单信息\n    OrderEntity orderEntity = orderMapper.selectById(id);\n    \n    //发送事务消息\n    org.springframework.messaging.Message<String> message = MessageBuilder.withPayload(JSON.toJSONString(orderEntity)).build();\n    TransactionSendResult sendResult = rocketMQTemplate.sendMessageInTransaction(\"order-del-topic:stock\", message, null);\n    if (sendResult.getSendStatus().ordinal() ==1){\n        return false;\n    }\n    return true;\n}\n```\n\n**2）创建事务消息监听类**\n\n```java\n@Component\n@RocketMQTransactionListener\npublic class TransactionListenerImpl implements RocketMQLocalTransactionListener {\n\n    @Autowired\n    private OrderMapper orderMapper;\n\n    @Override\n    //执行本地事务\n    public RocketMQLocalTransactionState executeLocalTransaction(Message msg, Object arg) {\n\n        byte[] info = (byte[]) msg.getPayload();\n        System.out.println(\"receive trans message : \"+new String(info));\n        //解析消息\n        OrderEntity orderEntity = JSON.parseObject(new String(info), OrderEntity.class);\n\n        //删除订单\n        orderEntity.setIsDel(1);\n        int result = orderMapper.updateById(orderEntity);\n        if (result >=1){\n            /**\n             * 事务消息状态有三种：\n             * COMMIT：提交事务，消费者会立即接收到消息\n             * ROLLBACK：回滚事务，消费方不会接收到消息\n             * UNKNOWN：中间状态，需要进行本地事务回查，如执行超时。\n             */\n\n            //模拟演示事务回查\n            try {\n                System.in.read();\n            } catch (IOException e) {\n                e.printStackTrace();\n            }\n\n            return RocketMQLocalTransactionState.COMMIT;\n        }\n        return RocketMQLocalTransactionState.ROLLBACK;\n    }\n\n    //事务回查\n    @Override\n    public RocketMQLocalTransactionState checkLocalTransaction(Message msg) {\n\n        byte[] info = (byte[]) msg.getPayload();\n        System.out.println(\"receive trans message : \"+new String(info));\n        //解析消息\n        OrderEntity orderEntity = JSON.parseObject(new String(info), OrderEntity.class);\n\n        int isDel = orderMapper.selectById(orderEntity.getId()).getIsDel();\n        if (isDel == 1){\n            return RocketMQLocalTransactionState.COMMIT;\n        }else {\n            return RocketMQLocalTransactionState.ROLLBACK;\n        }\n    }\n}\n```\n\n### 4.3.2 消费者实现\n\n```java\n@Component\n@RocketMQMessageListener(topic = \"order-del-topic\",consumerGroup = \"order-del-group\",selectorExpression = \"stock\")\npublic class DelOrderMessageListener implements RocketMQListener<String> {\n\n    @Autowired\n    private StockService stockService;\n\n    @Override\n    public void onMessage(String message) {\n\n        System.out.println(\"message receive info : \" + message);\n\n        //以message的key作为主键id，向消息表插入数据。通过主键避免消息重复处理\n        OrderEntity orderEntity = JSON.parseObject(message, OrderEntity.class);\n\n        QueryWrapper<StockEntity> wrapper = new QueryWrapper<>();\n        wrapper.lambda().eq(StockEntity::getGoodsId,orderEntity.getGoodsId());\n        StockEntity stockEntity = stockService.getOne(wrapper);\n\n        stockService.revertStock(stockEntity.getGoodsId(),orderEntity.getNumber(),stockEntity.getVersion());\n    }\n}\n```\n\n# 5 数据传输机制\n\n​	RocketMQ可以完成服务间的消息传递，那么它又是如何完成数据的传输呢？RocketMQ为了让数据更加高效的传输，采用了**零拷贝**的方式\n\n## 5.1 传统传输方式\n\n​	从上述流程可以发现，在传统传输模式下，大量的应用了内存进行数据缓冲，这种方式主要为了提升性能，因为通过内存可以进行数据预读并保存到内存中，当数据体积小于内存容量，将会极大的提升性能。\n\n\n\n## 5.2 零拷贝\n\n### 5.2.1 零拷贝介绍\n\n​	上诉流程过于繁琐，第二次和第三次操作的存在实属多余，产生很多冗余数据拷贝操作，造成性能浪费。数据可以直接从内核内存传输到网卡内存内存，这个过程就叫是零拷贝。零拷贝利用了NIO中的transferTo()在 Linux 和 UNIX 系统进行数据传输。\n\n\n\n### 5.2.2 性能对比\n\n\n\n# 6 消息存储结构\n\n​	RocketMQ会将数据存储在磁盘，从而直接解决了内容持久化问题。但是并不影响rocketMQ对于实时性与高吞吐量性能的要求。\n\n## 6.1 随机读写&顺序读写\n\n​	磁盘有时并没有想象的那么慢。就目前的高速磁盘(SSD)来将，**磁盘顺序写**的速度可以达到600M/s甚至更高，完全匹配的上网络间数据传输的速度或超出。但是对于磁盘**随机写**的速度大概100KB/s。两者之间相差了6000倍之多。\n\n​	**RocketMQ采用顺序写、随机读机制。 虽然是随机读但消息并不低，其利用操作系统的pagecache机制，完成批量读取。**\n\n### 6.1.1 随机读写\n\n​	当服务器要向磁盘写入数据时，数据是随机的写在磁盘不同位置上。\n\n\n### 6.1.2 顺序读写\n\n​	当服务器要向磁盘写入数据时，数据是按磁盘空间逐次进行写入。\n\n\n\n### 6.1.3 为何产生性能差距\n\n​	文件系统数据都是分成很多小块的，假如每块数据可以存储8KB的数据。而硬盘每次读写刚好读取8kb的情况下，当然可以达到最大读取效果。但如果每块里面只有1byte数据，而每次读写仍然是一个数据块。那么随机读写速度就会下降4000倍。而顺序读写每次都是读取最大的数据块。加上顺序读写的优化算法，肯定是比随机读写吞吐量大一些。\n\n## 6.2 消息存储结构\n\n​	RocketMQ内部数据存储，会操作两个文件：**CommitLog**、**ComsumeQueue**。并且这两个文件都会持久化到磁盘。\n\n**CommitLog**：所有消息内容全部持久化到这个文件中。\n\n**ComsumeQueue**：类似数据库的索引文件，存储CommitLog的元数据和tag属性。\n\n\n## 6.3 过期删除机制\n\n​	Rocket为了避免内存与磁盘的浪费，绝对不会将消息永远的存储在服务器上。内部会自动监控非当前写文件，在一定时间间隔（默认72小时，可修改**broker.config**中**fileReservedTime**重设，单位：小时）内没有再次被更新，则判定该文件已过期，应删除且不关注该文件中内容是否全部被消费。\n\n# 7 刷盘策略\n\n​	RocketMQ在通过顺序写的方式向磁盘写数据时，使用了两种方式：**同步刷盘**、**异步刷盘**。可以更改**broker.conf**文件中**flushDiskType**参数设置**SYNC_FLUSH**,**ASYNC_FLUSH**。\n\n## 7.1 同步刷盘\n\n**特点：**\n\n​	返回写成功状态时，消息已经被写入磁盘。\n\n**执行流程：**\n\n​	1）生产者向broker发送消息。\n\n​	2）生产者线程将消息写入内存后，唤醒并等待刷盘线程响应。\n\n​	3）刷盘线程启动，将内存数据写入到磁盘。\n\n​	4）当写入磁盘成功，刷盘线程会向生产者线程返回结果状态。\n\n​	5）生产者线程最终进行结果返回。\n\n​	\n\n## 7.2 异步刷盘\n\n**特点：**\n\n​	返回成功状态时，不保证消息一定写入磁盘成功。\n\n**执行流程：**\n\n​	1）生产者向broker发送消息，到达内存后，唤醒刷盘线程，直接返回结果状态。\n\n​	2）刷盘线程异步的完成磁盘写入。\n\n​	\n\n## 7.3 两种策略对比\n\n| 复制方式 | 优点               | 缺点                               | 适用场景                         |\n| -------- | ------------------ | ---------------------------------- | -------------------------------- |\n| 同步刷盘 | 能够保证消息不丢失 | 系统吞吐率相对于异步刷盘要低       | 消息可靠性要求较高的场景，如转账 |\n| 异步刷盘 | 系统吞吐量高       | 在一些特殊场景，有可能出现数据丢失 | 吞吐量要求较高的场景，如秒杀     |\n\n# 8 集群搭建&原理(扩展)\n\n​	详情请查看**04_帮助手册/RocketMQ集群搭建帮助手册**', '2022-02-01 11:56:56', 0, NULL, 0);
INSERT INTO `m_blog` VALUES (17, 1, 'asdfasd', 'fsdfs', 'fasdfasdfasasdfas', '2022-02-09 07:56:52', 0, '2022-02-08 23:57:37', 1);

-- ----------------------------
-- Table structure for m_user
-- ----------------------------
DROP TABLE IF EXISTS `m_user`;
CREATE TABLE `m_user`  (
  `id` bigint(20) NOT NULL AUTO_INCREMENT,
  `username` varchar(64) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `avatar` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `email` varchar(64) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `password` varchar(64) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `status` int(5) NOT NULL,
  `created` datetime(0) NULL DEFAULT NULL,
  `last_login` datetime(0) NULL DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `UK_USERNAME`(`username`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 3 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of m_user
-- ----------------------------
INSERT INTO `m_user` VALUES (1, 'admin', 'https://s4.ax1x.com/2021/12/06/or4Ide.jpg', NULL, 'e10adc3949ba59abbe56e057f20f883e', 0, '2020-04-20 10:44:01', NULL);
INSERT INTO `m_user` VALUES (2, 'ab', NULL, NULL, 'e10adc3949ba59abbe56e057f20f883e', 0, NULL, NULL);

SET FOREIGN_KEY_CHECKS = 1;
